{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset et création d'un dataset d'entraînement composé d'un dico avec 2 clés : text et label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "file_path_train = \"./data/train_submission.csv\"\n",
    "file_path_test = \"./data/test_without_labels.csv\"\n",
    "\n",
    "data_train = pd.read_csv(file_path_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Public</td>\n",
       "      <td>َ قَالَ النَّبِيُّ ص إِنِّي أَتَعَجَّبُ مِمَّن...</td>\n",
       "      <td>hau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Public</td>\n",
       "      <td>Filmen forteller historien om Will Hunting  en...</td>\n",
       "      <td>nob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public</td>\n",
       "      <td>An Arthrostylidium berryi in uska species han ...</td>\n",
       "      <td>wln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Public</td>\n",
       "      <td>Kancunarí enemigosniyquichejta munacuychej  al...</td>\n",
       "      <td>quh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public</td>\n",
       "      <td>Warmeqa ama yachachichunchu hermanospa tantaku...</td>\n",
       "      <td>quh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190594</th>\n",
       "      <td>Public</td>\n",
       "      <td>Publié par Masken à 22:46 Aucun commentaire:</td>\n",
       "      <td>hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190595</th>\n",
       "      <td>Public</td>\n",
       "      <td>ειπεν δε προς τους μαθητας ελευσονται ημεραι ο...</td>\n",
       "      <td>grc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190596</th>\n",
       "      <td>Public</td>\n",
       "      <td>Ya bay boch ban’en ni kug rung’aged ni ga be y...</td>\n",
       "      <td>yap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190597</th>\n",
       "      <td>Public</td>\n",
       "      <td>P'alimentase nun absuerben el sangre  sinón qu...</td>\n",
       "      <td>ast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190598</th>\n",
       "      <td>Public</td>\n",
       "      <td>Digau ala e hai hegau donu hagalee tale gi nia...</td>\n",
       "      <td>kpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190599 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text Label\n",
       "0       Public  َ قَالَ النَّبِيُّ ص إِنِّي أَتَعَجَّبُ مِمَّن...   hau\n",
       "1       Public  Filmen forteller historien om Will Hunting  en...   nob\n",
       "2       Public  An Arthrostylidium berryi in uska species han ...   wln\n",
       "3       Public  Kancunarí enemigosniyquichejta munacuychej  al...   quh\n",
       "4       Public  Warmeqa ama yachachichunchu hermanospa tantaku...   quh\n",
       "...        ...                                                ...   ...\n",
       "190594  Public       Publié par Masken à 22:46 Aucun commentaire:   hat\n",
       "190595  Public  ειπεν δε προς τους μαθητας ελευσονται ημεραι ο...   grc\n",
       "190596  Public  Ya bay boch ban’en ni kug rung’aged ni ga be y...   yap\n",
       "190597  Public  P'alimentase nun absuerben el sangre  sinón qu...   ast\n",
       "190598  Public  Digau ala e hai hegau donu hagalee tale gi nia...   kpg\n",
       "\n",
       "[190599 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse of the data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_without_label = data_train[data_train[\"Label\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Public</td>\n",
       "      <td>Kòe bô jōa kú  hō͘-sū sió-chiá lâi kā góan mn̄...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Public</td>\n",
       "      <td>Söğütçük sī chi̍t ê tī Türkiye Aydın séng Çine...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Public</td>\n",
       "      <td>Golden Valley Kūn ū khó-lêng sī kóng:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>Public</td>\n",
       "      <td>Tī Montégut-Lauragais ê sì-ûi ū Nogaret  Revel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Public</td>\n",
       "      <td>Soveria Simeri ùi séng lāi ê hoān-ûi.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189637</th>\n",
       "      <td>Public</td>\n",
       "      <td>Bellebrune sī ūi-tī Hoat-kok Nord-Pas-de-Calai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189946</th>\n",
       "      <td>Public</td>\n",
       "      <td>Bô phah-sǹg  tī sin-le̍k 10 go̍eh 29 hō ē-po͘ ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189959</th>\n",
       "      <td>Public</td>\n",
       "      <td>Wiejki sī chi̍t ê tī Pho-lân Kiōng-hô-kok Podl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190397</th>\n",
       "      <td>Public</td>\n",
       "      <td>Tī pún só͘-chāi sì-ûi ê tē-hng ū Valy  Veselí ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190493</th>\n",
       "      <td>Public</td>\n",
       "      <td>Ojén sī tī Se-pan-gâ Andalucía siā-lí Málaga s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text Label\n",
       "107     Public  Kòe bô jōa kú  hō͘-sū sió-chiá lâi kā góan mn̄...   NaN\n",
       "803     Public  Söğütçük sī chi̍t ê tī Türkiye Aydın séng Çine...   NaN\n",
       "1095    Public              Golden Valley Kūn ū khó-lêng sī kóng:   NaN\n",
       "1894    Public  Tī Montégut-Lauragais ê sì-ûi ū Nogaret  Revel...   NaN\n",
       "2499    Public              Soveria Simeri ùi séng lāi ê hoān-ûi.   NaN\n",
       "...        ...                                                ...   ...\n",
       "189637  Public  Bellebrune sī ūi-tī Hoat-kok Nord-Pas-de-Calai...   NaN\n",
       "189946  Public  Bô phah-sǹg  tī sin-le̍k 10 go̍eh 29 hō ē-po͘ ...   NaN\n",
       "189959  Public  Wiejki sī chi̍t ê tī Pho-lân Kiōng-hô-kok Podl...   NaN\n",
       "190397  Public  Tī pún só͘-chāi sì-ûi ê tē-hng ū Valy  Veselí ...   NaN\n",
       "190493  Public  Ojén sī tī Se-pan-gâ Andalucía siā-lí Málaga s...   NaN\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_without_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a 500 instances qui ne sont pas labellisées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_without_nan_for_label = data_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 390 différentes langues dans le dataset de train\n"
     ]
    }
   ],
   "source": [
    "number_of_languages = len(data_train[\"Label\"].unique())\n",
    "print(f\"Il y a {number_of_languages} différentes langues dans le dataset de train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse stats sur les données labellisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tgk</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guj</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tat</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crh</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaa</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gil</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toi</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaa</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kua</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcr</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Usage  Text\n",
       "Label             \n",
       "tgk     1500  1500\n",
       "guj     1000  1000\n",
       "tat     1000  1000\n",
       "crh     1000  1000\n",
       "kaa     1000  1000\n",
       "...      ...   ...\n",
       "gil        2     2\n",
       "toi        1     1\n",
       "gaa        1     1\n",
       "kua        1     1\n",
       "gcr        1     1\n",
       "\n",
       "[389 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sorted_by_number_instances_by_language = data_train_without_nan_for_label.groupby(\"Label\").count().sort_values('Usage', ascending=False)\n",
    "dataset_sorted_by_number_instances_by_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observer que le nombre d'exemples par langue varie énormément. Certaines langues sont sur-représentées (avec 1500 instances pour la première) par rapport à d'autres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de langues avec au moins 100 instances est 93.31619537275064%\n"
     ]
    }
   ],
   "source": [
    "percentage_of_languages_with_at_least_100_instances = len(dataset_sorted_by_number_instances_by_language[dataset_sorted_by_number_instances_by_language[\"Usage\"] >= 100])/len(dataset_sorted_by_number_instances_by_language) * 100\n",
    "print(f\"Le pourcentage de langues avec au moins 100 instances est {percentage_of_languages_with_at_least_100_instances}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitement du dataset de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re \n",
    "import unicodedata\n",
    "\n",
    "def cleaning(text): \n",
    "    \"\"\"\n",
    "    Fonction pour pré-traiter le texte en enlevant tous les éléments de ponctuation, les chiffres et les double espaces. \n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"\\(.*?\\)|\\[.*?\\]|\\{.*?\\}|['\\\"«»„“”‘’]|\\<.*?\\>\", \" \", text) # 1. Supprimer les textes entre (), [], {}, \"\", « »\n",
    "    text = re.sub(r\"https?://[^\\s]+|www\\.[^\\s]+\", \" \", text) # 2. Supprimer les URLs\n",
    "    text = re.sub(r\"\\b[A-Z]+\\d*[A-Z\\d]*\", \" \", text) # 3. Supprimer les sigles type \"IK10\", \"ABC123\", \"X4D\" (au moins 1 lettre + au moins 1 chiffre)\n",
    "    text = re.sub(r\"\\b[A-ZÀ-ÖØ-Þ][a-zà-öø-ÿ]*\", \" \", text) # 4. Supprimer les mots qui commencent par une majuscule (prénoms, noms propres, etc.)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)  # 5. Supprimer les nombres isolés\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # 6. Supprimer la ponctuation et les caractères spéciaux\n",
    "    text = ''.join(c for c in text if unicodedata.category(c)[0] not in [\"C\", \"S\"])  # 7. Supprimer les caractères de contrôle Unicode, symboles et emojis\n",
    "\n",
    "    # Liste de ponctuation à inclure pour les langues asiatiques\n",
    "    asian_punctuation = \"，。？！《》【】（）；：、。\"\n",
    "    text = text.replace('-', ' ')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + asian_punctuation))\n",
    "\n",
    "    # Supprimer les emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "\n",
    "    text_cleaned = emoji_pattern.sub(r'', text)\n",
    "    text_cleaned = text_cleaned.lower()\n",
    "\n",
    "    return(text_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un ensemble de mots anglais pour pouvoir enlever les mots anglais dans les phrases avec des mots anglais mélangés à d'autres langues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/hippolytelecomte/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Télécharger la liste des mots en anglais (une seule fois nécessaire)\n",
    "nltk.download('words')\n",
    "\n",
    "# Liste des mots en anglais\n",
    "english_words = set(word.lower() for word in words.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ang = data_train_without_nan_for_label[data_train_without_nan_for_label[\"Label\"] == 'eng'][\"Text\"]\n",
    "\n",
    "# Collecte des mots uniques\n",
    "for text in data_ang:\n",
    "    for word in text.split():\n",
    "        english_words.add(word.lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_most_english_words(text): \n",
    "    \"\"\"\n",
    "    Fonction pour enlever les mots anglais lorsque la langue du texte n'est pas l'anglais. \n",
    "    \"\"\"\n",
    "    tokens = text.split() \n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in english_words]\n",
    "\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première approche avec CountVectorizer et MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation entre le train et le val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, val_set = train_test_split(data_train_without_nan_for_label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application du pré-traitement sur tout le dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()  \n",
    "\n",
    "def pre_processing(df, remove_espace = True, not_test = True, need_to_clean = True): \n",
    "    if need_to_clean: \n",
    "        df['Text'] = df['Text'].apply(cleaning)\n",
    "    \n",
    "    if not_test: \n",
    "        df['Text'] = df.progress_apply(\n",
    "            lambda row: remove_most_english_words(row['Text']) if row['Label'] != 'eng' else row['Text'], axis=1\n",
    "        )\n",
    "    \n",
    "    if remove_espace: \n",
    "        df['Text'] = df['Text'].str.replace(' ', '', regex=False)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152079/152079 [00:01<00:00, 76878.05it/s]\n",
      "100%|██████████| 38020/38020 [00:00<00:00, 80662.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set_first_version = train_set.copy()\n",
    "val_set_first_version = val_set.copy()\n",
    "train_set_first_version = pre_processing(train_set_first_version, remove_espace=False)\n",
    "val_set_first_version = pre_processing(val_set_first_version, remove_espace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_first_version.to_csv(\"train_set_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(2, 6), max_features=10000)\n",
    "x_train = train_set_first_version['Text'].tolist()\n",
    "y_train = train_set_first_version['Label'].tolist()\n",
    "x_val = val_set_first_version['Text'].tolist()\n",
    "y_val = val_set_first_version['Label'].tolist()\n",
    "y_total = y_train + y_val\n",
    "\n",
    "# converting categorical variables to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_total)\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "label_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "\n",
    "\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_val = vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.0001, fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.0001, fit_prior=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.0001, fit_prior=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB(alpha= 0.0001, fit_prior = False) \n",
    "naive_bayes.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage    500\n",
       "Text     500\n",
       "Name: yue, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sorted_by_number_instances_by_language.loc[\"yue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7103366649132036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "predictions = naive_bayes.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtenir les indices des classes présentes dans y_val\n",
    "present_classes = np.unique(np.concatenate((y_val, predictions)))\n",
    "\n",
    "# Extraire uniquement les noms correspondants\n",
    "filtered_target_names = [le.classes_[i] for i in present_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (trié par F1-score décroissant):\n",
      "\n",
      "asm: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 99.0\n",
      "bpy: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "bzj: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 104.0\n",
      "cab: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 83.0\n",
      "ctu: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "knv: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "mau: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 104.0\n",
      "nav: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "top: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "csy: F1-score = 0.9959, Precision = 0.9917, Recall = 1.0000, Support = 120.0\n",
      "naq: F1-score = 0.9955, Precision = 0.9911, Recall = 1.0000, Support = 111.0\n",
      "mco: F1-score = 0.9954, Precision = 0.9908, Recall = 1.0000, Support = 108.0\n",
      "xav: F1-score = 0.9954, Precision = 0.9908, Recall = 1.0000, Support = 108.0\n",
      "nch: F1-score = 0.9949, Precision = 0.9899, Recall = 1.0000, Support = 98.0\n",
      "srm: F1-score = 0.9949, Precision = 1.0000, Recall = 0.9898, Support = 98.0\n",
      "yao: F1-score = 0.9948, Precision = 0.9897, Recall = 1.0000, Support = 96.0\n",
      "gym: F1-score = 0.9945, Precision = 1.0000, Recall = 0.9891, Support = 92.0\n",
      "tca: F1-score = 0.9945, Precision = 0.9891, Recall = 1.0000, Support = 91.0\n",
      "mgh: F1-score = 0.9945, Precision = 0.9890, Recall = 1.0000, Support = 90.0\n",
      "mal: F1-score = 0.9942, Precision = 1.0000, Recall = 0.9884, Support = 86.0\n",
      "arn: F1-score = 0.9913, Precision = 0.9913, Recall = 0.9913, Support = 115.0\n",
      "wal: F1-score = 0.9911, Precision = 0.9911, Recall = 0.9911, Support = 112.0\n",
      "ksd: F1-score = 0.9908, Precision = 0.9908, Recall = 0.9908, Support = 109.0\n",
      "kpg: F1-score = 0.9907, Precision = 0.9907, Recall = 0.9907, Support = 107.0\n",
      "tam: F1-score = 0.9902, Precision = 1.0000, Recall = 0.9806, Support = 103.0\n",
      "mzh: F1-score = 0.9900, Precision = 0.9802, Recall = 1.0000, Support = 99.0\n",
      "div: F1-score = 0.9894, Precision = 1.0000, Recall = 0.9789, Support = 95.0\n",
      "ikk: F1-score = 0.9891, Precision = 0.9891, Recall = 0.9891, Support = 92.0\n",
      "cuk: F1-score = 0.9890, Precision = 0.9783, Recall = 1.0000, Support = 90.0\n",
      "nyu: F1-score = 0.9889, Precision = 0.9889, Recall = 0.9889, Support = 90.0\n",
      "hui: F1-score = 0.9884, Precision = 0.9770, Recall = 1.0000, Support = 85.0\n",
      "lhu: F1-score = 0.9870, Precision = 1.0000, Recall = 0.9744, Support = 39.0\n",
      "tdt: F1-score = 0.9870, Precision = 0.9870, Recall = 0.9870, Support = 77.0\n",
      "ixl: F1-score = 0.9869, Precision = 0.9741, Recall = 1.0000, Support = 113.0\n",
      "qvi: F1-score = 0.9869, Precision = 0.9741, Recall = 1.0000, Support = 113.0\n",
      "mam: F1-score = 0.9862, Precision = 0.9907, Recall = 0.9817, Support = 109.0\n",
      "ngu: F1-score = 0.9852, Precision = 0.9804, Recall = 0.9901, Support = 101.0\n",
      "guc: F1-score = 0.9846, Precision = 0.9697, Recall = 1.0000, Support = 96.0\n",
      "hus: F1-score = 0.9845, Precision = 0.9794, Recall = 0.9896, Support = 96.0\n",
      "rug: F1-score = 0.9845, Precision = 0.9694, Recall = 1.0000, Support = 95.0\n",
      "tbz: F1-score = 0.9843, Precision = 0.9691, Recall = 1.0000, Support = 94.0\n",
      "yap: F1-score = 0.9843, Precision = 0.9691, Recall = 1.0000, Support = 94.0\n",
      "kjb: F1-score = 0.9838, Precision = 0.9891, Recall = 0.9785, Support = 93.0\n",
      "ahk: F1-score = 0.9834, Precision = 0.9674, Recall = 1.0000, Support = 89.0\n",
      "chk: F1-score = 0.9834, Precision = 0.9780, Recall = 0.9889, Support = 90.0\n",
      "mps: F1-score = 0.9834, Precision = 0.9674, Recall = 1.0000, Support = 89.0\n",
      "ote: F1-score = 0.9834, Precision = 0.9889, Recall = 0.9780, Support = 91.0\n",
      "suz: F1-score = 0.9829, Precision = 0.9746, Recall = 0.9914, Support = 116.0\n",
      "djk: F1-score = 0.9829, Precision = 0.9773, Recall = 0.9885, Support = 87.0\n",
      "rop: F1-score = 0.9829, Precision = 0.9663, Recall = 1.0000, Support = 86.0\n",
      "poh: F1-score = 0.9828, Precision = 0.9744, Recall = 0.9913, Support = 115.0\n",
      "tuc: F1-score = 0.9828, Precision = 0.9744, Recall = 0.9913, Support = 115.0\n",
      "ncj: F1-score = 0.9827, Precision = 0.9770, Recall = 0.9884, Support = 86.0\n",
      "quh: F1-score = 0.9825, Precision = 0.9655, Recall = 1.0000, Support = 84.0\n",
      "kbp: F1-score = 0.9818, Precision = 0.9643, Recall = 1.0000, Support = 108.0\n",
      "tso: F1-score = 0.9818, Precision = 0.9818, Recall = 0.9818, Support = 110.0\n",
      "khm: F1-score = 0.9814, Precision = 1.0000, Recall = 0.9634, Support = 82.0\n",
      "fij: F1-score = 0.9806, Precision = 0.9712, Recall = 0.9902, Support = 102.0\n",
      "ndo: F1-score = 0.9806, Precision = 0.9806, Recall = 0.9806, Support = 103.0\n",
      "umb: F1-score = 0.9802, Precision = 0.9802, Recall = 0.9802, Support = 101.0\n",
      "aoj: F1-score = 0.9800, Precision = 0.9608, Recall = 1.0000, Support = 98.0\n",
      "kal: F1-score = 0.9796, Precision = 0.9796, Recall = 0.9796, Support = 98.0\n",
      "kjh: F1-score = 0.9796, Precision = 1.0000, Recall = 0.9600, Support = 100.0\n",
      "kek: F1-score = 0.9785, Precision = 0.9891, Recall = 0.9681, Support = 94.0\n",
      "sat: F1-score = 0.9783, Precision = 1.0000, Recall = 0.9574, Support = 94.0\n",
      "toj: F1-score = 0.9770, Precision = 0.9636, Recall = 0.9907, Support = 107.0\n",
      "yom: F1-score = 0.9763, Precision = 0.9810, Recall = 0.9717, Support = 106.0\n",
      "quw: F1-score = 0.9756, Precision = 0.9615, Recall = 0.9901, Support = 101.0\n",
      "pls: F1-score = 0.9753, Precision = 0.9634, Recall = 0.9875, Support = 80.0\n",
      "tzo: F1-score = 0.9749, Precision = 0.9510, Recall = 1.0000, Support = 97.0\n",
      "lus: F1-score = 0.9733, Precision = 0.9891, Recall = 0.9579, Support = 95.0\n",
      "zai: F1-score = 0.9730, Precision = 0.9730, Recall = 0.9730, Support = 111.0\n",
      "tlh: F1-score = 0.9727, Precision = 1.0000, Recall = 0.9468, Support = 94.0\n",
      "kac: F1-score = 0.9717, Precision = 0.9810, Recall = 0.9626, Support = 107.0\n",
      "nnb: F1-score = 0.9714, Precision = 1.0000, Recall = 0.9444, Support = 108.0\n",
      "cak: F1-score = 0.9712, Precision = 0.9619, Recall = 0.9806, Support = 103.0\n",
      "kbd: F1-score = 0.9712, Precision = 0.9902, Recall = 0.9528, Support = 106.0\n",
      "lao: F1-score = 0.9712, Precision = 1.0000, Recall = 0.9439, Support = 107.0\n",
      "cjk: F1-score = 0.9694, Precision = 0.9500, Recall = 0.9896, Support = 96.0\n",
      "seh: F1-score = 0.9691, Precision = 0.9792, Recall = 0.9592, Support = 98.0\n",
      "bqc: F1-score = 0.9684, Precision = 0.9684, Recall = 0.9684, Support = 95.0\n",
      "pon: F1-score = 0.9681, Precision = 0.9785, Recall = 0.9579, Support = 95.0\n",
      "quc: F1-score = 0.9665, Precision = 0.9902, Recall = 0.9439, Support = 107.0\n",
      "vol: F1-score = 0.9626, Precision = 1.0000, Recall = 0.9278, Support = 97.0\n",
      "kos: F1-score = 0.9623, Precision = 0.9623, Recall = 0.9623, Support = 106.0\n",
      "eus: F1-score = 0.9622, Precision = 0.9674, Recall = 0.9570, Support = 93.0\n",
      "oss: F1-score = 0.9617, Precision = 0.9778, Recall = 0.9462, Support = 93.0\n",
      "hun: F1-score = 0.9609, Precision = 0.9773, Recall = 0.9451, Support = 91.0\n",
      "luo: F1-score = 0.9581, Precision = 0.9537, Recall = 0.9626, Support = 107.0\n",
      "sag: F1-score = 0.9569, Precision = 0.9901, Recall = 0.9259, Support = 108.0\n",
      "lug: F1-score = 0.9565, Precision = 0.9612, Recall = 0.9519, Support = 104.0\n",
      "tpi: F1-score = 0.9560, Precision = 0.9775, Recall = 0.9355, Support = 93.0\n",
      "acr: F1-score = 0.9557, Precision = 0.9417, Recall = 0.9700, Support = 100.0\n",
      "che: F1-score = 0.9548, Precision = 0.9596, Recall = 0.9500, Support = 100.0\n",
      "srn: F1-score = 0.9529, Precision = 0.9643, Recall = 0.9419, Support = 86.0\n",
      "mya: F1-score = 0.9508, Precision = 1.0000, Recall = 0.9062, Support = 96.0\n",
      "bem: F1-score = 0.9492, Precision = 0.9231, Recall = 0.9767, Support = 86.0\n",
      "ssw: F1-score = 0.9474, Precision = 0.9802, Recall = 0.9167, Support = 108.0\n",
      "alt: F1-score = 0.9457, Precision = 0.9255, Recall = 0.9667, Support = 90.0\n",
      "yid: F1-score = 0.9444, Precision = 0.9659, Recall = 0.9239, Support = 92.0\n",
      "hye: F1-score = 0.9441, Precision = 0.9870, Recall = 0.9048, Support = 84.0\n",
      "ewe: F1-score = 0.9412, Precision = 0.9565, Recall = 0.9263, Support = 95.0\n",
      "mos: F1-score = 0.9405, Precision = 0.9355, Recall = 0.9457, Support = 92.0\n",
      "orm: F1-score = 0.9390, Precision = 0.8929, Recall = 0.9901, Support = 101.0\n",
      "fon: F1-score = 0.9379, Precision = 1.0000, Recall = 0.8830, Support = 94.0\n",
      "hmo: F1-score = 0.9371, Precision = 0.9111, Recall = 0.9647, Support = 85.0\n",
      "meu: F1-score = 0.9369, Precision = 0.9541, Recall = 0.9204, Support = 113.0\n",
      "kmb: F1-score = 0.9355, Precision = 0.9158, Recall = 0.9560, Support = 91.0\n",
      "ach: F1-score = 0.9333, Precision = 0.9130, Recall = 0.9545, Support = 22.0\n",
      "kam: F1-score = 0.9326, Precision = 0.9121, Recall = 0.9540, Support = 87.0\n",
      "lua: F1-score = 0.9278, Precision = 0.9278, Recall = 0.9278, Support = 97.0\n",
      "bis: F1-score = 0.9251, Precision = 0.9545, Recall = 0.8974, Support = 117.0\n",
      "vie: F1-score = 0.9241, Precision = 0.9571, Recall = 0.8933, Support = 75.0\n",
      "tok: F1-score = 0.9223, Precision = 1.0000, Recall = 0.8559, Support = 111.0\n",
      "mhr: F1-score = 0.9192, Precision = 0.9192, Recall = 0.9192, Support = 99.0\n",
      "gug: F1-score = 0.9187, Precision = 0.9505, Recall = 0.8889, Support = 108.0\n",
      "sme: F1-score = 0.9179, Precision = 0.9223, Recall = 0.9135, Support = 104.0\n",
      "fin: F1-score = 0.9154, Precision = 0.8762, Recall = 0.9583, Support = 96.0\n",
      "pis: F1-score = 0.9118, Precision = 0.9118, Recall = 0.9118, Support = 34.0\n",
      "ven: F1-score = 0.9111, Precision = 0.9880, Recall = 0.8454, Support = 97.0\n",
      "cym: F1-score = 0.9101, Precision = 0.9247, Recall = 0.8958, Support = 96.0\n",
      "fao: F1-score = 0.9074, Precision = 0.9159, Recall = 0.8991, Support = 109.0\n",
      "kik: F1-score = 0.9071, Precision = 0.9651, Recall = 0.8557, Support = 97.0\n",
      "udm: F1-score = 0.9055, Precision = 0.9192, Recall = 0.8922, Support = 102.0\n",
      "vep: F1-score = 0.9045, Precision = 0.8824, Recall = 0.9278, Support = 97.0\n",
      "snd: F1-score = 0.9020, Precision = 0.8679, Recall = 0.9388, Support = 98.0\n",
      "new: F1-score = 0.9018, Precision = 0.9266, Recall = 0.8783, Support = 115.0\n",
      "roh: F1-score = 0.9000, Precision = 0.8761, Recall = 0.9252, Support = 107.0\n",
      "csb: F1-score = 0.8970, Precision = 0.8916, Recall = 0.9024, Support = 82.0\n",
      "azb: F1-score = 0.8938, Precision = 0.8347, Recall = 0.9619, Support = 105.0\n",
      "chv: F1-score = 0.8927, Precision = 0.9634, Recall = 0.8316, Support = 95.0\n",
      "dtp: F1-score = 0.8925, Precision = 0.9222, Recall = 0.8646, Support = 96.0\n",
      "isl: F1-score = 0.8912, Precision = 0.8776, Recall = 0.9053, Support = 95.0\n",
      "lvs: F1-score = 0.8878, Precision = 0.8835, Recall = 0.8922, Support = 102.0\n",
      "min: F1-score = 0.8851, Precision = 0.8953, Recall = 0.8750, Support = 88.0\n",
      "tum: F1-score = 0.8851, Precision = 0.9625, Recall = 0.8191, Support = 94.0\n",
      "gle: F1-score = 0.8835, Precision = 0.8273, Recall = 0.9479, Support = 96.0\n",
      "npi: F1-score = 0.8829, Precision = 0.8909, Recall = 0.8750, Support = 112.0\n",
      "glv: F1-score = 0.8815, Precision = 0.8230, Recall = 0.9490, Support = 98.0\n",
      "ace: F1-score = 0.8800, Precision = 0.9565, Recall = 0.8148, Support = 108.0\n",
      "kea: F1-score = 0.8788, Precision = 0.8365, Recall = 0.9255, Support = 94.0\n",
      "sah: F1-score = 0.8761, Precision = 0.8250, Recall = 0.9340, Support = 106.0\n",
      "sgs: F1-score = 0.8756, Precision = 0.9072, Recall = 0.8462, Support = 104.0\n",
      "tir: F1-score = 0.8731, Precision = 0.8515, Recall = 0.8958, Support = 96.0\n",
      "ukr: F1-score = 0.8687, Precision = 0.8431, Recall = 0.8958, Support = 96.0\n",
      "lin: F1-score = 0.8677, Precision = 0.9111, Recall = 0.8283, Support = 99.0\n",
      "uig: F1-score = 0.8667, Precision = 0.9750, Recall = 0.7800, Support = 200.0\n",
      "sin: F1-score = 0.8662, Precision = 1.0000, Recall = 0.7640, Support = 89.0\n",
      "gla: F1-score = 0.8660, Precision = 0.9231, Recall = 0.8155, Support = 103.0\n",
      "hmn: F1-score = 0.8627, Precision = 0.9888, Recall = 0.7652, Support = 115.0\n",
      "heb: F1-score = 0.8609, Precision = 0.9286, Recall = 0.8025, Support = 81.0\n",
      "kir: F1-score = 0.8595, Precision = 0.7820, Recall = 0.9541, Support = 109.0\n",
      "ilo: F1-score = 0.8571, Precision = 0.8889, Recall = 0.8276, Support = 116.0\n",
      "swe: F1-score = 0.8559, Precision = 0.8596, Recall = 0.8522, Support = 115.0\n",
      "hsb: F1-score = 0.8531, Precision = 0.8491, Recall = 0.8571, Support = 105.0\n",
      "yor: F1-score = 0.8511, Precision = 0.9524, Recall = 0.7692, Support = 104.0\n",
      "mwl: F1-score = 0.8479, Precision = 0.8070, Recall = 0.8932, Support = 103.0\n",
      "fur: F1-score = 0.8468, Precision = 0.8103, Recall = 0.8868, Support = 106.0\n",
      "pnb: F1-score = 0.8448, Precision = 0.7967, Recall = 0.8991, Support = 109.0\n",
      "dyu: F1-score = 0.8421, Precision = 0.8421, Recall = 0.8421, Support = 95.0\n",
      "frr: F1-score = 0.8421, Precision = 0.8224, Recall = 0.8627, Support = 102.0\n",
      "grn: F1-score = 0.8411, Precision = 0.8491, Recall = 0.8333, Support = 108.0\n",
      "mon: F1-score = 0.8406, Precision = 0.9539, Recall = 0.7513, Support = 193.0\n",
      "lit: F1-score = 0.8395, Precision = 0.7669, Recall = 0.9273, Support = 110.0\n",
      "bam: F1-score = 0.8360, Precision = 0.8778, Recall = 0.7980, Support = 99.0\n",
      "pol: F1-score = 0.8360, Precision = 0.7745, Recall = 0.9080, Support = 87.0\n",
      "ful: F1-score = 0.8350, Precision = 0.8190, Recall = 0.8515, Support = 101.0\n",
      "hnj: F1-score = 0.8333, Precision = 0.7143, Recall = 1.0000, Support = 5.0\n",
      "tuk: F1-score = 0.8310, Precision = 0.9752, Recall = 0.7239, Support = 163.0\n",
      "quy: F1-score = 0.8298, Precision = 0.7723, Recall = 0.8966, Support = 87.0\n",
      "bre: F1-score = 0.8273, Precision = 0.7982, Recall = 0.8585, Support = 106.0\n",
      "ton: F1-score = 0.8263, Precision = 0.9200, Recall = 0.7500, Support = 92.0\n",
      "jbo: F1-score = 0.8249, Precision = 0.9605, Recall = 0.7228, Support = 101.0\n",
      "ces: F1-score = 0.8247, Precision = 0.8696, Recall = 0.7843, Support = 102.0\n",
      "tah: F1-score = 0.8205, Precision = 0.9195, Recall = 0.7407, Support = 108.0\n",
      "pus: F1-score = 0.8187, Precision = 0.8977, Recall = 0.7524, Support = 105.0\n",
      "rmy: F1-score = 0.8182, Precision = 0.8351, Recall = 0.8020, Support = 101.0\n",
      "pap: F1-score = 0.8125, Precision = 0.8750, Recall = 0.7583, Support = 120.0\n",
      "kom: F1-score = 0.8119, Precision = 0.8039, Recall = 0.8200, Support = 100.0\n",
      "ksh: F1-score = 0.8103, Precision = 0.7769, Recall = 0.8468, Support = 111.0\n",
      "slk: F1-score = 0.8093, Precision = 0.7632, Recall = 0.8614, Support = 101.0\n",
      "mzn: F1-score = 0.8085, Precision = 0.8085, Recall = 0.8085, Support = 94.0\n",
      "ceb: F1-score = 0.8070, Precision = 0.8415, Recall = 0.7753, Support = 89.0\n",
      "myv: F1-score = 0.8067, Precision = 0.7385, Recall = 0.8889, Support = 108.0\n",
      "bul: F1-score = 0.8040, Precision = 0.7692, Recall = 0.8421, Support = 95.0\n",
      "fry: F1-score = 0.8000, Precision = 0.8515, Recall = 0.7544, Support = 114.0\n",
      "lue: F1-score = 0.8000, Precision = 0.6667, Recall = 1.0000, Support = 4.0\n",
      "kon: F1-score = 0.7956, Precision = 0.8471, Recall = 0.7500, Support = 96.0\n",
      "szl: F1-score = 0.7956, Precision = 0.8372, Recall = 0.7579, Support = 95.0\n",
      "tls: F1-score = 0.7955, Precision = 0.8642, Recall = 0.7368, Support = 95.0\n",
      "pms: F1-score = 0.7953, Precision = 0.8831, Recall = 0.7234, Support = 94.0\n",
      "aln: F1-score = 0.7940, Precision = 0.8404, Recall = 0.7524, Support = 105.0\n",
      "ibo: F1-score = 0.7931, Precision = 0.8625, Recall = 0.7340, Support = 94.0\n",
      "diq: F1-score = 0.7892, Precision = 0.8022, Recall = 0.7766, Support = 94.0\n",
      "ayr: F1-score = 0.7870, Precision = 0.7456, Recall = 0.8333, Support = 102.0\n",
      "tur: F1-score = 0.7850, Precision = 0.7119, Recall = 0.8750, Support = 96.0\n",
      "lfn: F1-score = 0.7831, Precision = 0.7708, Recall = 0.7957, Support = 93.0\n",
      "ext: F1-score = 0.7826, Precision = 0.7438, Recall = 0.8257, Support = 109.0\n",
      "ron: F1-score = 0.7789, Precision = 0.7789, Recall = 0.7789, Support = 95.0\n",
      "gcf: F1-score = 0.7755, Precision = 1.0000, Recall = 0.6333, Support = 30.0\n",
      "dzo: F1-score = 0.7729, Precision = 0.8163, Recall = 0.7339, Support = 109.0\n",
      "smo: F1-score = 0.7657, Precision = 0.8701, Recall = 0.6837, Support = 98.0\n",
      "afr: F1-score = 0.7653, Precision = 0.8621, Recall = 0.6881, Support = 109.0\n",
      "epo: F1-score = 0.7640, Precision = 0.7391, Recall = 0.7907, Support = 86.0\n",
      "ido: F1-score = 0.7598, Precision = 0.8095, Recall = 0.7158, Support = 95.0\n",
      "vls: F1-score = 0.7593, Precision = 0.7130, Recall = 0.8119, Support = 101.0\n",
      "bod: F1-score = 0.7590, Precision = 0.7400, Recall = 0.7789, Support = 95.0\n",
      "jam: F1-score = 0.7576, Precision = 0.6579, Recall = 0.8929, Support = 112.0\n",
      "tyv: F1-score = 0.7528, Precision = 0.6755, Recall = 0.8500, Support = 120.0\n",
      "pfl: F1-score = 0.7527, Precision = 0.6796, Recall = 0.8434, Support = 83.0\n",
      "nso: F1-score = 0.7500, Precision = 0.7143, Recall = 0.7895, Support = 95.0\n",
      "grc: F1-score = 0.7480, Precision = 0.6051, Recall = 0.9794, Support = 97.0\n",
      "pag: F1-score = 0.7458, Precision = 0.9296, Recall = 0.6226, Support = 106.0\n",
      "deu: F1-score = 0.7404, Precision = 0.7333, Recall = 0.7476, Support = 103.0\n",
      "plt: F1-score = 0.7333, Precision = 0.9625, Recall = 0.5923, Support = 130.0\n",
      "qub: F1-score = 0.7273, Precision = 0.8000, Recall = 0.6667, Support = 6.0\n",
      "nap: F1-score = 0.7232, Precision = 0.7364, Recall = 0.7105, Support = 114.0\n",
      "zlm: F1-score = 0.7213, Precision = 0.7097, Recall = 0.7333, Support = 120.0\n",
      "eml: F1-score = 0.7208, Precision = 0.8256, Recall = 0.6396, Support = 111.0\n",
      "cat: F1-score = 0.7158, Precision = 0.7640, Recall = 0.6733, Support = 101.0\n",
      "krc: F1-score = 0.7125, Precision = 0.5644, Recall = 0.9661, Support = 118.0\n",
      "arg: F1-score = 0.7124, Precision = 0.6587, Recall = 0.7757, Support = 107.0\n",
      "weighted avg: F1-score = 0.7116, Precision = 0.7438, Recall = 0.7186, Support = 38020.0\n",
      "mlt: F1-score = 0.7097, Precision = 0.6525, Recall = 0.7778, Support = 99.0\n",
      "macro avg: F1-score = 0.7089, Precision = 0.7289, Recall = 0.7243, Support = 38020.0\n",
      "por: F1-score = 0.7079, Precision = 0.7778, Recall = 0.6495, Support = 97.0\n",
      "rap: F1-score = 0.7059, Precision = 0.8889, Recall = 0.5854, Support = 41.0\n",
      "gor: F1-score = 0.7039, Precision = 0.7875, Recall = 0.6364, Support = 99.0\n",
      "wol: F1-score = 0.7006, Precision = 0.8462, Recall = 0.5978, Support = 92.0\n",
      "bar: F1-score = 0.6987, Precision = 0.6299, Recall = 0.7843, Support = 102.0\n",
      "kab: F1-score = 0.6893, Precision = 0.6017, Recall = 0.8068, Support = 88.0\n",
      "haw: F1-score = 0.6889, Precision = 0.6966, Recall = 0.6813, Support = 91.0\n",
      "lij: F1-score = 0.6778, Precision = 0.5745, Recall = 0.8265, Support = 98.0\n",
      "twi: F1-score = 0.6759, Precision = 0.6239, Recall = 0.7374, Support = 99.0\n",
      "swc: F1-score = 0.6738, Precision = 0.8289, Recall = 0.5676, Support = 111.0\n",
      "nno: F1-score = 0.6730, Precision = 0.5726, Recall = 0.8161, Support = 87.0\n",
      "bih: F1-score = 0.6728, Precision = 0.5407, Recall = 0.8902, Support = 82.0\n",
      "lat: F1-score = 0.6696, Precision = 0.5891, Recall = 0.7755, Support = 98.0\n",
      "ekk: F1-score = 0.6667, Precision = 0.6364, Recall = 0.7000, Support = 110.0\n",
      "iba: F1-score = 0.6667, Precision = 1.0000, Recall = 0.5000, Support = 2.0\n",
      "xmf: F1-score = 0.6667, Precision = 0.5314, Recall = 0.8942, Support = 104.0\n",
      "arb: F1-score = 0.6643, Precision = 0.5655, Recall = 0.8051, Support = 118.0\n",
      "pcd: F1-score = 0.6634, Precision = 0.6667, Recall = 0.6602, Support = 103.0\n",
      "zea: F1-score = 0.6627, Precision = 0.7000, Recall = 0.6292, Support = 89.0\n",
      "arz: F1-score = 0.6612, Precision = 0.6532, Recall = 0.6694, Support = 121.0\n",
      "nds: F1-score = 0.6606, Precision = 0.6348, Recall = 0.6887, Support = 106.0\n",
      "bsb: F1-score = 0.6602, Precision = 0.6733, Recall = 0.6476, Support = 105.0\n",
      "nld: F1-score = 0.6601, Precision = 0.6907, Recall = 0.6321, Support = 106.0\n",
      "hat: F1-score = 0.6600, Precision = 0.6804, Recall = 0.6408, Support = 103.0\n",
      "bew: F1-score = 0.6595, Precision = 0.7176, Recall = 0.6100, Support = 100.0\n",
      "guj: F1-score = 0.6585, Precision = 0.7068, Recall = 0.6164, Support = 219.0\n",
      "nbl: F1-score = 0.6570, Precision = 0.6239, Recall = 0.6939, Support = 98.0\n",
      "ckb: F1-score = 0.6492, Precision = 0.4877, Recall = 0.9706, Support = 102.0\n",
      "hne: F1-score = 0.6479, Precision = 0.6053, Recall = 0.6970, Support = 99.0\n",
      "hif: F1-score = 0.6473, Precision = 0.5826, Recall = 0.7283, Support = 92.0\n",
      "eng: F1-score = 0.6463, Precision = 0.5026, Recall = 0.9048, Support = 105.0\n",
      "kmr: F1-score = 0.6441, Precision = 0.5390, Recall = 0.8000, Support = 95.0\n",
      "amh: F1-score = 0.6377, Precision = 0.9362, Recall = 0.4835, Support = 91.0\n",
      "slv: F1-score = 0.6377, Precision = 0.5641, Recall = 0.7333, Support = 90.0\n",
      "lmo: F1-score = 0.6349, Precision = 0.5882, Recall = 0.6897, Support = 87.0\n",
      "mlg: F1-score = 0.6340, Precision = 0.5385, Recall = 0.7706, Support = 109.0\n",
      "fra: F1-score = 0.6332, Precision = 0.5888, Recall = 0.6848, Support = 92.0\n",
      "bjn: F1-score = 0.6325, Precision = 0.6167, Recall = 0.6491, Support = 114.0\n",
      "wln: F1-score = 0.6321, Precision = 0.5865, Recall = 0.6854, Support = 89.0\n",
      "glg: F1-score = 0.6304, Precision = 0.6304, Recall = 0.6304, Support = 92.0\n",
      "gsw: F1-score = 0.6289, Precision = 0.5701, Recall = 0.7011, Support = 87.0\n",
      "dan: F1-score = 0.6270, Precision = 0.6744, Recall = 0.5859, Support = 99.0\n",
      "tsn: F1-score = 0.6270, Precision = 0.6744, Recall = 0.5859, Support = 99.0\n",
      "bel: F1-score = 0.6196, Precision = 0.5938, Recall = 0.6477, Support = 88.0\n",
      "war: F1-score = 0.6182, Precision = 0.7727, Recall = 0.5152, Support = 99.0\n",
      "nya: F1-score = 0.6170, Precision = 0.6517, Recall = 0.5859, Support = 99.0\n",
      "mai: F1-score = 0.6165, Precision = 0.5375, Recall = 0.7227, Support = 119.0\n",
      "aka: F1-score = 0.6098, Precision = 0.7812, Recall = 0.5000, Support = 100.0\n",
      "prs: F1-score = 0.6071, Precision = 0.5271, Recall = 0.7158, Support = 95.0\n",
      "mar: F1-score = 0.6048, Precision = 0.4490, Recall = 0.9263, Support = 95.0\n",
      "kaa: F1-score = 0.6042, Precision = 0.8696, Recall = 0.4630, Support = 216.0\n",
      "rue: F1-score = 0.6034, Precision = 0.4636, Recall = 0.8642, Support = 81.0\n",
      "mri: F1-score = 0.6034, Precision = 0.7013, Recall = 0.5294, Support = 102.0\n",
      "srd: F1-score = 0.6030, Precision = 0.6742, Recall = 0.5455, Support = 110.0\n",
      "ile: F1-score = 0.5955, Precision = 0.7794, Recall = 0.4818, Support = 110.0\n",
      "nep: F1-score = 0.5926, Precision = 0.5039, Recall = 0.7191, Support = 89.0\n",
      "ber: F1-score = 0.5882, Precision = 0.7812, Recall = 0.4717, Support = 106.0\n",
      "est: F1-score = 0.5882, Precision = 0.6322, Recall = 0.5500, Support = 100.0\n",
      "scn: F1-score = 0.5877, Precision = 0.5826, Recall = 0.5929, Support = 113.0\n",
      "xho: F1-score = 0.5864, Precision = 0.6292, Recall = 0.5490, Support = 102.0\n",
      "run: F1-score = 0.5830, Precision = 0.4832, Recall = 0.7347, Support = 98.0\n",
      "lim: F1-score = 0.5820, Precision = 0.4830, Recall = 0.7320, Support = 97.0\n",
      "que: F1-score = 0.5806, Precision = 0.7258, Recall = 0.4839, Support = 93.0\n",
      "cbk: F1-score = 0.5773, Precision = 0.5490, Recall = 0.6087, Support = 92.0\n",
      "ory: F1-score = 0.5740, Precision = 0.4776, Recall = 0.7191, Support = 89.0\n",
      "gom: F1-score = 0.5714, Precision = 0.8367, Recall = 0.4339, Support = 189.0\n",
      "hyw: F1-score = 0.5714, Precision = 0.4286, Recall = 0.8571, Support = 7.0\n",
      "mah: F1-score = 0.5714, Precision = 0.6667, Recall = 0.5000, Support = 4.0\n",
      "uzb: F1-score = 0.5562, Precision = 0.6735, Recall = 0.4737, Support = 209.0\n",
      "sot: F1-score = 0.5500, Precision = 0.5789, Recall = 0.5238, Support = 105.0\n",
      "som: F1-score = 0.5484, Precision = 0.8095, Recall = 0.4146, Support = 205.0\n",
      "glk: F1-score = 0.5427, Precision = 0.5400, Recall = 0.5455, Support = 99.0\n",
      "kaz: F1-score = 0.5425, Precision = 0.3750, Recall = 0.9802, Support = 101.0\n",
      "urd: F1-score = 0.5405, Precision = 0.3980, Recall = 0.8421, Support = 95.0\n",
      "azj: F1-score = 0.5401, Precision = 0.4181, Recall = 0.7629, Support = 97.0\n",
      "pcm: F1-score = 0.5301, Precision = 0.8148, Recall = 0.3929, Support = 112.0\n",
      "jav: F1-score = 0.5263, Precision = 0.5446, Recall = 0.5093, Support = 108.0\n",
      "ell: F1-score = 0.5248, Precision = 0.9737, Recall = 0.3592, Support = 103.0\n",
      "ast: F1-score = 0.5236, Precision = 0.4114, Recall = 0.7200, Support = 100.0\n",
      "pes: F1-score = 0.5175, Precision = 0.4758, Recall = 0.5673, Support = 104.0\n",
      "oci: F1-score = 0.5124, Precision = 0.4133, Recall = 0.6739, Support = 92.0\n",
      "aym: F1-score = 0.5096, Precision = 0.6250, Recall = 0.4301, Support = 93.0\n",
      "uzn: F1-score = 0.5073, Precision = 0.3444, Recall = 0.9630, Support = 108.0\n",
      "ada: F1-score = 0.5000, Precision = 0.3333, Recall = 1.0000, Support = 1.0\n",
      "hau: F1-score = 0.5000, Precision = 0.7321, Recall = 0.3796, Support = 216.0\n",
      "niu: F1-score = 0.5000, Precision = 0.3333, Recall = 1.0000, Support = 1.0\n",
      "swa: F1-score = 0.4979, Precision = 0.4874, Recall = 0.5088, Support = 114.0\n",
      "crh: F1-score = 0.4945, Precision = 0.9571, Recall = 0.3333, Support = 201.0\n",
      "tat: F1-score = 0.4881, Precision = 0.5509, Recall = 0.4381, Support = 210.0\n",
      "mkd: F1-score = 0.4835, Precision = 0.3321, Recall = 0.8889, Support = 99.0\n",
      "sqi: F1-score = 0.4825, Precision = 0.4198, Recall = 0.5670, Support = 97.0\n",
      "swh: F1-score = 0.4793, Precision = 0.4522, Recall = 0.5098, Support = 102.0\n",
      "ita: F1-score = 0.4783, Precision = 0.4835, Recall = 0.4731, Support = 93.0\n",
      "ina: F1-score = 0.4762, Precision = 0.3871, Recall = 0.6186, Support = 97.0\n",
      "ltz: F1-score = 0.4701, Precision = 0.3986, Recall = 0.5729, Support = 96.0\n",
      "vec: F1-score = 0.4554, Precision = 0.3835, Recall = 0.5604, Support = 91.0\n",
      "sun: F1-score = 0.4500, Precision = 0.4839, Recall = 0.4206, Support = 107.0\n",
      "bcl: F1-score = 0.4428, Precision = 0.3727, Recall = 0.5455, Support = 110.0\n",
      "spa: F1-score = 0.4421, Precision = 0.4719, Recall = 0.4158, Support = 101.0\n",
      "kat: F1-score = 0.4357, Precision = 0.8592, Recall = 0.2919, Support = 209.0\n",
      "nde: F1-score = 0.4268, Precision = 0.4268, Recall = 0.4268, Support = 82.0\n",
      "bik: F1-score = 0.4211, Precision = 0.5161, Recall = 0.3556, Support = 90.0\n",
      "hbo: F1-score = 0.4211, Precision = 0.2667, Recall = 1.0000, Support = 4.0\n",
      "fil: F1-score = 0.4158, Precision = 0.3889, Recall = 0.4468, Support = 94.0\n",
      "sna: F1-score = 0.4151, Precision = 0.5789, Recall = 0.3235, Support = 102.0\n",
      "apc: F1-score = 0.4103, Precision = 0.3153, Recall = 0.5872, Support = 109.0\n",
      "ori: F1-score = 0.3949, Precision = 0.5536, Recall = 0.3069, Support = 101.0\n",
      "tgl: F1-score = 0.3902, Precision = 0.5333, Recall = 0.3077, Support = 104.0\n",
      "kin: F1-score = 0.3882, Precision = 0.3929, Recall = 0.3837, Support = 86.0\n",
      "nob: F1-score = 0.3673, Precision = 0.3789, Recall = 0.3564, Support = 101.0\n",
      "ban: F1-score = 0.3598, Precision = 0.4533, Recall = 0.2982, Support = 114.0\n",
      "ara: F1-score = 0.3545, Precision = 0.2328, Recall = 0.7431, Support = 109.0\n",
      "nor: F1-score = 0.3371, Precision = 0.3797, Recall = 0.3030, Support = 99.0\n",
      "enm: F1-score = 0.3333, Precision = 0.5000, Recall = 0.2500, Support = 4.0\n",
      "als: F1-score = 0.3191, Precision = 0.3333, Recall = 0.3061, Support = 98.0\n",
      "mad: F1-score = 0.3169, Precision = 0.3766, Recall = 0.2736, Support = 106.0\n",
      "zul: F1-score = 0.3169, Precision = 0.3222, Recall = 0.3118, Support = 93.0\n",
      "sco: F1-score = 0.3140, Precision = 0.2500, Recall = 0.4220, Support = 109.0\n",
      "cos: F1-score = 0.3113, Precision = 0.3300, Recall = 0.2946, Support = 112.0\n",
      "msa: F1-score = 0.3099, Precision = 0.2486, Recall = 0.4112, Support = 107.0\n",
      "hil: F1-score = 0.2857, Precision = 0.6000, Recall = 0.1875, Support = 16.0\n",
      "fas: F1-score = 0.2836, Precision = 0.5000, Recall = 0.1979, Support = 96.0\n",
      "zsm: F1-score = 0.2775, Precision = 0.2637, Recall = 0.2927, Support = 82.0\n",
      "ind: F1-score = 0.2771, Precision = 0.2911, Recall = 0.2644, Support = 87.0\n",
      "bos: F1-score = 0.2703, Precision = 0.2288, Recall = 0.3302, Support = 106.0\n",
      "bak: F1-score = 0.2691, Precision = 0.5441, Recall = 0.1787, Support = 207.0\n",
      "hrv: F1-score = 0.2639, Precision = 0.1872, Recall = 0.4471, Support = 85.0\n",
      "kur: F1-score = 0.2628, Precision = 0.5806, Recall = 0.1698, Support = 212.0\n",
      "ajp: F1-score = 0.2424, Precision = 0.3019, Recall = 0.2025, Support = 79.0\n",
      "san: F1-score = 0.2353, Precision = 0.6957, Recall = 0.1416, Support = 113.0\n",
      "ary: F1-score = 0.2339, Precision = 0.3030, Recall = 0.1905, Support = 105.0\n",
      "hrx: F1-score = 0.2286, Precision = 1.0000, Recall = 0.1290, Support = 31.0\n",
      "acm: F1-score = 0.2239, Precision = 0.3659, Recall = 0.1613, Support = 93.0\n",
      "aze: F1-score = 0.1818, Precision = 0.3467, Recall = 0.1232, Support = 211.0\n",
      "pam: F1-score = 0.1729, Precision = 0.1039, Recall = 0.5152, Support = 99.0\n",
      "afb: F1-score = 0.1678, Precision = 0.2609, Recall = 0.1237, Support = 97.0\n",
      "abk: F1-score = 0.1663, Precision = 0.0908, Recall = 0.9828, Support = 116.0\n",
      "hin: F1-score = 0.1564, Precision = 0.4318, Recall = 0.0955, Support = 199.0\n",
      "tgk: F1-score = 0.0762, Precision = 0.4444, Recall = 0.0417, Support = 288.0\n",
      "hbs: F1-score = 0.0541, Precision = 0.4286, Recall = 0.0288, Support = 208.0\n",
      "srp: F1-score = 0.0396, Precision = 0.4444, Recall = 0.0207, Support = 193.0\n",
      "kor: F1-score = 0.0198, Precision = 0.2000, Recall = 0.0104, Support = 96.0\n",
      "tha: F1-score = 0.0198, Precision = 0.2000, Recall = 0.0104, Support = 96.0\n",
      "cmn: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 88.0\n",
      "gaa: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "gil: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "iku: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 113.0\n",
      "jpn: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 98.0\n",
      "kan: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 92.0\n",
      "ksw: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 3.0\n",
      "lzh: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 101.0\n",
      "miq: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "ngl: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 3.0\n",
      "pan: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 119.0\n",
      "quz: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "teo: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "tvl: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "wbm: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "wuu: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 116.0\n",
      "yue: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 118.0\n",
      "zho: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 105.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Générer le rapport de classification sous forme de dictionnaire\n",
    "report = classification_report(y_val, predictions, target_names=filtered_target_names, output_dict=True)\n",
    "\n",
    "# Filtrer les classes (en excluant 'accuracy', 'macro avg', 'weighted avg')\n",
    "filtered_report = {label: metrics for label, metrics in report.items() if isinstance(metrics, dict)}\n",
    "\n",
    "# Trier les langues par F1-score de manière décroissante\n",
    "sorted_report = sorted(filtered_report.items(), key=lambda x: x[1]['f1-score'], reverse=True)\n",
    "\n",
    "# Afficher le rapport trié\n",
    "print(\"Classification Report (trié par F1-score décroissant):\\n\")\n",
    "for label, metrics in sorted_report:\n",
    "    print(f\"{label}: F1-score = {metrics['f1-score']:.4f}, Precision = {metrics['precision']:.4f}, Recall = {metrics['recall']:.4f}, Support = {metrics['support']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151638</th>\n",
       "      <td>Public</td>\n",
       "      <td>茂原市處日本千葉縣。</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73107</th>\n",
       "      <td>Public</td>\n",
       "      <td>此四者，當世數學之四則定義也。</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12069</th>\n",
       "      <td>Public</td>\n",
       "      <td>至於除夕，同賀新春，共食團年飯。亦制餃子、年糕、春捲等。</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171980</th>\n",
       "      <td>Public</td>\n",
       "      <td>可黎可足，諱赤祖德贊，又作克黎可足、徠巴贍、熱巴中。吐蕃贊普，建元彝泰。其在位時，吐蕃文武極...</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168788</th>\n",
       "      <td>Public</td>\n",
       "      <td>魏室於軍政之外，文學亦為大家。魏三祖皆有成於詩文，而至者為文帝弟植。謝靈運曰：「天下文才一石...</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48276</th>\n",
       "      <td>Public</td>\n",
       "      <td>方事故時，適有記者在場。《東京朝日新聞》採其說，旦朝報之。據報道，躓踐之後，憲兵、警察官分散...</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17778</th>\n",
       "      <td>Public</td>\n",
       "      <td>妹穆皇后莧</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137368</th>\n",
       "      <td>Public</td>\n",
       "      <td>阮氏大越本紀</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135298</th>\n",
       "      <td>Public</td>\n",
       "      <td>一月二十日者，公曆之二十日也，距歲暮餘三百又四十五日（閏年乃三百又四十六日）。</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170747</th>\n",
       "      <td>Public</td>\n",
       "      <td>卷二十二　行品</td>\n",
       "      <td>lzh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text Label\n",
       "151638  Public                                         茂原市處日本千葉縣。   lzh\n",
       "73107   Public                                    此四者，當世數學之四則定義也。   lzh\n",
       "12069   Public                       至於除夕，同賀新春，共食團年飯。亦制餃子、年糕、春捲等。   lzh\n",
       "171980  Public  可黎可足，諱赤祖德贊，又作克黎可足、徠巴贍、熱巴中。吐蕃贊普，建元彝泰。其在位時，吐蕃文武極...   lzh\n",
       "168788  Public  魏室於軍政之外，文學亦為大家。魏三祖皆有成於詩文，而至者為文帝弟植。謝靈運曰：「天下文才一石...   lzh\n",
       "...        ...                                                ...   ...\n",
       "48276   Public  方事故時，適有記者在場。《東京朝日新聞》採其說，旦朝報之。據報道，躓踐之後，憲兵、警察官分散...   lzh\n",
       "17778   Public                                              妹穆皇后莧   lzh\n",
       "137368  Public                                             阮氏大越本紀   lzh\n",
       "135298  Public            一月二十日者，公曆之二十日也，距歲暮餘三百又四十五日（閏年乃三百又四十六日）。   lzh\n",
       "170747  Public                                            卷二十二　行品   lzh\n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[val_set['Label'] == \"lzh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième approche avec SentencePiece comme tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération d'un fichier brut .txt pour entraîner SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimal_preprocessing(text):\n",
    "    # Convertir en minuscules\n",
    "    text = text.lower()\n",
    "    # Supprimer les espaces excédentaires\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190599/190599 [00:02<00:00, 76582.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus enregistré : corpus_multilingue.txt, avec 190599 phrases.\n"
     ]
    }
   ],
   "source": [
    "# Extraire uniquement la colonne \"Text\"\n",
    "corpus_path = \"corpus_multilingue.txt\"  # Chemin de sortie pour le corpus\n",
    "data_train_preprocessed_for_corpus = data_train.copy()\n",
    "data_train_preprocessed_for_corpus = pre_processing(data_train_preprocessed_for_corpus, remove_espace=False, not_test=True, need_to_clean=True)\n",
    "data_train_preprocessed_for_corpus[\"Text\"].dropna().to_csv(corpus_path, index=False, header=False, sep=\"\\n\")\n",
    "\n",
    "print(f\"Corpus enregistré : {corpus_path}, avec {len(data_train)} phrases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement de SentencePiece et chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/corpus_multilingue.txt\n",
      "  input_format: \n",
      "  model_prefix: sp_model\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 60000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ./data/corpus_multilingue.txt\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (8498 > 4192).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 190432 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 167 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=21355447\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=2357\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 190431 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=9950123\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 1002357 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 190431\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 1062486\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 1062486 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=553592 obj=19.0602 num_tokens=2396710 num_tokens/piece=4.32938\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=478769 obj=17.7755 num_tokens=2405634 num_tokens/piece=5.02462\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=358764 obj=17.8094 num_tokens=2485532 num_tokens/piece=6.92804\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=357900 obj=17.7342 num_tokens=2486802 num_tokens/piece=6.94832\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=268332 obj=17.987 num_tokens=2614517 num_tokens/piece=9.74359\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=268257 obj=17.8963 num_tokens=2615825 num_tokens/piece=9.75119\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=201178 obj=18.2846 num_tokens=2764109 num_tokens/piece=13.7396\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=201170 obj=18.1696 num_tokens=2765114 num_tokens/piece=13.7452\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=150872 obj=18.6421 num_tokens=2917690 num_tokens/piece=19.3388\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=150871 obj=18.5209 num_tokens=2917974 num_tokens/piece=19.3409\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=113152 obj=19.0453 num_tokens=3073140 num_tokens/piece=27.1594\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=113152 obj=18.9263 num_tokens=3073493 num_tokens/piece=27.1625\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=84864 obj=19.4952 num_tokens=3231495 num_tokens/piece=38.0785\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=84864 obj=19.3773 num_tokens=3232020 num_tokens/piece=38.0847\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=66000 obj=19.8962 num_tokens=3369740 num_tokens/piece=51.0567\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=66000 obj=19.7943 num_tokens=3370431 num_tokens/piece=51.0671\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: sp_model.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: sp_model.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input='./data/corpus_multilingue.txt',  \n",
    "    model_prefix='sp_model',\n",
    "    vocab_size=60000,  \n",
    "    character_coverage=1.0,  \n",
    "    model_type='unigram'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='sp_model.model')\n",
    "\n",
    "def sentencepiece_tokenize(text):\n",
    "    \"\"\"Tokenise un texte en sous-mots avec SentencePiece\"\"\"\n",
    "    return ' '.join(sp.encode(text, out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_second_version = train_set.copy()\n",
    "val_set_second_version = val_set.copy()\n",
    "# train_set_second_version = pre_processing(train_set_second_version, remove_espace=False, not_test=True, need_to_clean=False)\n",
    "# val_set_second_version = pre_processing(val_set_second_version, remove_espace=False, not_test=True, need_to_clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "\n",
    "# Catégorisation fine des scripts\n",
    "SCRIPT_MAP = {\n",
    "    \"LATIN\": \"Latin\",\n",
    "    \"CYRILLIC\": \"Cyrillique\",\n",
    "    \"ARABIC\": \"Arabe\",\n",
    "    \"HEBREW\": \"Hébreu\",\n",
    "    \"GREEK\": \"Grec\",\n",
    "    \"DEVANAGARI\": \"Devanagari (Hindi, Sanskrit)\",\n",
    "    \"HIRAGANA\": \"Hiragana (Japonais)\",\n",
    "    \"KATAKANA\": \"Katakana (Japonais)\",\n",
    "    \"CJK\": \"Kanji (Chinois, Japonais, Coréen)\",\n",
    "    \"HANGUL\": \"Hangul (Coréen)\",\n",
    "    \"THAI\": \"Thaï\",\n",
    "    \"ARMENIAN\": \"Arménien\",\n",
    "    \"GEORGIAN\": \"Géorgien\",\n",
    "    \"ETHIOPIC\": \"Éthiopien\",\n",
    "    \"TAMIL\": \"Tamoul\",\n",
    "    \"BENGALI\": \"Bengali\",\n",
    "    \"TELUGU\": \"Télougou\",\n",
    "}\n",
    "\n",
    "def count_alphabet_characters(text):\n",
    "    script_counts = defaultdict(int)\n",
    "\n",
    "    for char in text:\n",
    "        if char.isalpha():  # On ignore les symboles et ponctuations\n",
    "            try:\n",
    "                char_name = unicodedata.name(char)  # Ex: 'LATIN CAPITAL LETTER A'\n",
    "                script_key = char_name.split()[0]  # Prend le premier mot du nom Unicode\n",
    "                \n",
    "                if \"CJK\" in char_name:\n",
    "                    script_key = \"CJK\"  # Les kanji sont classés sous \"CJK UNIFIED IDEOGRAPH\"\n",
    "                \n",
    "                script_name = SCRIPT_MAP.get(script_key, script_key)  # Utilise le mapping ou garde l'original\n",
    "                script_counts[script_name] += 1  # Incrémente le compteur\n",
    "                \n",
    "            except ValueError:\n",
    "                continue  # Si le caractère n'a pas de nom Unicode\n",
    "    \n",
    "    return dict(script_counts)  # Retourne un dictionnaire des comptages\n",
    "\n",
    "def most_frequent_script(text):\n",
    "    script_counts = count_alphabet_characters(text)  # Appel de la fonction précédente\n",
    "    \n",
    "    if script_counts:  # Vérifie si le dictionnaire n'est pas vide\n",
    "        most_common_script = max(script_counts.items(), key=lambda x: x[1])  # Trouve l'alphabet avec le max de caractères\n",
    "        return most_common_script  # Retourne (nom de l'alphabet, nombre d'occurrences)\n",
    "    else:\n",
    "        return None  # Retourne None si aucun alphabet trouvé\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def add_alphabet_to_label(df):\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):  # Parcourt chaque ligne du DataFrame\n",
    "        alphabet_most_frequent = most_frequent_script(row['Text'])  # Détecte l'alphabet dominant\n",
    "        \n",
    "        if alphabet_most_frequent:  # Vérifie si un alphabet a été trouvé\n",
    "            df.at[index, 'Label'] = f\"{row['Label']}_{alphabet_most_frequent[0]}\"  # Met à jour le label\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152079/152079 [00:12<00:00, 12465.21it/s]\n",
      "100%|██████████| 38020/38020 [00:03<00:00, 12228.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set_second_version = add_alphabet_to_label(train_set_second_version)\n",
    "val_set_second_version = add_alphabet_to_label(val_set_second_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152079/152079 [00:07<00:00, 20590.64it/s]\n",
      "100%|██████████| 38020/38020 [00:01<00:00, 20673.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Appliquer SentencePiece à ton dataset\n",
    "train_set_second_version['Text'] = train_set_second_version['Text'].progress_apply(sentencepiece_tokenize)\n",
    "val_set_second_version['Text'] = val_set_second_version['Text'].progress_apply(sentencepiece_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-15 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-15 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-15 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-15 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-15 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-15 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-15 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-15 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-15 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000, ngram_range=(1, 4))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.001, fit_prior=False)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char', max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                ('mnb', MultinomialNB(alpha=0.001, fit_prior=False))])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer_sp = TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4), max_features=200000)\n",
    "naive_bayes_sp = MultinomialNB(alpha= 0.001, fit_prior = False) \n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer_sp),\n",
    "    ('mnb', naive_bayes_sp)\n",
    "])\n",
    "\n",
    "x_train_sp = train_set_second_version['Text'].tolist()\n",
    "y_train_sp = train_set_second_version['Label'].tolist()\n",
    "x_val_sp = val_set_second_version['Text'].tolist()\n",
    "y_val_sp = val_set_second_version['Label'].tolist()\n",
    "y_total_sp = y_train_sp + y_val_sp\n",
    "\n",
    "# converting categorical variables to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_sp = LabelEncoder()\n",
    "le_sp.fit(y_total_sp)\n",
    "\n",
    "y_train_sp = le_sp.transform(y_train_sp)\n",
    "y_val_sp = le_sp.transform(y_val_sp)\n",
    "label_mapping = dict(zip(le_sp.classes_, range(len(le_sp.classes_))))\n",
    "\n",
    "\n",
    "pipeline.fit(x_train_sp, y_train_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8501841136244082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "predictions_sp = pipeline.predict(x_val_sp)\n",
    "accuracy_sp = accuracy_score(y_val_sp, predictions_sp)\n",
    "print(\"Accuracy:\", accuracy_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_sp = le_sp.inverse_transform(predictions_sp)\n",
    "labels_to_predict = le_sp.inverse_transform(y_val_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def restore_original_label(label):\n",
    "    return label.split(\"_\")[0]  # Prend seulement la première partie avant '_'\n",
    "\n",
    "def restore_labels(liste):\n",
    "    new_liste = []\n",
    "    for element in tqdm(liste): \n",
    "        new_liste.append(restore_original_label(element))\n",
    "    return np.array(new_liste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38020/38020 [00:00<00:00, 997269.85it/s]\n",
      "100%|██████████| 38020/38020 [00:00<00:00, 493087.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8521304576538664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_prediction = restore_labels(predicted_labels_sp)\n",
    "val_to_predict = restore_labels(labels_to_predict)\n",
    "final_accuracy = accuracy_score(val_to_predict, final_prediction)\n",
    "print(\"Accuracy:\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_classes_sp = np.unique(np.concatenate((y_val_sp, predictions_sp)))\n",
    "\n",
    "# Extraire uniquement les noms correspondants\n",
    "filtered_target_names_sp = [le_sp.classes_[i] for i in present_classes_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (trié par F1-score décroissant):\n",
      "\n",
      "abk_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 116.0\n",
      "ach_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 22.0\n",
      "ada_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "ahk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 89.0\n",
      "alt_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "aoj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "arn_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "asm_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 99.0\n",
      "bpy_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "bqc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "bzj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 104.0\n",
      "cab_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 83.0\n",
      "cak_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 103.0\n",
      "chk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "csy_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 120.0\n",
      "ctu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "cuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "div_THAANA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "djk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 87.0\n",
      "gom_Devanagari (Hindi, Sanskrit): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "guc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "hbo_Hébreu: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 4.0\n",
      "hnj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 5.0\n",
      "hui_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 85.0\n",
      "hus_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "ikk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 92.0\n",
      "iku_CANADIAN: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "ixl_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "kal_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "kan_KANNADA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 92.0\n",
      "kjb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "kjh_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 100.0\n",
      "knv_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "ksw_MYANMAR: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 3.0\n",
      "lhu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 39.0\n",
      "mah_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 4.0\n",
      "mal_MALAYALAM: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "mam_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 109.0\n",
      "mau_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 104.0\n",
      "mco_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 108.0\n",
      "mgh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "mos_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 92.0\n",
      "mps_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 89.0\n",
      "mzh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 99.0\n",
      "naq_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 111.0\n",
      "nav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "nch_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "ncj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "ngu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "nnb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 108.0\n",
      "ote_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 91.0\n",
      "pan_GURMUKHI: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 119.0\n",
      "poh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "pon_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "qub_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 6.0\n",
      "qvi_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "rop_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "srm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "suz_Devanagari (Hindi, Sanskrit): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 116.0\n",
      "tbz_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "tca_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 91.0\n",
      "tdt_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 77.0\n",
      "tlh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "toj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 107.0\n",
      "tok_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 111.0\n",
      "top_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "tuc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "tuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 117.0\n",
      "tzo_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 97.0\n",
      "uig_Arabe: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "umb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "xav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 108.0\n",
      "yao_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "yap_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "yom_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 106.0\n",
      "zai_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 111.0\n",
      "wal_Latin: F1-score = 0.9956, Precision = 0.9912, Recall = 1.0000, Support = 112.0\n",
      "guj_GUJARATI: F1-score = 0.9955, Precision = 1.0000, Recall = 0.9910, Support = 111.0\n",
      "ksd_Latin: F1-score = 0.9954, Precision = 0.9909, Recall = 1.0000, Support = 109.0\n",
      "kac_Latin: F1-score = 0.9953, Precision = 0.9907, Recall = 1.0000, Support = 107.0\n",
      "luo_Latin: F1-score = 0.9953, Precision = 0.9907, Recall = 1.0000, Support = 107.0\n",
      "kpg_Latin: F1-score = 0.9953, Precision = 1.0000, Recall = 0.9907, Support = 107.0\n",
      "kos_Latin: F1-score = 0.9953, Precision = 1.0000, Recall = 0.9906, Support = 106.0\n",
      "sgs_Latin: F1-score = 0.9952, Precision = 1.0000, Recall = 0.9904, Support = 104.0\n",
      "lvs_Latin: F1-score = 0.9951, Precision = 0.9903, Recall = 1.0000, Support = 102.0\n",
      "tam_Tamoul: F1-score = 0.9951, Precision = 0.9903, Recall = 1.0000, Support = 102.0\n",
      "quw_Latin: F1-score = 0.9950, Precision = 1.0000, Recall = 0.9901, Support = 101.0\n",
      "seh_Latin: F1-score = 0.9949, Precision = 1.0000, Recall = 0.9898, Support = 98.0\n",
      "cjk_Latin: F1-score = 0.9948, Precision = 0.9897, Recall = 1.0000, Support = 96.0\n",
      "rug_Latin: F1-score = 0.9948, Precision = 0.9896, Recall = 1.0000, Support = 95.0\n",
      "ewe_Latin: F1-score = 0.9947, Precision = 1.0000, Recall = 0.9895, Support = 95.0\n",
      "lus_Latin: F1-score = 0.9947, Precision = 1.0000, Recall = 0.9895, Support = 95.0\n",
      "fon_Latin: F1-score = 0.9947, Precision = 1.0000, Recall = 0.9894, Support = 94.0\n",
      "kek_Latin: F1-score = 0.9947, Precision = 1.0000, Recall = 0.9894, Support = 94.0\n",
      "sat_OL: F1-score = 0.9947, Precision = 0.9894, Recall = 1.0000, Support = 93.0\n",
      "gym_Latin: F1-score = 0.9945, Precision = 1.0000, Recall = 0.9891, Support = 92.0\n",
      "kmb_Latin: F1-score = 0.9945, Precision = 1.0000, Recall = 0.9890, Support = 91.0\n",
      "nyu_Latin: F1-score = 0.9945, Precision = 0.9890, Recall = 1.0000, Support = 90.0\n",
      "sin_SINHALA: F1-score = 0.9944, Precision = 0.9888, Recall = 1.0000, Support = 88.0\n",
      "bem_Latin: F1-score = 0.9942, Precision = 1.0000, Recall = 0.9884, Support = 86.0\n",
      "pls_Latin: F1-score = 0.9937, Precision = 1.0000, Recall = 0.9875, Support = 80.0\n",
      "kbp_Latin: F1-score = 0.9908, Precision = 0.9818, Recall = 1.0000, Support = 108.0\n",
      "kir_Cyrillique: F1-score = 0.9908, Precision = 0.9908, Recall = 0.9908, Support = 109.0\n",
      "sag_Latin: F1-score = 0.9907, Precision = 0.9907, Recall = 0.9907, Support = 108.0\n",
      "kbd_Cyrillique: F1-score = 0.9905, Precision = 1.0000, Recall = 0.9811, Support = 106.0\n",
      "ndo_Latin: F1-score = 0.9903, Precision = 0.9903, Recall = 0.9903, Support = 103.0\n",
      "xmf_Géorgien: F1-score = 0.9903, Precision = 1.0000, Recall = 0.9808, Support = 104.0\n",
      "che_Cyrillique: F1-score = 0.9899, Precision = 1.0000, Recall = 0.9800, Support = 100.0\n",
      "lua_Latin: F1-score = 0.9898, Precision = 0.9798, Recall = 1.0000, Support = 97.0\n",
      "mon_Cyrillique: F1-score = 0.9898, Precision = 0.9798, Recall = 1.0000, Support = 97.0\n",
      "snd_Arabe: F1-score = 0.9898, Precision = 0.9898, Recall = 0.9898, Support = 98.0\n",
      "vol_Latin: F1-score = 0.9896, Precision = 1.0000, Recall = 0.9794, Support = 97.0\n",
      "kor_Hangul (Coréen): F1-score = 0.9895, Precision = 1.0000, Recall = 0.9792, Support = 96.0\n",
      "tha_Thaï: F1-score = 0.9895, Precision = 0.9792, Recall = 1.0000, Support = 94.0\n",
      "gom_Latin: F1-score = 0.9894, Precision = 1.0000, Recall = 0.9789, Support = 95.0\n",
      "mya_MYANMAR: F1-score = 0.9894, Precision = 0.9789, Recall = 1.0000, Support = 93.0\n",
      "hun_Latin: F1-score = 0.9891, Precision = 0.9785, Recall = 1.0000, Support = 91.0\n",
      "kam_Latin: F1-score = 0.9884, Precision = 1.0000, Recall = 0.9770, Support = 87.0\n",
      "srn_Latin: F1-score = 0.9882, Precision = 1.0000, Recall = 0.9767, Support = 86.0\n",
      "pap_Latin: F1-score = 0.9873, Precision = 1.0000, Recall = 0.9750, Support = 120.0\n",
      "vie_Latin: F1-score = 0.9867, Precision = 0.9867, Recall = 0.9867, Support = 75.0\n",
      "tso_Latin: F1-score = 0.9864, Precision = 0.9820, Recall = 0.9909, Support = 110.0\n",
      "sah_Cyrillique: F1-score = 0.9858, Precision = 0.9905, Recall = 0.9811, Support = 106.0\n",
      "orm_Latin: F1-score = 0.9852, Precision = 0.9804, Recall = 0.9901, Support = 101.0\n",
      "jbo_Latin: F1-score = 0.9849, Precision = 1.0000, Recall = 0.9703, Support = 101.0\n",
      "kik_Latin: F1-score = 0.9843, Precision = 1.0000, Recall = 0.9691, Support = 97.0\n",
      "yid_Hébreu: F1-score = 0.9838, Precision = 0.9785, Recall = 0.9891, Support = 92.0\n",
      "krc_Cyrillique: F1-score = 0.9829, Precision = 0.9914, Recall = 0.9746, Support = 118.0\n",
      "meu_Latin: F1-score = 0.9823, Precision = 0.9823, Recall = 0.9823, Support = 113.0\n",
      "lit_Latin: F1-score = 0.9820, Precision = 0.9732, Recall = 0.9909, Support = 110.0\n",
      "heb_Hébreu: F1-score = 0.9814, Precision = 0.9875, Recall = 0.9753, Support = 81.0\n",
      "kat_Géorgien: F1-score = 0.9800, Precision = 0.9703, Recall = 0.9899, Support = 99.0\n",
      "kaz_Cyrillique: F1-score = 0.9798, Precision = 1.0000, Recall = 0.9604, Support = 101.0\n",
      "dtp_Latin: F1-score = 0.9792, Precision = 0.9792, Recall = 0.9792, Support = 96.0\n",
      "mar_Devanagari (Hindi, Sanskrit): F1-score = 0.9789, Precision = 0.9789, Recall = 0.9789, Support = 95.0\n",
      "eus_Latin: F1-score = 0.9783, Precision = 0.9890, Recall = 0.9677, Support = 93.0\n",
      "new_Devanagari (Hindi, Sanskrit): F1-score = 0.9778, Precision = 1.0000, Recall = 0.9565, Support = 115.0\n",
      "gug_Latin: F1-score = 0.9770, Precision = 0.9725, Recall = 0.9815, Support = 108.0\n",
      "roh_Latin: F1-score = 0.9763, Precision = 0.9904, Recall = 0.9626, Support = 107.0\n",
      "khm_KHMER: F1-score = 0.9747, Precision = 0.9506, Recall = 1.0000, Support = 77.0\n",
      "fin_Latin: F1-score = 0.9741, Precision = 0.9691, Recall = 0.9792, Support = 96.0\n",
      "grc_Grec: F1-score = 0.9735, Precision = 1.0000, Recall = 0.9485, Support = 97.0\n",
      "szl_Latin: F1-score = 0.9735, Precision = 0.9787, Recall = 0.9684, Support = 95.0\n",
      "oss_Cyrillique: F1-score = 0.9724, Precision = 1.0000, Recall = 0.9462, Support = 93.0\n",
      "ell_Grec: F1-score = 0.9717, Precision = 0.9450, Recall = 1.0000, Support = 103.0\n",
      "quh_Latin: F1-score = 0.9711, Precision = 0.9438, Recall = 1.0000, Support = 84.0\n",
      "crh_Latin: F1-score = 0.9709, Precision = 0.9901, Recall = 0.9524, Support = 105.0\n",
      "fij_Latin: F1-score = 0.9709, Precision = 0.9615, Recall = 0.9804, Support = 102.0\n",
      "hmo_Latin: F1-score = 0.9708, Precision = 0.9651, Recall = 0.9765, Support = 85.0\n",
      "sme_Latin: F1-score = 0.9703, Precision = 1.0000, Recall = 0.9423, Support = 104.0\n",
      "isl_Latin: F1-score = 0.9688, Precision = 0.9588, Recall = 0.9789, Support = 95.0\n",
      "tpi_Latin: F1-score = 0.9670, Precision = 0.9888, Recall = 0.9462, Support = 93.0\n",
      "fur_Latin: F1-score = 0.9662, Precision = 0.9901, Recall = 0.9434, Support = 106.0\n",
      "ces_Latin: F1-score = 0.9659, Precision = 0.9612, Recall = 0.9706, Support = 102.0\n",
      "udm_Cyrillique: F1-score = 0.9652, Precision = 0.9798, Recall = 0.9510, Support = 102.0\n",
      "acr_Latin: F1-score = 0.9645, Precision = 0.9794, Recall = 0.9500, Support = 100.0\n",
      "glv_Latin: F1-score = 0.9645, Precision = 0.9596, Recall = 0.9694, Support = 98.0\n",
      "tir_Éthiopien: F1-score = 0.9645, Precision = 0.9406, Recall = 0.9896, Support = 96.0\n",
      "vep_Latin: F1-score = 0.9634, Precision = 0.9787, Recall = 0.9485, Support = 97.0\n",
      "quc_Latin: F1-score = 0.9633, Precision = 0.9459, Recall = 0.9813, Support = 107.0\n",
      "csb_Latin: F1-score = 0.9630, Precision = 0.9750, Recall = 0.9512, Support = 82.0\n",
      "azb_Arabe: F1-score = 0.9626, Precision = 0.9450, Recall = 0.9810, Support = 105.0\n",
      "fao_Latin: F1-score = 0.9626, Precision = 0.9810, Recall = 0.9450, Support = 109.0\n",
      "pms_Latin: F1-score = 0.9613, Precision = 1.0000, Recall = 0.9255, Support = 94.0\n",
      "lug_Latin: F1-score = 0.9612, Precision = 0.9706, Recall = 0.9519, Support = 104.0\n",
      "amh_Éthiopien: F1-score = 0.9605, Precision = 0.9884, Recall = 0.9341, Support = 91.0\n",
      "frr_Latin: F1-score = 0.9596, Precision = 0.9896, Recall = 0.9314, Support = 102.0\n",
      "kom_Cyrillique: F1-score = 0.9588, Precision = 0.9894, Recall = 0.9300, Support = 100.0\n",
      "epo_Latin: F1-score = 0.9581, Precision = 0.9877, Recall = 0.9302, Support = 86.0\n",
      "cym_Latin: F1-score = 0.9579, Precision = 0.9681, Recall = 0.9479, Support = 96.0\n",
      "kea_Latin: F1-score = 0.9570, Precision = 0.9674, Recall = 0.9468, Support = 94.0\n",
      "slk_Latin: F1-score = 0.9557, Precision = 0.9510, Recall = 0.9604, Support = 101.0\n",
      "hye_Arménien: F1-score = 0.9545, Precision = 0.9130, Recall = 1.0000, Support = 84.0\n",
      "eml_Latin: F1-score = 0.9537, Precision = 0.9810, Recall = 0.9279, Support = 111.0\n",
      "ace_Latin: F1-score = 0.9524, Precision = 0.9804, Recall = 0.9259, Support = 108.0\n",
      "kon_Latin: F1-score = 0.9524, Precision = 0.9677, Recall = 0.9375, Support = 96.0\n",
      "tyv_Cyrillique: F1-score = 0.9524, Precision = 0.9910, Recall = 0.9167, Support = 120.0\n",
      "tum_Latin: F1-score = 0.9514, Precision = 0.9670, Recall = 0.9362, Support = 94.0\n",
      "mhr_Cyrillique: F1-score = 0.9500, Precision = 0.9406, Recall = 0.9596, Support = 99.0\n",
      "kaa_Latin: F1-score = 0.9493, Precision = 0.9904, Recall = 0.9115, Support = 113.0\n",
      "tur_Latin: F1-score = 0.9485, Precision = 0.9388, Recall = 0.9583, Support = 96.0\n",
      "afr_Latin: F1-score = 0.9484, Precision = 0.9712, Recall = 0.9266, Support = 109.0\n",
      "bul_Cyrillique: F1-score = 0.9479, Precision = 0.9381, Recall = 0.9579, Support = 95.0\n",
      "grn_Latin: F1-score = 0.9479, Precision = 0.9709, Recall = 0.9259, Support = 108.0\n",
      "ssw_Latin: F1-score = 0.9479, Precision = 0.9709, Recall = 0.9259, Support = 108.0\n",
      "gcf_Latin: F1-score = 0.9474, Precision = 1.0000, Recall = 0.9000, Support = 30.0\n",
      "aln_Latin: F1-score = 0.9450, Precision = 0.9115, Recall = 0.9810, Support = 105.0\n",
      "chv_Cyrillique: F1-score = 0.9444, Precision = 1.0000, Recall = 0.8947, Support = 95.0\n",
      "swe_Latin: F1-score = 0.9437, Precision = 0.9397, Recall = 0.9478, Support = 115.0\n",
      "mkd_Cyrillique: F1-score = 0.9430, Precision = 0.9681, Recall = 0.9192, Support = 99.0\n",
      "lin_Latin: F1-score = 0.9418, Precision = 0.9889, Recall = 0.8990, Support = 99.0\n",
      "npi_Devanagari (Hindi, Sanskrit): F1-score = 0.9406, Precision = 0.9626, Recall = 0.9196, Support = 112.0\n",
      "gle_Latin: F1-score = 0.9400, Precision = 0.9038, Recall = 0.9792, Support = 96.0\n",
      "mai_Devanagari (Hindi, Sanskrit): F1-score = 0.9386, Precision = 0.9727, Recall = 0.9068, Support = 118.0\n",
      "mwl_Latin: F1-score = 0.9366, Precision = 0.9412, Recall = 0.9320, Support = 103.0\n",
      "slv_Latin: F1-score = 0.9364, Precision = 0.9759, Recall = 0.9000, Support = 90.0\n",
      "crh_Cyrillique: F1-score = 0.9333, Precision = 1.0000, Recall = 0.8750, Support = 96.0\n",
      "ilo_Latin: F1-score = 0.9333, Precision = 0.9633, Recall = 0.9052, Support = 116.0\n",
      "lao_LAO: F1-score = 0.9333, Precision = 0.8835, Recall = 0.9891, Support = 92.0\n",
      "diq_Latin: F1-score = 0.9326, Precision = 0.9881, Recall = 0.8830, Support = 94.0\n",
      "ksh_Latin: F1-score = 0.9321, Precision = 0.9364, Recall = 0.9279, Support = 111.0\n",
      "hsb_Latin: F1-score = 0.9320, Precision = 0.9505, Recall = 0.9143, Support = 105.0\n",
      "pus_Arabe: F1-score = 0.9307, Precision = 0.9592, Recall = 0.9038, Support = 104.0\n",
      "pol_Latin: F1-score = 0.9305, Precision = 0.8700, Recall = 1.0000, Support = 87.0\n",
      "bis_Latin: F1-score = 0.9292, Precision = 0.9633, Recall = 0.8974, Support = 117.0\n",
      "lfn_Latin: F1-score = 0.9282, Precision = 0.9545, Recall = 0.9032, Support = 93.0\n",
      "arz_Arabe: F1-score = 0.9264, Precision = 0.9727, Recall = 0.8843, Support = 121.0\n",
      "jam_Latin: F1-score = 0.9259, Precision = 0.9615, Recall = 0.8929, Support = 112.0\n",
      "dyu_Latin: F1-score = 0.9246, Precision = 0.8846, Recall = 0.9684, Support = 95.0\n",
      "gla_Latin: F1-score = 0.9223, Precision = 0.9889, Recall = 0.8641, Support = 103.0\n",
      "ven_Latin: F1-score = 0.9222, Precision = 1.0000, Recall = 0.8557, Support = 97.0\n",
      "pis_Latin: F1-score = 0.9189, Precision = 0.8500, Recall = 1.0000, Support = 34.0\n",
      "mzn_Arabe: F1-score = 0.9180, Precision = 0.9438, Recall = 0.8936, Support = 94.0\n",
      "ukr_Cyrillique: F1-score = 0.9175, Precision = 0.9082, Recall = 0.9271, Support = 96.0\n",
      "yor_Latin: F1-score = 0.9175, Precision = 0.9889, Recall = 0.8558, Support = 104.0\n",
      "por_Latin: F1-score = 0.9167, Precision = 0.9263, Recall = 0.9072, Support = 97.0\n",
      "san_Devanagari (Hindi, Sanskrit): F1-score = 0.9159, Precision = 0.8448, Recall = 1.0000, Support = 98.0\n",
      "ful_Latin: F1-score = 0.9158, Precision = 0.9775, Recall = 0.8614, Support = 101.0\n",
      "hne_Devanagari (Hindi, Sanskrit): F1-score = 0.9158, Precision = 0.9255, Recall = 0.9062, Support = 96.0\n",
      "quy_Latin: F1-score = 0.9149, Precision = 0.8515, Recall = 0.9885, Support = 87.0\n",
      "bre_Latin: F1-score = 0.9126, Precision = 0.9400, Recall = 0.8868, Support = 106.0\n",
      "bih_Devanagari (Hindi, Sanskrit): F1-score = 0.9112, Precision = 0.8851, Recall = 0.9390, Support = 82.0\n",
      "pnb_Arabe: F1-score = 0.9107, Precision = 0.8870, Recall = 0.9358, Support = 109.0\n",
      "ido_Latin: F1-score = 0.9101, Precision = 0.9149, Recall = 0.9053, Support = 95.0\n",
      "tah_Latin: F1-score = 0.9100, Precision = 0.9891, Recall = 0.8426, Support = 108.0\n",
      "ceb_Latin: F1-score = 0.9070, Precision = 0.9398, Recall = 0.8764, Support = 89.0\n",
      "rap_Latin: F1-score = 0.9067, Precision = 1.0000, Recall = 0.8293, Support = 41.0\n",
      "cat_Latin: F1-score = 0.9029, Precision = 0.8857, Recall = 0.9208, Support = 101.0\n",
      "kaa_Cyrillique: F1-score = 0.8995, Precision = 0.9884, Recall = 0.8252, Support = 103.0\n",
      "rmy_Latin: F1-score = 0.8995, Precision = 0.9659, Recall = 0.8416, Support = 101.0\n",
      "lij_Latin: F1-score = 0.8980, Precision = 0.8980, Recall = 0.8980, Support = 98.0\n",
      "fry_Latin: F1-score = 0.8972, Precision = 0.9600, Recall = 0.8421, Support = 114.0\n",
      "min_Latin: F1-score = 0.8966, Precision = 0.9070, Recall = 0.8864, Support = 88.0\n",
      "ibo_Latin: F1-score = 0.8953, Precision = 0.9872, Recall = 0.8191, Support = 94.0\n",
      "lat_Latin: F1-score = 0.8934, Precision = 0.8889, Recall = 0.8980, Support = 98.0\n",
      "bam_Latin: F1-score = 0.8925, Precision = 0.9540, Recall = 0.8384, Support = 99.0\n",
      "bod_TIBETAN: F1-score = 0.8923, Precision = 0.8529, Recall = 0.9355, Support = 93.0\n",
      "dzo_TIBETAN: F1-score = 0.8922, Precision = 0.8922, Recall = 0.8922, Support = 102.0\n",
      "pag_Latin: F1-score = 0.8866, Precision = 0.9773, Recall = 0.8113, Support = 106.0\n",
      "ron_Latin: F1-score = 0.8856, Precision = 0.8396, Recall = 0.9368, Support = 95.0\n",
      "lzh_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8826, Precision = 0.8393, Recall = 0.9307, Support = 101.0\n",
      "ile_Latin: F1-score = 0.8804, Precision = 0.9293, Recall = 0.8364, Support = 110.0\n",
      "vls_Latin: F1-score = 0.8804, Precision = 0.8519, Recall = 0.9109, Support = 101.0\n",
      "tls_Latin: F1-score = 0.8772, Precision = 0.9868, Recall = 0.7895, Support = 95.0\n",
      "arg_Latin: F1-score = 0.8750, Precision = 0.8376, Recall = 0.9159, Support = 107.0\n",
      "mon_Latin: F1-score = 0.8750, Precision = 0.9625, Recall = 0.8021, Support = 96.0\n",
      "myv_Cyrillique: F1-score = 0.8722, Precision = 0.8319, Recall = 0.9167, Support = 108.0\n",
      "ton_Latin: F1-score = 0.8715, Precision = 0.8966, Recall = 0.8478, Support = 92.0\n",
      "ext_Latin: F1-score = 0.8704, Precision = 0.8785, Recall = 0.8624, Support = 109.0\n",
      "ayr_Latin: F1-score = 0.8700, Precision = 0.8017, Recall = 0.9510, Support = 102.0\n",
      "nep_Devanagari (Hindi, Sanskrit): F1-score = 0.8681, Precision = 0.8404, Recall = 0.8977, Support = 88.0\n",
      "tat_Cyrillique: F1-score = 0.8681, Precision = 0.7786, Recall = 0.9808, Support = 104.0\n",
      "hmn_Latin: F1-score = 0.8670, Precision = 1.0000, Recall = 0.7652, Support = 115.0\n",
      "deu_Latin: F1-score = 0.8664, Precision = 0.8246, Recall = 0.9126, Support = 103.0\n",
      "lim_Latin: F1-score = 0.8643, Precision = 0.8431, Recall = 0.8866, Support = 97.0\n",
      "lue_Latin: F1-score = 0.8571, Precision = 1.0000, Recall = 0.7500, Support = 4.0\n",
      "som_Latin: F1-score = 0.8556, Precision = 0.9524, Recall = 0.7767, Support = 103.0\n",
      "nld_Latin: F1-score = 0.8545, Precision = 0.8246, Recall = 0.8868, Support = 106.0\n",
      "weighted avg: F1-score = 0.8512, Precision = 0.8633, Recall = 0.8502, Support = 38020.0\n",
      "lmo_Latin: F1-score = 0.8506, Precision = 0.8506, Recall = 0.8506, Support = 87.0\n",
      "dan_Latin: F1-score = 0.8495, Precision = 0.9080, Recall = 0.7980, Support = 99.0\n",
      "nap_Latin: F1-score = 0.8482, Precision = 0.8636, Recall = 0.8333, Support = 114.0\n",
      "pfl_Latin: F1-score = 0.8475, Precision = 0.7979, Recall = 0.9036, Support = 83.0\n",
      "mlt_Latin: F1-score = 0.8473, Precision = 0.8269, Recall = 0.8687, Support = 99.0\n",
      "gsw_Latin: F1-score = 0.8439, Precision = 0.8488, Recall = 0.8391, Support = 87.0\n",
      "rue_Cyrillique: F1-score = 0.8432, Precision = 0.7500, Recall = 0.9630, Support = 81.0\n",
      "zlm_Latin: F1-score = 0.8413, Precision = 0.8030, Recall = 0.8833, Support = 120.0\n",
      "hif_Latin: F1-score = 0.8377, Precision = 0.8081, Recall = 0.8696, Support = 92.0\n",
      "pcd_Latin: F1-score = 0.8372, Precision = 0.8036, Recall = 0.8738, Support = 103.0\n",
      "wol_Latin: F1-score = 0.8364, Precision = 0.9452, Recall = 0.7500, Support = 92.0\n",
      "pcm_Latin: F1-score = 0.8333, Precision = 0.7812, Recall = 0.8929, Support = 112.0\n",
      "uzb_Latin: F1-score = 0.8333, Precision = 0.7692, Recall = 0.9091, Support = 110.0\n",
      "zea_Latin: F1-score = 0.8313, Precision = 0.8961, Recall = 0.7753, Support = 89.0\n",
      "bsb_Latin: F1-score = 0.8293, Precision = 0.8500, Recall = 0.8095, Support = 105.0\n",
      "hau_Latin: F1-score = 0.8276, Precision = 0.8000, Recall = 0.8571, Support = 98.0\n",
      "yue_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8264, Precision = 0.8065, Recall = 0.8475, Support = 118.0\n",
      "bak_Cyrillique: F1-score = 0.8259, Precision = 0.9765, Recall = 0.7155, Support = 116.0\n",
      "jpn_Katakana (Japonais): F1-score = 0.8235, Precision = 0.7778, Recall = 0.8750, Support = 24.0\n",
      "fra_Latin: F1-score = 0.8223, Precision = 0.7714, Recall = 0.8804, Support = 92.0\n",
      "swc_Latin: F1-score = 0.8173, Precision = 0.8763, Recall = 0.7658, Support = 111.0\n",
      "gor_Latin: F1-score = 0.8172, Precision = 0.8736, Recall = 0.7677, Support = 99.0\n",
      "nds_Latin: F1-score = 0.8169, Precision = 0.8131, Recall = 0.8208, Support = 106.0\n",
      "hil_Latin: F1-score = 0.8148, Precision = 1.0000, Recall = 0.6875, Support = 16.0\n",
      "nso_Latin: F1-score = 0.8144, Precision = 0.7980, Recall = 0.8316, Support = 95.0\n",
      "nno_Latin: F1-score = 0.8119, Precision = 0.7130, Recall = 0.9425, Support = 87.0\n",
      "smo_Latin: F1-score = 0.8118, Precision = 0.9583, Recall = 0.7041, Support = 98.0\n",
      "uig_Latin: F1-score = 0.8090, Precision = 0.9114, Recall = 0.7273, Support = 99.0\n",
      "macro avg: F1-score = 0.8067, Precision = 0.8229, Recall = 0.8042, Support = 38020.0\n",
      "plt_Latin: F1-score = 0.8018, Precision = 0.9674, Recall = 0.6846, Support = 130.0\n",
      "kur_Latin: F1-score = 0.7965, Precision = 0.7188, Recall = 0.8932, Support = 103.0\n",
      "kat_Latin: F1-score = 0.7943, Precision = 0.8384, Recall = 0.7545, Support = 110.0\n",
      "wuu_Kanji (Chinois, Japonais, Coréen): F1-score = 0.7811, Precision = 0.7778, Recall = 0.7845, Support = 116.0\n",
      "ber_Latin: F1-score = 0.7800, Precision = 0.8298, Recall = 0.7358, Support = 106.0\n",
      "oci_Latin: F1-score = 0.7765, Precision = 0.8462, Recall = 0.7174, Support = 92.0\n",
      "haw_Latin: F1-score = 0.7702, Precision = 0.8857, Recall = 0.6813, Support = 91.0\n",
      "bar_Latin: F1-score = 0.7692, Precision = 0.6818, Recall = 0.8824, Support = 102.0\n",
      "scn_Latin: F1-score = 0.7692, Precision = 0.7870, Recall = 0.7522, Support = 113.0\n",
      "jpn_Hiragana (Japonais): F1-score = 0.7674, Precision = 0.6600, Recall = 0.9167, Support = 36.0\n",
      "glg_Latin: F1-score = 0.7594, Precision = 0.7474, Recall = 0.7717, Support = 92.0\n",
      "kmr_Latin: F1-score = 0.7590, Precision = 0.8873, Recall = 0.6632, Support = 95.0\n",
      "hat_Latin: F1-score = 0.7565, Precision = 0.8111, Recall = 0.7087, Support = 103.0\n",
      "aka_Latin: F1-score = 0.7553, Precision = 0.8068, Recall = 0.7100, Support = 100.0\n",
      "kab_Latin: F1-score = 0.7539, Precision = 0.6990, Recall = 0.8182, Support = 88.0\n",
      "hbs_Cyrillique: F1-score = 0.7448, Precision = 0.6496, Recall = 0.8725, Support = 102.0\n",
      "prs_Arabe: F1-score = 0.7386, Precision = 0.6096, Recall = 0.9368, Support = 95.0\n",
      "ekk_Latin: F1-score = 0.7315, Precision = 0.7453, Recall = 0.7182, Support = 110.0\n",
      "twi_Latin: F1-score = 0.7300, Precision = 0.7228, Recall = 0.7374, Support = 99.0\n",
      "cbk_Latin: F1-score = 0.7294, Precision = 0.7949, Recall = 0.6739, Support = 92.0\n",
      "ori_ORIYA: F1-score = 0.7273, Precision = 0.7347, Recall = 0.7200, Support = 100.0\n",
      "srd_Latin: F1-score = 0.7234, Precision = 0.8718, Recall = 0.6182, Support = 110.0\n",
      "tsn_Latin: F1-score = 0.7225, Precision = 0.7500, Recall = 0.6970, Support = 99.0\n",
      "bew_Cyrillique: F1-score = 0.7166, Precision = 0.7701, Recall = 0.6700, Support = 100.0\n",
      "ina_Latin: F1-score = 0.7156, Precision = 0.6446, Recall = 0.8041, Support = 97.0\n",
      "arb_Arabe: F1-score = 0.7143, Precision = 0.6419, Recall = 0.8051, Support = 118.0\n",
      "mri_Latin: F1-score = 0.7104, Precision = 0.8025, Recall = 0.6373, Support = 102.0\n",
      "bjn_Latin: F1-score = 0.7085, Precision = 0.7248, Recall = 0.6930, Support = 114.0\n",
      "hrx_Latin: F1-score = 0.7083, Precision = 1.0000, Recall = 0.5484, Support = 31.0\n",
      "ory_ORIYA: F1-score = 0.7072, Precision = 0.6957, Recall = 0.7191, Support = 89.0\n",
      "que_Latin: F1-score = 0.7027, Precision = 0.9455, Recall = 0.5591, Support = 93.0\n",
      "hin_Devanagari (Hindi, Sanskrit): F1-score = 0.7024, Precision = 0.6792, Recall = 0.7273, Support = 99.0\n",
      "nya_Latin: F1-score = 0.7006, Precision = 0.7949, Recall = 0.6263, Support = 99.0\n",
      "ast_Latin: F1-score = 0.6967, Precision = 0.5903, Recall = 0.8500, Support = 100.0\n",
      "jav_Latin: F1-score = 0.6965, Precision = 0.7527, Recall = 0.6481, Support = 108.0\n",
      "est_Latin: F1-score = 0.6961, Precision = 0.6827, Recall = 0.7100, Support = 100.0\n",
      "cmn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6952, Precision = 0.6566, Recall = 0.7386, Support = 88.0\n",
      "nbl_Latin: F1-score = 0.6920, Precision = 0.5899, Recall = 0.8367, Support = 98.0\n",
      "bel_Cyrillique: F1-score = 0.6919, Precision = 0.6598, Recall = 0.7273, Support = 88.0\n",
      "ckb_Arabe: F1-score = 0.6850, Precision = 0.5724, Recall = 0.8529, Support = 102.0\n",
      "run_Latin: F1-score = 0.6784, Precision = 0.5969, Recall = 0.7857, Support = 98.0\n",
      "mlg_Latin: F1-score = 0.6752, Precision = 0.6320, Recall = 0.7248, Support = 109.0\n",
      "glk_Arabe: F1-score = 0.6667, Precision = 0.6228, Recall = 0.7172, Support = 99.0\n",
      "iba_Latin: F1-score = 0.6667, Precision = 1.0000, Recall = 0.5000, Support = 2.0\n",
      "bak_Latin: F1-score = 0.6595, Precision = 0.6489, Recall = 0.6703, Support = 91.0\n",
      "aym_Latin: F1-score = 0.6575, Precision = 0.9057, Recall = 0.5161, Support = 93.0\n",
      "ita_Latin: F1-score = 0.6535, Precision = 0.6055, Recall = 0.7097, Support = 93.0\n",
      "spa_Latin: F1-score = 0.6535, Precision = 0.6535, Recall = 0.6535, Support = 101.0\n",
      "aze_Arabe: F1-score = 0.6479, Precision = 0.6389, Recall = 0.6571, Support = 105.0\n",
      "tgl_Latin: F1-score = 0.6462, Precision = 0.6923, Recall = 0.6058, Support = 104.0\n",
      "swa_Latin: F1-score = 0.6460, Precision = 0.6518, Recall = 0.6404, Support = 114.0\n",
      "xho_Latin: F1-score = 0.6429, Precision = 0.8182, Recall = 0.5294, Support = 102.0\n",
      "sqi_Latin: F1-score = 0.6419, Precision = 0.5847, Recall = 0.7113, Support = 97.0\n",
      "swh_Latin: F1-score = 0.6267, Precision = 0.5913, Recall = 0.6667, Support = 102.0\n",
      "jpn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6230, Precision = 0.7917, Recall = 0.5135, Support = 37.0\n",
      "war_Latin: F1-score = 0.6203, Precision = 0.6591, Recall = 0.5859, Support = 99.0\n",
      "urd_Arabe: F1-score = 0.6063, Precision = 0.4843, Recall = 0.8105, Support = 95.0\n",
      "srp_Latin: F1-score = 0.5907, Precision = 0.6333, Recall = 0.5534, Support = 103.0\n",
      "hbs_Latin: F1-score = 0.5862, Precision = 0.4620, Recall = 0.8019, Support = 106.0\n",
      "vec_Latin: F1-score = 0.5820, Precision = 0.5612, Recall = 0.6044, Support = 91.0\n",
      "san_Latin: F1-score = 0.5806, Precision = 0.5625, Recall = 0.6000, Support = 15.0\n",
      "hau_Arabe: F1-score = 0.5797, Precision = 0.6742, Recall = 0.5085, Support = 118.0\n",
      "srp_Cyrillique: F1-score = 0.5733, Precision = 0.7167, Recall = 0.4778, Support = 90.0\n",
      "sot_Latin: F1-score = 0.5729, Precision = 0.6322, Recall = 0.5238, Support = 105.0\n",
      "ban_Latin: F1-score = 0.5714, Precision = 0.6517, Recall = 0.5088, Support = 114.0\n",
      "wln_Latin: F1-score = 0.5698, Precision = 0.5667, Recall = 0.5730, Support = 89.0\n",
      "zho_Kanji (Chinois, Japonais, Coréen): F1-score = 0.5682, Precision = 0.7042, Recall = 0.4762, Support = 105.0\n",
      "tuk_Cyrillique: F1-score = 0.5669, Precision = 0.4444, Recall = 0.7826, Support = 46.0\n",
      "nob_Latin: F1-score = 0.5572, Precision = 0.5600, Recall = 0.5545, Support = 101.0\n",
      "tgk_Cyrillique: F1-score = 0.5535, Precision = 0.6769, Recall = 0.4681, Support = 94.0\n",
      "guj_Devanagari (Hindi, Sanskrit): F1-score = 0.5500, Precision = 0.5500, Recall = 0.5500, Support = 100.0\n",
      "tat_Latin: F1-score = 0.5488, Precision = 0.7759, Recall = 0.4245, Support = 106.0\n",
      "aze_Latin: F1-score = 0.5438, Precision = 0.5315, Recall = 0.5566, Support = 106.0\n",
      "sun_Latin: F1-score = 0.5350, Precision = 0.4779, Recall = 0.6075, Support = 107.0\n",
      "kur_Arabe: F1-score = 0.5269, Precision = 0.7586, Recall = 0.4037, Support = 109.0\n",
      "cos_Latin: F1-score = 0.5217, Precision = 0.4681, Recall = 0.5893, Support = 112.0\n",
      "bik_Latin: F1-score = 0.5155, Precision = 0.4808, Recall = 0.5556, Support = 90.0\n",
      "mad_Latin: F1-score = 0.5146, Precision = 0.5300, Recall = 0.5000, Support = 106.0\n",
      "nor_Latin: F1-score = 0.5137, Precision = 0.5595, Recall = 0.4747, Support = 99.0\n",
      "azj_Latin: F1-score = 0.5134, Precision = 0.5333, Recall = 0.4948, Support = 97.0\n",
      "fil_Latin: F1-score = 0.5123, Precision = 0.4771, Recall = 0.5532, Support = 94.0\n",
      "ary_Arabe: F1-score = 0.5094, Precision = 0.5047, Recall = 0.5143, Support = 105.0\n",
      "ara_Arabe: F1-score = 0.5017, Precision = 0.4045, Recall = 0.6606, Support = 109.0\n",
      "mya_Latin: F1-score = 0.5000, Precision = 1.0000, Recall = 0.3333, Support = 3.0\n",
      "pam_Latin: F1-score = 0.4977, Precision = 0.4508, Recall = 0.5556, Support = 99.0\n",
      "ajp_Arabe: F1-score = 0.4975, Precision = 0.4098, Recall = 0.6329, Support = 79.0\n",
      "kin_Latin: F1-score = 0.4944, Precision = 0.4783, Recall = 0.5116, Support = 86.0\n",
      "uzn_Cyrillique: F1-score = 0.4873, Precision = 0.5393, Recall = 0.4444, Support = 108.0\n",
      "ltz_Latin: F1-score = 0.4872, Precision = 0.3519, Recall = 0.7917, Support = 96.0\n",
      "tgk_Latin: F1-score = 0.4727, Precision = 0.5342, Recall = 0.4239, Support = 92.0\n",
      "pes_Arabe: F1-score = 0.4713, Precision = 0.5857, Recall = 0.3942, Support = 104.0\n",
      "uzb_Cyrillique: F1-score = 0.4651, Precision = 0.3774, Recall = 0.6061, Support = 99.0\n",
      "hin_Latin: F1-score = 0.4639, Precision = 0.4787, Recall = 0.4500, Support = 100.0\n",
      "apc_Arabe: F1-score = 0.4574, Precision = 0.4474, Recall = 0.4679, Support = 109.0\n",
      "fas_Arabe: F1-score = 0.4571, Precision = 0.5063, Recall = 0.4167, Support = 96.0\n",
      "als_Latin: F1-score = 0.4528, Precision = 0.5902, Recall = 0.3673, Support = 98.0\n",
      "sna_Latin: F1-score = 0.4444, Precision = 0.6667, Recall = 0.3333, Support = 102.0\n",
      "acm_Arabe: F1-score = 0.4416, Precision = 0.5574, Recall = 0.3656, Support = 93.0\n",
      "zsm_Latin: F1-score = 0.4270, Precision = 0.3958, Recall = 0.4634, Support = 82.0\n",
      "msa_Latin: F1-score = 0.4261, Precision = 0.3984, Recall = 0.4579, Support = 107.0\n",
      "eng_Latin: F1-score = 0.4242, Precision = 0.2984, Recall = 0.7333, Support = 105.0\n",
      "ind_Latin: F1-score = 0.4162, Precision = 0.4186, Recall = 0.4138, Support = 87.0\n",
      "nde_Latin: F1-score = 0.4052, Precision = 0.4366, Recall = 0.3780, Support = 82.0\n",
      "enm_Latin: F1-score = 0.4000, Precision = 1.0000, Recall = 0.2500, Support = 4.0\n",
      "bcl_Latin: F1-score = 0.3889, Precision = 0.3451, Recall = 0.4455, Support = 110.0\n",
      "afb_Arabe: F1-score = 0.3864, Precision = 0.4304, Recall = 0.3505, Support = 97.0\n",
      "zul_Latin: F1-score = 0.3681, Precision = 0.4286, Recall = 0.3226, Support = 93.0\n",
      "sco_Latin: F1-score = 0.3557, Precision = 0.2377, Recall = 0.7064, Support = 109.0\n",
      "lao_Latin: F1-score = 0.3333, Precision = 0.7500, Recall = 0.2143, Support = 14.0\n",
      "som_Arabe: F1-score = 0.3226, Precision = 0.9091, Recall = 0.1961, Support = 102.0\n",
      "khm_Latin: F1-score = 0.2857, Precision = 0.5000, Recall = 0.2000, Support = 5.0\n",
      "tgk_Arabe: F1-score = 0.2819, Precision = 0.4468, Recall = 0.2059, Support = 102.0\n",
      "bos_Latin: F1-score = 0.2712, Precision = 0.3380, Recall = 0.2264, Support = 106.0\n",
      "hrv_Latin: F1-score = 0.2270, Precision = 0.2857, Recall = 0.1882, Support = 85.0\n",
      "guj_Latin: F1-score = 0.1538, Precision = 0.2000, Recall = 0.1250, Support = 8.0\n",
      "bod_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "dzo_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 7.0\n",
      "hne_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 3.0\n",
      "hyw_Arménien: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 7.0\n",
      "jpn_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "lao_Cyrillique: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "mai_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "miq_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "nep_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "ngl_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 3.0\n",
      "niu_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "ori_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "pus_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "quz_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sat_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sin_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "tam_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "teo_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "tha_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "wbm_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Générer le rapport de classification sous forme de dictionnaire\n",
    "report_sp = classification_report(y_val_sp, predictions_sp, target_names=filtered_target_names_sp, output_dict=True)\n",
    "\n",
    "# Filtrer les classes (en excluant 'accuracy', 'macro avg', 'weighted avg')\n",
    "filtered_report = {label: metrics for label, metrics in report_sp.items() if isinstance(metrics, dict)}\n",
    "\n",
    "# Trier les langues par F1-score de manière décroissante\n",
    "sorted_report = sorted(filtered_report.items(), key=lambda x: x[1]['f1-score'], reverse=True)\n",
    "\n",
    "# Afficher le rapport trié\n",
    "print(\"Classification Report (trié par F1-score décroissant):\\n\")\n",
    "for label, metrics in sorted_report:\n",
    "    print(f\"{label}: F1-score = {metrics['f1-score']:.4f}, Precision = {metrics['precision']:.4f}, Recall = {metrics['recall']:.4f}, Support = {metrics['support']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128184</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ A p ă râ nd ▁fa ț ă ▁în t r - un ▁exerci ți ...</td>\n",
       "      <td>ron_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95049</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁kaya ▁vua ▁ J i su ▁vol ai ▁ta lega ▁ka kua ▁...</td>\n",
       "      <td>fij_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170377</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁אי ן ▁צו וא נ צ יק ▁י אר ▁הא ט ▁דא ס ▁דא ר ף ...</td>\n",
       "      <td>yid_Hébreu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171119</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ S en iň ▁s özü ň e ▁gu lak ▁ assa ▁do ga nyň...</td>\n",
       "      <td>tuk_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62238</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁gro nta pu ▁fesi . ▁pra ti ▁ini ▁grup u ▁le k...</td>\n",
       "      <td>srn_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38370</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ A ndũ ▁nĩ ▁mara kari re ▁mũno . N ĩ ▁ma tho ...</td>\n",
       "      <td>kik_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175527</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ T á ▁ ið ▁hu g sa ð ▁verður ▁ska ðar nar ▁ i...</td>\n",
       "      <td>fao_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65025</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ I ng ku ro ▁oku ▁mi lo ' ▁mo ngu hu p ▁ T om ?</td>\n",
       "      <td>dtp_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150121</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ A ˬ ▁ma - ah ˇ ▁ya ˆ ▁ phy aw ˇ ▁ya ˆ ▁neh ˬ...</td>\n",
       "      <td>ahk_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176563</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ 99 % ▁ O xi d ized</td>\n",
       "      <td>sun_Latin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38020 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text       Label\n",
       "128184  Public  ▁ A p ă râ nd ▁fa ț ă ▁în t r - un ▁exerci ți ...   ron_Latin\n",
       "95049   Public  ▁kaya ▁vua ▁ J i su ▁vol ai ▁ta lega ▁ka kua ▁...   fij_Latin\n",
       "170377  Public  ▁אי ן ▁צו וא נ צ יק ▁י אר ▁הא ט ▁דא ס ▁דא ר ף ...  yid_Hébreu\n",
       "171119  Public  ▁ S en iň ▁s özü ň e ▁gu lak ▁ assa ▁do ga nyň...   tuk_Latin\n",
       "62238   Public  ▁gro nta pu ▁fesi . ▁pra ti ▁ini ▁grup u ▁le k...   srn_Latin\n",
       "...        ...                                                ...         ...\n",
       "38370   Public  ▁ A ndũ ▁nĩ ▁mara kari re ▁mũno . N ĩ ▁ma tho ...   kik_Latin\n",
       "175527  Public  ▁ T á ▁ ið ▁hu g sa ð ▁verður ▁ska ðar nar ▁ i...   fao_Latin\n",
       "65025   Public   ▁ I ng ku ro ▁oku ▁mi lo ' ▁mo ngu hu p ▁ T om ?   dtp_Latin\n",
       "150121  Public  ▁ A ˬ ▁ma - ah ˇ ▁ya ˆ ▁ phy aw ˇ ▁ya ˆ ▁neh ˬ...   ahk_Latin\n",
       "176563  Public                               ▁ 99 % ▁ O xi d ized   sun_Latin\n",
       "\n",
       "[38020 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set_second_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test avec SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test avec SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing training data: 100%|██████████| 152079/152079 [01:11<00:00, 2138.84it/s]\n",
      "Vectorizing validation data: 100%|██████████| 38020/38020 [00:16<00:00, 2253.33it/s]\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.7837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer_sp_2 = TfidfVectorizer(analyzer=\"char\", ngram_range=(1,4), max_features=50000)\n",
    "# sgdclassifier_model = SGDClassifier(loss=\"hinge\", alpha=0.0001, shuffle=True, max_iter=1, warm_start=True)\n",
    "\n",
    "# x_train_sgdc_vectorized = vectorizer_sp_2.fit_transform(tqdm(x_train_sp, desc=\"Vectorizing training data\"))\n",
    "# x_val_sgdc_vectorized = vectorizer_sp_2.transform(tqdm(x_val_sp, desc=\"Vectorizing validation data\"))\n",
    "\n",
    "# sgdclassifier_model.fit(x_train_sgdc_vectorized, y_train_sp)\n",
    "# val_accuracy = accuracy_score(y_val_sp, sgdclassifier_model.predict(x_val_sgdc_vectorized))\n",
    "# print(f\"Val Accuracy: {val_accuracy:.4f}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.7128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer_sp_2 = TfidfVectorizer(analyzer=\"char\", ngram_range=(1,4), max_features=20000)\n",
    "sgdclassifier_model = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=1, learning_rate='optimal', early_stopping=False)\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('tfidf', vectorizer_sp_2),\n",
    "    ('mnb', sgdclassifier_model)\n",
    "])\n",
    "\n",
    "pipeline_svm.fit(x_train_sp, y_train_sp)\n",
    "predictions_svm = pipeline_svm.predict(x_val_sp)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val_sp, predictions_svm)\n",
    "print(f\"Val Accuracy: {val_accuracy:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation du meilleur modèle pour le test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190567/190567 [00:08<00:00, 22595.11it/s]\n"
     ]
    }
   ],
   "source": [
    "data_test= pd.read_csv(file_path_test)\n",
    "test_set = pre_processing(data_test, remove_espace=False, not_test=False)\n",
    "test_set['Text'] = test_set['Text'].progress_apply(sentencepiece_tokenize)\n",
    "\n",
    "# pipeline chose \n",
    "\n",
    "best_pipeline = pipeline\n",
    "\n",
    "x_test = test_set['Text'].tolist()\n",
    "predictions_test = best_pipeline.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190567/190567 [00:00<00:00, 1041060.33it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_test = le_sp.inverse_transform(predictions_test)\n",
    "predicted_labels_test = restore_labels(predicted_labels_test)\n",
    "test_set['Label'] = predicted_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_ID = [i for i in range(1, len(test_set)+1)]\n",
    "test_set['ID'] = column_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[['Label', 'ID']].to_csv('test_set_v4_predicted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
