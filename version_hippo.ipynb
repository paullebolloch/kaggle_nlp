{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "file_path_train = \"../data/train_submission_1.csv\"\n",
    "file_path_test = \"../data/test_without_labels_1.csv\"\n",
    "\n",
    "data_train = pd.read_csv(file_path_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse du dataset d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On observe d'abord les données non labellisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_without_label = data_train[data_train[\"Label\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Public</td>\n",
       "      <td>Kòe bô jōa kú  hō͘-sū sió-chiá lâi kā góan mn̄...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Public</td>\n",
       "      <td>Söğütçük sī chi̍t ê tī Türkiye Aydın séng Çine...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Public</td>\n",
       "      <td>Golden Valley Kūn ū khó-lêng sī kóng:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>Public</td>\n",
       "      <td>Tī Montégut-Lauragais ê sì-ûi ū Nogaret  Revel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Public</td>\n",
       "      <td>Soveria Simeri ùi séng lāi ê hoān-ûi.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189637</th>\n",
       "      <td>Public</td>\n",
       "      <td>Bellebrune sī ūi-tī Hoat-kok Nord-Pas-de-Calai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189946</th>\n",
       "      <td>Public</td>\n",
       "      <td>Bô phah-sǹg  tī sin-le̍k 10 go̍eh 29 hō ē-po͘ ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189959</th>\n",
       "      <td>Public</td>\n",
       "      <td>Wiejki sī chi̍t ê tī Pho-lân Kiōng-hô-kok Podl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190397</th>\n",
       "      <td>Public</td>\n",
       "      <td>Tī pún só͘-chāi sì-ûi ê tē-hng ū Valy  Veselí ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190493</th>\n",
       "      <td>Public</td>\n",
       "      <td>Ojén sī tī Se-pan-gâ Andalucía siā-lí Málaga s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text Label\n",
       "107     Public  Kòe bô jōa kú  hō͘-sū sió-chiá lâi kā góan mn̄...   NaN\n",
       "803     Public  Söğütçük sī chi̍t ê tī Türkiye Aydın séng Çine...   NaN\n",
       "1095    Public              Golden Valley Kūn ū khó-lêng sī kóng:   NaN\n",
       "1894    Public  Tī Montégut-Lauragais ê sì-ûi ū Nogaret  Revel...   NaN\n",
       "2499    Public              Soveria Simeri ùi séng lāi ê hoān-ûi.   NaN\n",
       "...        ...                                                ...   ...\n",
       "189637  Public  Bellebrune sī ūi-tī Hoat-kok Nord-Pas-de-Calai...   NaN\n",
       "189946  Public  Bô phah-sǹg  tī sin-le̍k 10 go̍eh 29 hō ē-po͘ ...   NaN\n",
       "189959  Public  Wiejki sī chi̍t ê tī Pho-lân Kiōng-hô-kok Podl...   NaN\n",
       "190397  Public  Tī pún só͘-chāi sì-ûi ê tē-hng ū Valy  Veselí ...   NaN\n",
       "190493  Public  Ojén sī tī Se-pan-gâ Andalucía siā-lí Málaga s...   NaN\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_without_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a 500 instances qui ne sont pas labellisées. \n",
    "\n",
    "On choisit de se débarasser de ces données pour l'entraînement de nos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_without_nan_for_label = data_train.dropna() # suppression des données non labellisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des données labellisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 390 différentes langues dans le dataset de train\n"
     ]
    }
   ],
   "source": [
    "number_of_languages = len(data_train[\"Label\"].unique())\n",
    "print(f\"Il y a {number_of_languages} différentes langues dans le dataset de train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gcr</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaa</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toi</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kua</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gil</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Usage  Text\n",
       "Label             \n",
       "gcr        1     1\n",
       "gaa        1     1\n",
       "toi        1     1\n",
       "kua        1     1\n",
       "gil        2     2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sorted_by_number_instances_by_language = data_train_without_nan_for_label.groupby(\"Label\").count().sort_values('Usage', ascending=True)\n",
    "dataset_sorted_by_number_instances_by_language.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Creating an histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset_sorted_by_number_instances_by_language['Text'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(\"Number of Instances per Language\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.title(\"Distribution of training instances per language in the dataset\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gcr',\n",
       " 'gaa',\n",
       " 'toi',\n",
       " 'kua',\n",
       " 'gil',\n",
       " 'tvl',\n",
       " 'pau',\n",
       " 'crs',\n",
       " 'wbm',\n",
       " 'niu',\n",
       " 'miq',\n",
       " 'ada',\n",
       " 'teo',\n",
       " 'quz',\n",
       " 'ngl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Underrepresented languages\n",
    "df = dataset_sorted_by_number_instances_by_language\n",
    "underrepresented_languages = list(df[df['Text']<10].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observer que le nombre d'exemples par langue varie. Certaines langues sont sur-représentées (avec 1500 instances pour la première) par rapport à d'autres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de langues avec au moins 100 instances est 93.31619537275064%\n"
     ]
    }
   ],
   "source": [
    "percentage_of_languages_with_at_least_100_instances = len(dataset_sorted_by_number_instances_by_language[dataset_sorted_by_number_instances_by_language[\"Usage\"] >= 100])/len(dataset_sorted_by_number_instances_by_language) * 100\n",
    "print(f\"Le pourcentage de langues avec au moins 100 instances est {percentage_of_languages_with_at_least_100_instances}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitement du dataset de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re \n",
    "import unicodedata\n",
    "\n",
    "def cleaning(text): \n",
    "    \"\"\"\n",
    "    Fonction pour pré-traiter le texte en enlevant tous les éléments de ponctuation, les chiffres, les double espaces, les URL etc. \n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # text = re.sub(r\"\\(.*?\\)|\\[.*?\\]|\\{.*?\\}|['\\\"«»„“”‘’]|\\<.*?\\>\", \" \", text) # 1. Supprimer les textes entre (), [], {}, \"\", « »\n",
    "    text = re.sub(r\"https?://[^\\s]+|www\\.[^\\s]+\", \" \", text) # Supprimer les URLs\n",
    "    # text = re.sub(r\"\\b[A-ZÀ-ÖØ-Þ][a-zà-öø-ÿ]*\", \" \", text) # Supprimer les mots qui commencent par une majuscule (prénoms, noms propres, etc.)\n",
    "    # text = re.sub(r\"\\b[A-Z]+\\d*[A-Z\\d]*\", \" \", text) # Supprimer les sigles type \"IK10\", \"ABC123\", \"X4D\" (au moins 1 lettre + au moins 1 chiffre)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)  # Supprimer les nombres isolés\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Supprimer la ponctuation et les caractères spéciaux\n",
    "    # text = ''.join(c for c in text if unicodedata.category(c)[0] not in [\"C\", \"S\"])  # Supprimer les caractères de contrôle Unicode, symboles et emojis\n",
    "    text = ''.join(c for c in text if not (unicodedata.category(c).startswith('P') or unicodedata.category(c) in ['No']))\n",
    "\n",
    "    asian_punctuation = \"，。？！《》【】（）；：、。•\" # Liste de ponctuation à inclure pour les langues asiatiques\n",
    "    text = re.sub(r'[\\-\\u2010-\\u2015]', '', text) # supprime tous les types de tirets\n",
    "    text = re.sub(r\"['\\\"‘’‚‛“”„‟‹›«»⹂⹃⸂⸃⸄⸅⸉⸊「」『』〝〞＂ˮ`´ʹʺʻʼʽʾʿˈˊˋ]\", '', text)\n",
    "\n",
    "    # text = text.translate(str.maketrans('', '', string.punctuation + asian_punctuation)) # supprime la ponctuation asiatique\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip() # enlève les double espaces\n",
    "\n",
    "    text_cleaned = text.lower() # met le texte en minuscule \n",
    "\n",
    "    return(text_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit de ne pas enlever le texte entre (), [], {}, \"\", « » car on s'aperçoit que les résultats sont moins bons, cela nous fait perdre de l'information utile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un ensemble de mots anglais pour pouvoir enlever les mots anglais dans les phrases avec des mots anglais mélangés à d'autres langues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/hippolytelecomte/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Télécharger la liste des mots en anglais (une seule fois nécessaire)\n",
    "nltk.download('words')\n",
    "\n",
    "# Liste des mots en anglais\n",
    "english_words = set(word.lower() for word in words.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ang = data_train_without_nan_for_label[data_train_without_nan_for_label[\"Label\"] == 'eng'][\"Text\"]\n",
    "\n",
    "# Collecte des mots uniques\n",
    "for text in data_ang:\n",
    "    for word in text.split():\n",
    "        english_words.add(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_most_english_words(text): \n",
    "    \"\"\"\n",
    "    Fonction pour enlever les mots anglais lorsque la langue du texte n'est pas l'anglais. \n",
    "    \"\"\"\n",
    "    tokens = text.split() \n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in english_words]\n",
    "\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement on s'aperçoit qu'enlever les mots anglais dans les phrases qui ne sont pas labellisées comme du texte anglais baisse nos résultats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()  \n",
    "\n",
    "def pre_processing(df, remove_espace = True, not_test = True, need_to_clean = True): \n",
    "    \"\"\"\n",
    "    Utilisation des méthodes de pré-traitement définies auparavant pour rendre le texte propre. \n",
    "    \"\"\"\n",
    "\n",
    "    if need_to_clean: \n",
    "        df['Text'] = df['Text'].apply(cleaning)\n",
    "    \n",
    "    if not_test: \n",
    "        df['Text'] = df.progress_apply(\n",
    "            lambda row: remove_most_english_words(row['Text']) if row['Label'] != 'eng' else row['Text'], axis=1\n",
    "        )\n",
    "    \n",
    "    if remove_espace: \n",
    "        df['Text'] = df['Text'].str.replace(' ', '', regex=False)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'apperçoit également que dans le dataset d'entraînement il y a des langues qui peuvent écrites dans différents alphabets, c'est le cas pour certaines langues asiatiques notamment. On choisit ainsi de créer une fonction qui permet de détecter les alphabets présents dans la phrase et de déterminer l'alphabet majoritaire en fonction du nombre de caractères (même si cette méthode n'est pas optimale car certains alphabets contiennent plus d'informations dans leur caractère que d'autres). Ensuite on change le label des phrases en ajoutant l'alphabet utilisé pour la langue et créant ainsi de nouvelles catégories comme fra_Latin pour le français écrit avec l'alphabet latin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "\n",
    "# Catégorisation fine des scripts\n",
    "SCRIPT_MAP = {\n",
    "    \"LATIN\": \"Latin\",\n",
    "    \"CYRILLIC\": \"Cyrillique\",\n",
    "    \"ARABIC\": \"Arabe\",\n",
    "    \"HEBREW\": \"Hébreu\",\n",
    "    \"GREEK\": \"Grec\",\n",
    "    \"DEVANAGARI\": \"Devanagari (Hindi, Sanskrit)\",\n",
    "    \"HIRAGANA\": \"Hiragana (Japonais)\",\n",
    "    \"KATAKANA\": \"Katakana (Japonais)\",\n",
    "    \"CJK\": \"Kanji (Chinois, Japonais, Coréen)\",\n",
    "    \"HANGUL\": \"Hangul (Coréen)\",\n",
    "    \"THAI\": \"Thaï\",\n",
    "    \"ARMENIAN\": \"Arménien\",\n",
    "    \"GEORGIAN\": \"Géorgien\",\n",
    "    \"ETHIOPIC\": \"Éthiopien\",\n",
    "    \"TAMIL\": \"Tamoul\",\n",
    "    \"BENGALI\": \"Bengali\",\n",
    "    \"TELUGU\": \"Télougou\",\n",
    "}\n",
    "\n",
    "def count_alphabet_characters(text):\n",
    "    script_counts = defaultdict(int)\n",
    "\n",
    "    for char in text:\n",
    "        if char.isalpha():  # On ignore les symboles et ponctuations\n",
    "            try:\n",
    "                char_name = unicodedata.name(char) \n",
    "                script_key = char_name.split()[0]  # Prend le premier mot du nom Unicode\n",
    "                \n",
    "                if \"CJK\" in char_name:\n",
    "                    script_key = \"CJK\"  # Les kanji sont classés sous \"CJK UNIFIED IDEOGRAPH\"\n",
    "                \n",
    "                script_name = SCRIPT_MAP.get(script_key, script_key)  # Utilise le mapping o\n",
    "                script_counts[script_name] += 1  # Incrémente le compteur\n",
    "                \n",
    "            except ValueError:\n",
    "                continue  # Si le caractère n'a pas de nom Unicode\n",
    "    \n",
    "    return dict(script_counts)  # Retourne un dictionnaire des comptages\n",
    "\n",
    "def most_frequent_script(text):\n",
    "    script_counts = count_alphabet_characters(text)  # Appel de la fonction précédente\n",
    "    \n",
    "    if script_counts:  # Vérifie si le dictionnaire n'est pas vide\n",
    "        most_common_script = max(script_counts.items(), key=lambda x: x[1])  # Trouve l'alphabet avec le max de caractères\n",
    "        return most_common_script  # Retourne (nom de l'alphabet, nombre d'occurrences)\n",
    "    else:\n",
    "        return None  # Retourne None si aucun alphabet trouvé\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def add_alphabet_to_label(df):\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):  # Parcourt chaque ligne du DataFrame\n",
    "        alphabet_most_frequent = most_frequent_script(row['Text'])  # Détecte l'alphabet dominant\n",
    "        \n",
    "        if alphabet_most_frequent:  # Vérifie si un alphabet a été trouvé\n",
    "            df.at[index, 'Label'] = f\"{row['Label']}_{alphabet_most_frequent[0]}\"  # Met à jour le label\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def restore_original_label(label):\n",
    "    return label.split(\"_\")[0]  # Prend seulement la première partie avant '_'\n",
    "\n",
    "def restore_labels(liste):\n",
    "    new_liste = []\n",
    "    for element in tqdm(liste): \n",
    "        new_liste.append(restore_original_label(element))\n",
    "    return np.array(new_liste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première approche sans tokenizer avec TFIDF et MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, val_set = train_test_split(data_train_without_nan_for_label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application du pré-traitement et du changement de labellisation sur le train et le val. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171089/171089 [00:06<00:00, 26524.87it/s]\n",
      "100%|██████████| 19010/19010 [00:00<00:00, 25265.55it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set_first_version = train_set.copy()\n",
    "val_set_first_version = val_set.copy()\n",
    "train_set_first_version = pre_processing(train_set_first_version, remove_espace=False, not_test=False) \n",
    "val_set_first_version = pre_processing(val_set_first_version, remove_espace=False, not_test=False)\n",
    "train_set_first_version = add_alphabet_to_label(train_set_first_version)\n",
    "val_set_first_version = add_alphabet_to_label(val_set_first_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en place de la pipeline pour le modèle où on choisit d'utiliser comme Vectorizer TFIDF et comme modèle MultinomialNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128184</th>\n",
       "      <td>Public</td>\n",
       "      <td>apărând din față întrun exercițiu apăsând rolu...</td>\n",
       "      <td>ron_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95049</th>\n",
       "      <td>Public</td>\n",
       "      <td>sa kaya vua ko jisu sa volai talega mo kakua n...</td>\n",
       "      <td>fij_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170377</th>\n",
       "      <td>Public</td>\n",
       "      <td>אין צוואנציק יאר האט דאס דארף פארוואנדלט אין א...</td>\n",
       "      <td>yid_Hébreu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171119</th>\n",
       "      <td>Public</td>\n",
       "      <td>seniň sözüňe gulak assa bu doganyňy gazandygyň...</td>\n",
       "      <td>tuk_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62238</th>\n",
       "      <td>Public</td>\n",
       "      <td>ala sma fu grontapu o kon na en fesi dan a o p...</td>\n",
       "      <td>srn_Latin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text       Label\n",
       "128184  Public  apărând din față întrun exercițiu apăsând rolu...   ron_Latin\n",
       "95049   Public  sa kaya vua ko jisu sa volai talega mo kakua n...   fij_Latin\n",
       "170377  Public  אין צוואנציק יאר האט דאס דארף פארוואנדלט אין א...  yid_Hébreu\n",
       "171119  Public  seniň sözüňe gulak assa bu doganyňy gazandygyň...   tuk_Latin\n",
       "62238   Public  ala sma fu grontapu o kon na en fesi dan a o p...   srn_Latin"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set_first_version.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set_first_version['Text'].tolist()\n",
    "y_train = train_set_first_version['Label'].tolist()\n",
    "x_val = val_set_first_version['Text'].tolist()\n",
    "y_val = val_set_first_version['Label'].tolist()\n",
    "y_total = y_train + y_val\n",
    "\n",
    "# converting categorical variables to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "label_mapping = dict(zip(le.classes_, range(len(le.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000, ngram_range=(1, 5))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.001, fit_prior=False)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char', max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                ('classifier', MultinomialNB(alpha=0.001, fit_prior=False))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilisation dans le pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# Pipeline avec barres de progression\n",
    "pipe = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 5), max_features=200000)),\n",
    "    ('classifier', MultinomialNB(alpha=0.001, fit_prior=False))\n",
    "])\n",
    "\n",
    "\n",
    "# Utilisation\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8514466070489216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "predictions = pipe.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de fonctions pour récupéer les labels originaux. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = le.inverse_transform(predictions)\n",
    "labels_predict = le.inverse_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19010/19010 [00:00<00:00, 1117109.90it/s]\n",
      "100%|██████████| 19010/19010 [00:00<00:00, 476642.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7778011572856391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_pred = restore_labels(predicted_labels)\n",
    "val_predict = restore_labels(labels_predict)\n",
    "final_accuracy = accuracy_score(val_predict, final_pred)\n",
    "print(\"Accuracy:\", final_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (trié par F1-score décroissant):\n",
      "\n",
      "abk_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "ahk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "alt_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "aoj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "arn_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 63.0\n",
      "asm_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 44.0\n",
      "bem_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 38.0\n",
      "bpy_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "bqc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "bzj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 43.0\n",
      "cab_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "cak_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "chk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "cjk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "csy_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "ctu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "cuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "div_THAANA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 39.0\n",
      "djk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "fon_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 44.0\n",
      "gom_Devanagari (Hindi, Sanskrit): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 40.0\n",
      "guc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "guj_GUJARATI: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "gym_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "hbo_Hébreu: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "hnj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "hui_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 43.0\n",
      "hus_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "iba_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "iku_CANADIAN: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 61.0\n",
      "ixl_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "kac_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "kal_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "kan_KANNADA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "kek_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 43.0\n",
      "kjb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 40.0\n",
      "knv_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 51.0\n",
      "kos_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 51.0\n",
      "kpg_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 56.0\n",
      "ksd_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "lhu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 20.0\n",
      "lue_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "luo_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "lus_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "lvs_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "mah_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 2.0\n",
      "mal_MALAYALAM: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 44.0\n",
      "mam_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "mau_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "mco_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "meu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 61.0\n",
      "mgh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "mon_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "mos_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 52.0\n",
      "mps_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "mya_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 2.0\n",
      "mzh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 44.0\n",
      "naq_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 59.0\n",
      "nav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "nch_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "ncj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 39.0\n",
      "ngu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "nnb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "nyu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 42.0\n",
      "orm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 63.0\n",
      "ote_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "pan_GURMUKHI: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 52.0\n",
      "pap_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "pls_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 36.0\n",
      "poh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "pon_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 47.0\n",
      "qub_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 2.0\n",
      "qvi_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "rop_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 42.0\n",
      "rug_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "sat_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "sat_OL: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 52.0\n",
      "seh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 51.0\n",
      "srm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 63.0\n",
      "srn_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "suz_Devanagari (Hindi, Sanskrit): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "tam_Tamoul: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "tbz_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "tca_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 43.0\n",
      "tdt_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 38.0\n",
      "tlh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "toj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "tok_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "top_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 51.0\n",
      "tso_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 61.0\n",
      "tuc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 59.0\n",
      "tuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "tzo_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "uig_Arabe: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 59.0\n",
      "umb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 52.0\n",
      "wal_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 63.0\n",
      "wbm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "xav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 61.0\n",
      "yao_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 57.0\n",
      "yap_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "zai_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "kir_Cyrillique: F1-score = 0.9920, Precision = 0.9841, Recall = 1.0000, Support = 62.0\n",
      "sgs_Latin: F1-score = 0.9917, Precision = 1.0000, Recall = 0.9836, Support = 61.0\n",
      "krc_Cyrillique: F1-score = 0.9913, Precision = 1.0000, Recall = 0.9828, Support = 58.0\n",
      "sah_Cyrillique: F1-score = 0.9913, Precision = 1.0000, Recall = 0.9828, Support = 58.0\n",
      "crh_Latin: F1-score = 0.9908, Precision = 1.0000, Recall = 0.9818, Support = 55.0\n",
      "kbd_Cyrillique: F1-score = 0.9908, Precision = 1.0000, Recall = 0.9818, Support = 55.0\n",
      "roh_Latin: F1-score = 0.9908, Precision = 0.9818, Recall = 1.0000, Support = 54.0\n",
      "eus_Latin: F1-score = 0.9907, Precision = 1.0000, Recall = 0.9815, Support = 54.0\n",
      "quw_Latin: F1-score = 0.9907, Precision = 1.0000, Recall = 0.9815, Support = 54.0\n",
      "yom_Latin: F1-score = 0.9907, Precision = 0.9815, Recall = 1.0000, Support = 53.0\n",
      "ikk_Latin: F1-score = 0.9901, Precision = 0.9804, Recall = 1.0000, Support = 50.0\n",
      "kjh_Cyrillique: F1-score = 0.9901, Precision = 1.0000, Recall = 0.9804, Support = 51.0\n",
      "che_Cyrillique: F1-score = 0.9899, Precision = 1.0000, Recall = 0.9800, Support = 50.0\n",
      "kbp_Latin: F1-score = 0.9899, Precision = 0.9800, Recall = 1.0000, Support = 49.0\n",
      "kor_Hangul (Coréen): F1-score = 0.9897, Precision = 1.0000, Recall = 0.9796, Support = 49.0\n",
      "sin_SINHALA: F1-score = 0.9897, Precision = 0.9796, Recall = 1.0000, Support = 48.0\n",
      "hun_Latin: F1-score = 0.9895, Precision = 0.9792, Recall = 1.0000, Support = 47.0\n",
      "lua_Latin: F1-score = 0.9895, Precision = 0.9792, Recall = 1.0000, Support = 47.0\n",
      "ewe_Latin: F1-score = 0.9892, Precision = 1.0000, Recall = 0.9787, Support = 47.0\n",
      "mya_MYANMAR: F1-score = 0.9890, Precision = 0.9783, Recall = 1.0000, Support = 45.0\n",
      "heb_Hébreu: F1-score = 0.9888, Precision = 0.9778, Recall = 1.0000, Support = 44.0\n",
      "csb_Latin: F1-score = 0.9885, Precision = 1.0000, Recall = 0.9773, Support = 44.0\n",
      "yid_Hébreu: F1-score = 0.9870, Precision = 1.0000, Recall = 0.9744, Support = 39.0\n",
      "kam_Latin: F1-score = 0.9867, Precision = 1.0000, Recall = 0.9737, Support = 38.0\n",
      "tha_Thaï: F1-score = 0.9863, Precision = 0.9730, Recall = 1.0000, Support = 36.0\n",
      "khm_KHMER: F1-score = 0.9855, Precision = 1.0000, Recall = 0.9714, Support = 35.0\n",
      "sag_Latin: F1-score = 0.9841, Precision = 0.9841, Recall = 0.9841, Support = 63.0\n",
      "quc_Latin: F1-score = 0.9836, Precision = 0.9836, Recall = 0.9836, Support = 61.0\n",
      "mwl_Latin: F1-score = 0.9828, Precision = 0.9828, Recall = 0.9828, Support = 58.0\n",
      "isl_Latin: F1-score = 0.9825, Precision = 0.9655, Recall = 1.0000, Support = 56.0\n",
      "snd_Arabe: F1-score = 0.9821, Precision = 0.9821, Recall = 0.9821, Support = 56.0\n",
      "jbo_Latin: F1-score = 0.9811, Precision = 1.0000, Recall = 0.9630, Support = 54.0\n",
      "acr_Latin: F1-score = 0.9808, Precision = 0.9808, Recall = 0.9808, Support = 52.0\n",
      "fij_Latin: F1-score = 0.9804, Precision = 0.9615, Recall = 1.0000, Support = 50.0\n",
      "vol_Latin: F1-score = 0.9804, Precision = 1.0000, Recall = 0.9615, Support = 52.0\n",
      "gom_Latin: F1-score = 0.9792, Precision = 1.0000, Recall = 0.9592, Support = 49.0\n",
      "kmb_Latin: F1-score = 0.9792, Precision = 0.9592, Recall = 1.0000, Support = 47.0\n",
      "xmf_Géorgien: F1-score = 0.9792, Precision = 1.0000, Recall = 0.9592, Support = 49.0\n",
      "hmo_Latin: F1-score = 0.9787, Precision = 0.9583, Recall = 1.0000, Support = 46.0\n",
      "dtp_Latin: F1-score = 0.9783, Precision = 1.0000, Recall = 0.9574, Support = 47.0\n",
      "glv_Latin: F1-score = 0.9783, Precision = 1.0000, Recall = 0.9574, Support = 47.0\n",
      "quh_Latin: F1-score = 0.9756, Precision = 0.9524, Recall = 1.0000, Support = 40.0\n",
      "vie_Latin: F1-score = 0.9744, Precision = 1.0000, Recall = 0.9500, Support = 40.0\n",
      "oss_Cyrillique: F1-score = 0.9735, Precision = 1.0000, Recall = 0.9483, Support = 58.0\n",
      "lit_Latin: F1-score = 0.9730, Precision = 0.9643, Recall = 0.9818, Support = 55.0\n",
      "pms_Latin: F1-score = 0.9730, Precision = 1.0000, Recall = 0.9474, Support = 38.0\n",
      "fur_Latin: F1-score = 0.9709, Precision = 0.9804, Recall = 0.9615, Support = 52.0\n",
      "ilo_Latin: F1-score = 0.9709, Precision = 1.0000, Recall = 0.9434, Support = 53.0\n",
      "frr_Latin: F1-score = 0.9691, Precision = 1.0000, Recall = 0.9400, Support = 50.0\n",
      "ndo_Latin: F1-score = 0.9691, Precision = 0.9592, Recall = 0.9792, Support = 48.0\n",
      "tur_Latin: F1-score = 0.9691, Precision = 0.9592, Recall = 0.9792, Support = 48.0\n",
      "diq_Latin: F1-score = 0.9677, Precision = 0.9783, Recall = 0.9574, Support = 47.0\n",
      "kat_Géorgien: F1-score = 0.9677, Precision = 0.9375, Recall = 1.0000, Support = 45.0\n",
      "lin_Latin: F1-score = 0.9677, Precision = 1.0000, Recall = 0.9375, Support = 48.0\n",
      "sme_Latin: F1-score = 0.9677, Precision = 1.0000, Recall = 0.9375, Support = 48.0\n",
      "tpi_Latin: F1-score = 0.9677, Precision = 1.0000, Recall = 0.9375, Support = 48.0\n",
      "mkd_Cyrillique: F1-score = 0.9667, Precision = 0.9508, Recall = 0.9831, Support = 59.0\n",
      "eml_Latin: F1-score = 0.9649, Precision = 1.0000, Recall = 0.9322, Support = 59.0\n",
      "bul_Cyrillique: F1-score = 0.9647, Precision = 0.9762, Recall = 0.9535, Support = 43.0\n",
      "azb_Arabe: F1-score = 0.9643, Precision = 0.9643, Recall = 0.9643, Support = 56.0\n",
      "kon_Latin: F1-score = 0.9643, Precision = 1.0000, Recall = 0.9310, Support = 58.0\n",
      "swe_Latin: F1-score = 0.9636, Precision = 0.9464, Recall = 0.9815, Support = 54.0\n",
      "cat_Latin: F1-score = 0.9630, Precision = 0.9512, Recall = 0.9750, Support = 40.0\n",
      "kik_Latin: F1-score = 0.9630, Precision = 1.0000, Recall = 0.9286, Support = 42.0\n",
      "mar_Devanagari (Hindi, Sanskrit): F1-score = 0.9630, Precision = 0.9750, Recall = 0.9512, Support = 41.0\n",
      "slv_Latin: F1-score = 0.9630, Precision = 0.9750, Recall = 0.9512, Support = 41.0\n",
      "kea_Latin: F1-score = 0.9615, Precision = 0.9804, Recall = 0.9434, Support = 53.0\n",
      "tum_Latin: F1-score = 0.9608, Precision = 0.9608, Recall = 0.9608, Support = 51.0\n",
      "jam_Latin: F1-score = 0.9593, Precision = 1.0000, Recall = 0.9219, Support = 64.0\n",
      "bam_Latin: F1-score = 0.9592, Precision = 1.0000, Recall = 0.9216, Support = 51.0\n",
      "tyv_Cyrillique: F1-score = 0.9587, Precision = 1.0000, Recall = 0.9206, Support = 63.0\n",
      "cym_Latin: F1-score = 0.9583, Precision = 0.9583, Recall = 0.9583, Support = 48.0\n",
      "fin_Latin: F1-score = 0.9583, Precision = 0.9787, Recall = 0.9388, Support = 49.0\n",
      "amh_Éthiopien: F1-score = 0.9574, Precision = 1.0000, Recall = 0.9184, Support = 49.0\n",
      "dyu_Latin: F1-score = 0.9565, Precision = 0.9167, Recall = 1.0000, Support = 55.0\n",
      "lfn_Latin: F1-score = 0.9565, Precision = 0.9778, Recall = 0.9362, Support = 47.0\n",
      "ell_Grec: F1-score = 0.9558, Precision = 0.9153, Recall = 1.0000, Support = 54.0\n",
      "grc_Grec: F1-score = 0.9558, Precision = 1.0000, Recall = 0.9153, Support = 59.0\n",
      "kaz_Cyrillique: F1-score = 0.9545, Precision = 1.0000, Recall = 0.9130, Support = 46.0\n",
      "tir_Éthiopien: F1-score = 0.9535, Precision = 0.9111, Recall = 1.0000, Support = 41.0\n",
      "ssw_Latin: F1-score = 0.9531, Precision = 0.9683, Recall = 0.9385, Support = 65.0\n",
      "yor_Latin: F1-score = 0.9515, Precision = 1.0000, Recall = 0.9074, Support = 54.0\n",
      "lao_LAO: F1-score = 0.9512, Precision = 0.9286, Recall = 0.9750, Support = 40.0\n",
      "ace_Latin: F1-score = 0.9505, Precision = 0.9796, Recall = 0.9231, Support = 52.0\n",
      "hye_Arménien: F1-score = 0.9505, Precision = 0.9231, Recall = 0.9796, Support = 49.0\n",
      "ido_Latin: F1-score = 0.9500, Precision = 0.9500, Recall = 0.9500, Support = 40.0\n",
      "lug_Latin: F1-score = 0.9495, Precision = 0.9592, Recall = 0.9400, Support = 50.0\n",
      "new_Devanagari (Hindi, Sanskrit): F1-score = 0.9474, Precision = 0.9818, Recall = 0.9153, Support = 59.0\n",
      "vep_Latin: F1-score = 0.9474, Precision = 1.0000, Recall = 0.9000, Support = 50.0\n",
      "slk_Latin: F1-score = 0.9444, Precision = 0.9444, Recall = 0.9444, Support = 54.0\n",
      "udm_Cyrillique: F1-score = 0.9438, Precision = 0.9767, Recall = 0.9130, Support = 46.0\n",
      "rmy_Latin: F1-score = 0.9423, Precision = 0.9800, Recall = 0.9074, Support = 54.0\n",
      "ach_Latin: F1-score = 0.9412, Precision = 0.8889, Recall = 1.0000, Support = 8.0\n",
      "bre_Latin: F1-score = 0.9402, Precision = 0.9649, Recall = 0.9167, Support = 60.0\n",
      "chv_Cyrillique: F1-score = 0.9398, Precision = 1.0000, Recall = 0.8864, Support = 44.0\n",
      "epo_Latin: F1-score = 0.9398, Precision = 0.9750, Recall = 0.9070, Support = 43.0\n",
      "szl_Latin: F1-score = 0.9394, Precision = 0.9688, Recall = 0.9118, Support = 34.0\n",
      "gug_Latin: F1-score = 0.9391, Precision = 0.9000, Recall = 0.9818, Support = 55.0\n",
      "kom_Cyrillique: F1-score = 0.9388, Precision = 0.9583, Recall = 0.9200, Support = 50.0\n",
      "gla_Latin: F1-score = 0.9375, Precision = 0.9783, Recall = 0.9000, Support = 50.0\n",
      "bis_Latin: F1-score = 0.9369, Precision = 0.9811, Recall = 0.8966, Support = 58.0\n",
      "mhr_Cyrillique: F1-score = 0.9369, Precision = 0.9286, Recall = 0.9455, Support = 55.0\n",
      "ful_Latin: F1-score = 0.9348, Precision = 1.0000, Recall = 0.8776, Support = 49.0\n",
      "aln_Latin: F1-score = 0.9346, Precision = 0.9091, Recall = 0.9615, Support = 52.0\n",
      "fao_Latin: F1-score = 0.9320, Precision = 0.9600, Recall = 0.9057, Support = 53.0\n",
      "ces_Latin: F1-score = 0.9318, Precision = 0.9535, Recall = 0.9111, Support = 45.0\n",
      "arg_Latin: F1-score = 0.9310, Precision = 0.9474, Recall = 0.9153, Support = 59.0\n",
      "ibo_Latin: F1-score = 0.9293, Precision = 1.0000, Recall = 0.8679, Support = 53.0\n",
      "san_Devanagari (Hindi, Sanskrit): F1-score = 0.9280, Precision = 0.8788, Recall = 0.9831, Support = 59.0\n",
      "afr_Latin: F1-score = 0.9273, Precision = 0.9444, Recall = 0.9107, Support = 56.0\n",
      "kaa_Latin: F1-score = 0.9273, Precision = 0.9808, Recall = 0.8793, Support = 58.0\n",
      "arz_Arabe: F1-score = 0.9245, Precision = 0.9608, Recall = 0.8909, Support = 55.0\n",
      "npi_Devanagari (Hindi, Sanskrit): F1-score = 0.9242, Precision = 0.9242, Recall = 0.9242, Support = 66.0\n",
      "crh_Cyrillique: F1-score = 0.9231, Precision = 1.0000, Recall = 0.8571, Support = 42.0\n",
      "som_Latin: F1-score = 0.9231, Precision = 0.9767, Recall = 0.8750, Support = 48.0\n",
      "pag_Latin: F1-score = 0.9216, Precision = 1.0000, Recall = 0.8545, Support = 55.0\n",
      "tah_Latin: F1-score = 0.9213, Precision = 1.0000, Recall = 0.8542, Support = 48.0\n",
      "ksh_Latin: F1-score = 0.9206, Precision = 0.9355, Recall = 0.9062, Support = 64.0\n",
      "fry_Latin: F1-score = 0.9200, Precision = 0.9388, Recall = 0.9020, Support = 51.0\n",
      "gle_Latin: F1-score = 0.9189, Precision = 0.8793, Recall = 0.9623, Support = 53.0\n",
      "pis_Latin: F1-score = 0.9189, Precision = 0.8500, Recall = 1.0000, Support = 17.0\n",
      "hsb_Latin: F1-score = 0.9184, Precision = 0.9783, Recall = 0.8654, Support = 52.0\n",
      "ton_Latin: F1-score = 0.9184, Precision = 0.9184, Recall = 0.9184, Support = 49.0\n",
      "pus_Arabe: F1-score = 0.9174, Precision = 0.9615, Recall = 0.8772, Support = 57.0\n",
      "lij_Latin: F1-score = 0.9159, Precision = 0.9074, Recall = 0.9245, Support = 53.0\n",
      "wol_Latin: F1-score = 0.9157, Precision = 0.9268, Recall = 0.9048, Support = 42.0\n",
      "ven_Latin: F1-score = 0.9149, Precision = 1.0000, Recall = 0.8431, Support = 51.0\n",
      "ile_Latin: F1-score = 0.9143, Precision = 0.9231, Recall = 0.9057, Support = 53.0\n",
      "mzn_Arabe: F1-score = 0.9130, Precision = 0.9545, Recall = 0.8750, Support = 48.0\n",
      "pol_Latin: F1-score = 0.9109, Precision = 0.8364, Recall = 1.0000, Support = 46.0\n",
      "jpn_Katakana (Japonais): F1-score = 0.9091, Precision = 0.8333, Recall = 1.0000, Support = 10.0\n",
      "kaa_Cyrillique: F1-score = 0.9091, Precision = 0.9804, Recall = 0.8475, Support = 59.0\n",
      "vls_Latin: F1-score = 0.9091, Precision = 0.8772, Recall = 0.9434, Support = 53.0\n",
      "grn_Latin: F1-score = 0.9053, Precision = 0.9556, Recall = 0.8600, Support = 50.0\n",
      "por_Latin: F1-score = 0.9053, Precision = 0.8958, Recall = 0.9149, Support = 47.0\n",
      "mai_Devanagari (Hindi, Sanskrit): F1-score = 0.9043, Precision = 0.9286, Recall = 0.8814, Support = 59.0\n",
      "gcf_Latin: F1-score = 0.9032, Precision = 1.0000, Recall = 0.8235, Support = 17.0\n",
      "lim_Latin: F1-score = 0.9032, Precision = 0.9130, Recall = 0.8936, Support = 47.0\n",
      "gsw_Latin: F1-score = 0.9014, Precision = 0.8889, Recall = 0.9143, Support = 35.0\n",
      "pnb_Arabe: F1-score = 0.8980, Precision = 0.9167, Recall = 0.8800, Support = 50.0\n",
      "min_Latin: F1-score = 0.8958, Precision = 0.8958, Recall = 0.8958, Support = 48.0\n",
      "hmn_Latin: F1-score = 0.8913, Precision = 1.0000, Recall = 0.8039, Support = 51.0\n",
      "ext_Latin: F1-score = 0.8889, Precision = 0.8980, Recall = 0.8800, Support = 50.0\n",
      "tat_Cyrillique: F1-score = 0.8889, Precision = 0.8125, Recall = 0.9811, Support = 53.0\n",
      "ukr_Cyrillique: F1-score = 0.8889, Precision = 0.8148, Recall = 0.9778, Support = 45.0\n",
      "zlm_Latin: F1-score = 0.8873, Precision = 0.8750, Recall = 0.9000, Support = 70.0\n",
      "myv_Cyrillique: F1-score = 0.8872, Precision = 0.8429, Recall = 0.9365, Support = 63.0\n",
      "ron_Latin: F1-score = 0.8868, Precision = 0.8393, Recall = 0.9400, Support = 50.0\n",
      "tls_Latin: F1-score = 0.8866, Precision = 0.9556, Recall = 0.8269, Support = 52.0\n",
      "quy_Latin: F1-score = 0.8824, Precision = 0.7895, Recall = 1.0000, Support = 45.0\n",
      "pfl_Latin: F1-score = 0.8780, Precision = 0.8780, Recall = 0.8780, Support = 41.0\n",
      "hne_Devanagari (Hindi, Sanskrit): F1-score = 0.8772, Precision = 0.9091, Recall = 0.8475, Support = 59.0\n",
      "lmo_Latin: F1-score = 0.8706, Precision = 0.8409, Recall = 0.9024, Support = 41.0\n",
      "nap_Latin: F1-score = 0.8679, Precision = 0.9200, Recall = 0.8214, Support = 56.0\n",
      "ceb_Latin: F1-score = 0.8675, Precision = 0.9000, Recall = 0.8372, Support = 43.0\n",
      "rap_Latin: F1-score = 0.8636, Precision = 0.9500, Recall = 0.7917, Support = 24.0\n",
      "nno_Latin: F1-score = 0.8605, Precision = 0.7872, Recall = 0.9487, Support = 39.0\n",
      "bod_TIBETAN: F1-score = 0.8600, Precision = 0.7818, Recall = 0.9556, Support = 45.0\n",
      "deu_Latin: F1-score = 0.8600, Precision = 0.8113, Recall = 0.9149, Support = 47.0\n",
      "bih_Devanagari (Hindi, Sanskrit): F1-score = 0.8571, Precision = 0.8077, Recall = 0.9130, Support = 46.0\n",
      "hif_Latin: F1-score = 0.8571, Precision = 0.8125, Recall = 0.9070, Support = 43.0\n",
      "mon_Latin: F1-score = 0.8537, Precision = 0.9211, Recall = 0.7955, Support = 44.0\n",
      "weighted avg: F1-score = 0.8525, Precision = 0.8672, Recall = 0.8514, Support = 19010.0\n",
      "fra_Latin: F1-score = 0.8515, Precision = 0.7818, Recall = 0.9348, Support = 46.0\n",
      "glg_Latin: F1-score = 0.8485, Precision = 0.8400, Recall = 0.8571, Support = 49.0\n",
      "dan_Latin: F1-score = 0.8471, Precision = 0.9000, Recall = 0.8000, Support = 45.0\n",
      "lat_Latin: F1-score = 0.8462, Precision = 0.8000, Recall = 0.8980, Support = 49.0\n",
      "yue_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8462, Precision = 0.8871, Recall = 0.8088, Support = 68.0\n",
      "nds_Latin: F1-score = 0.8387, Precision = 0.7959, Recall = 0.8864, Support = 44.0\n",
      "dzo_TIBETAN: F1-score = 0.8333, Precision = 0.9091, Recall = 0.7692, Support = 52.0\n",
      "hau_Latin: F1-score = 0.8333, Precision = 0.7759, Recall = 0.9000, Support = 50.0\n",
      "macro avg: F1-score = 0.8319, Precision = 0.8460, Recall = 0.8324, Support = 19010.0\n",
      "bsb_Latin: F1-score = 0.8298, Precision = 0.8667, Recall = 0.7959, Support = 49.0\n",
      "bar_Latin: F1-score = 0.8288, Precision = 0.8214, Recall = 0.8364, Support = 55.0\n",
      "nld_Latin: F1-score = 0.8283, Precision = 0.8039, Recall = 0.8542, Support = 48.0\n",
      "pcd_Latin: F1-score = 0.8205, Precision = 0.7742, Recall = 0.8727, Support = 55.0\n",
      "lzh_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8154, Precision = 0.7361, Recall = 0.9138, Support = 58.0\n",
      "hrx_Latin: F1-score = 0.8148, Precision = 1.0000, Recall = 0.6875, Support = 16.0\n",
      "zea_Latin: F1-score = 0.8140, Precision = 0.8333, Recall = 0.7955, Support = 44.0\n",
      "bak_Cyrillique: F1-score = 0.8119, Precision = 0.9535, Recall = 0.7069, Support = 58.0\n",
      "rue_Cyrillique: F1-score = 0.8119, Precision = 0.7193, Recall = 0.9318, Support = 44.0\n",
      "swc_Latin: F1-score = 0.8113, Precision = 0.8776, Recall = 0.7544, Support = 57.0\n",
      "jpn_Hiragana (Japonais): F1-score = 0.8085, Precision = 0.6786, Recall = 1.0000, Support = 19.0\n",
      "mlt_Latin: F1-score = 0.8046, Precision = 0.8537, Recall = 0.7609, Support = 46.0\n",
      "hat_Latin: F1-score = 0.8043, Precision = 0.9024, Recall = 0.7255, Support = 51.0\n",
      "nso_Latin: F1-score = 0.8043, Precision = 0.7872, Recall = 0.8222, Support = 45.0\n",
      "pcm_Latin: F1-score = 0.8027, Precision = 0.7375, Recall = 0.8806, Support = 67.0\n",
      "ast_Latin: F1-score = 0.8000, Precision = 0.7213, Recall = 0.8980, Support = 49.0\n",
      "bjn_Latin: F1-score = 0.8000, Precision = 0.8085, Recall = 0.7917, Support = 48.0\n",
      "uzb_Latin: F1-score = 0.7967, Precision = 0.7538, Recall = 0.8448, Support = 58.0\n",
      "ayr_Latin: F1-score = 0.7885, Precision = 0.6949, Recall = 0.9111, Support = 45.0\n",
      "plt_Latin: F1-score = 0.7850, Precision = 1.0000, Recall = 0.6462, Support = 65.0\n",
      "uig_Latin: F1-score = 0.7848, Precision = 0.9394, Recall = 0.6739, Support = 46.0\n",
      "kur_Latin: F1-score = 0.7820, Precision = 0.6842, Recall = 0.9123, Support = 57.0\n",
      "smo_Latin: F1-score = 0.7816, Precision = 0.9189, Recall = 0.6800, Support = 50.0\n",
      "scn_Latin: F1-score = 0.7805, Precision = 0.8000, Recall = 0.7619, Support = 63.0\n",
      "oci_Latin: F1-score = 0.7765, Precision = 0.8462, Recall = 0.7174, Support = 46.0\n",
      "jav_Latin: F1-score = 0.7708, Precision = 0.7708, Recall = 0.7708, Support = 48.0\n",
      "nep_Devanagari (Hindi, Sanskrit): F1-score = 0.7619, Precision = 0.7805, Recall = 0.7442, Support = 43.0\n",
      "haw_Latin: F1-score = 0.7595, Precision = 0.9091, Recall = 0.6522, Support = 46.0\n",
      "prs_Arabe: F1-score = 0.7581, Precision = 0.6714, Recall = 0.8704, Support = 54.0\n",
      "est_Latin: F1-score = 0.7573, Precision = 0.8298, Recall = 0.6964, Support = 56.0\n",
      "srd_Latin: F1-score = 0.7551, Precision = 0.9024, Recall = 0.6491, Support = 57.0\n",
      "bew_Cyrillique: F1-score = 0.7547, Precision = 0.7273, Recall = 0.7843, Support = 51.0\n",
      "ekk_Latin: F1-score = 0.7527, Precision = 0.6863, Recall = 0.8333, Support = 42.0\n",
      "kat_Latin: F1-score = 0.7521, Precision = 0.7213, Recall = 0.7857, Support = 56.0\n",
      "mlg_Latin: F1-score = 0.7520, Precision = 0.6620, Recall = 0.8704, Support = 54.0\n",
      "que_Latin: F1-score = 0.7500, Precision = 0.9677, Recall = 0.6122, Support = 49.0\n",
      "tsn_Latin: F1-score = 0.7391, Precision = 0.7391, Recall = 0.7391, Support = 46.0\n",
      "cmn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.7381, Precision = 0.6327, Recall = 0.8857, Support = 35.0\n",
      "kab_Latin: F1-score = 0.7368, Precision = 0.6269, Recall = 0.8936, Support = 47.0\n",
      "ina_Latin: F1-score = 0.7347, Precision = 0.7200, Recall = 0.7500, Support = 48.0\n",
      "ber_Latin: F1-score = 0.7216, Precision = 0.8750, Recall = 0.6140, Support = 57.0\n",
      "cbk_Latin: F1-score = 0.7216, Precision = 0.7292, Recall = 0.7143, Support = 49.0\n",
      "nya_Latin: F1-score = 0.7209, Precision = 0.8378, Recall = 0.6327, Support = 49.0\n",
      "hbs_Cyrillique: F1-score = 0.7179, Precision = 0.6562, Recall = 0.7925, Support = 53.0\n",
      "aka_Latin: F1-score = 0.7097, Precision = 0.7500, Recall = 0.6735, Support = 49.0\n",
      "bak_Latin: F1-score = 0.7071, Precision = 0.6863, Recall = 0.7292, Support = 48.0\n",
      "kmr_Latin: F1-score = 0.7059, Precision = 0.9677, Recall = 0.5556, Support = 54.0\n",
      "bel_Cyrillique: F1-score = 0.7010, Precision = 0.7556, Recall = 0.6538, Support = 52.0\n",
      "nbl_Latin: F1-score = 0.7010, Precision = 0.5574, Recall = 0.9444, Support = 36.0\n",
      "wuu_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6947, Precision = 0.6875, Recall = 0.7021, Support = 47.0\n",
      "jpn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6923, Precision = 1.0000, Recall = 0.5294, Support = 17.0\n",
      "hin_Devanagari (Hindi, Sanskrit): F1-score = 0.6852, Precision = 0.6379, Recall = 0.7400, Support = 50.0\n",
      "wln_Latin: F1-score = 0.6804, Precision = 0.7021, Recall = 0.6600, Support = 50.0\n",
      "ltz_Latin: F1-score = 0.6800, Precision = 0.5965, Recall = 0.7907, Support = 43.0\n",
      "spa_Latin: F1-score = 0.6792, Precision = 0.6207, Recall = 0.7500, Support = 48.0\n",
      "twi_Latin: F1-score = 0.6792, Precision = 0.6667, Recall = 0.6923, Support = 52.0\n",
      "dzo_Latin: F1-score = 0.6667, Precision = 1.0000, Recall = 0.5000, Support = 4.0\n",
      "hil_Latin: F1-score = 0.6667, Precision = 0.8000, Recall = 0.5714, Support = 7.0\n",
      "mri_Latin: F1-score = 0.6667, Precision = 0.8387, Recall = 0.5532, Support = 47.0\n",
      "run_Latin: F1-score = 0.6610, Precision = 0.5652, Recall = 0.7959, Support = 49.0\n",
      "arb_Arabe: F1-score = 0.6565, Precision = 0.5584, Recall = 0.7963, Support = 54.0\n",
      "xho_Latin: F1-score = 0.6500, Precision = 0.8966, Recall = 0.5098, Support = 51.0\n",
      "ban_Latin: F1-score = 0.6471, Precision = 0.7333, Recall = 0.5789, Support = 57.0\n",
      "gor_Latin: F1-score = 0.6429, Precision = 0.9474, Recall = 0.4865, Support = 37.0\n",
      "glk_Arabe: F1-score = 0.6353, Precision = 0.6750, Recall = 0.6000, Support = 45.0\n",
      "war_Latin: F1-score = 0.6353, Precision = 0.6279, Recall = 0.6429, Support = 42.0\n",
      "ckb_Arabe: F1-score = 0.6333, Precision = 0.5135, Recall = 0.8261, Support = 46.0\n",
      "aym_Latin: F1-score = 0.6234, Precision = 0.8889, Recall = 0.4800, Support = 50.0\n",
      "ita_Latin: F1-score = 0.6186, Precision = 0.5556, Recall = 0.6977, Support = 43.0\n",
      "tgl_Latin: F1-score = 0.6126, Precision = 0.6800, Recall = 0.5574, Support = 61.0\n",
      "urd_Arabe: F1-score = 0.6061, Precision = 0.4878, Recall = 0.8000, Support = 50.0\n",
      "sqi_Latin: F1-score = 0.6042, Precision = 0.5179, Recall = 0.7250, Support = 40.0\n",
      "swa_Latin: F1-score = 0.5979, Precision = 0.5918, Recall = 0.6042, Support = 48.0\n",
      "ory_ORIYA: F1-score = 0.5926, Precision = 0.5581, Recall = 0.6316, Support = 38.0\n",
      "aze_Latin: F1-score = 0.5859, Precision = 0.5800, Recall = 0.5918, Support = 49.0\n",
      "pes_Arabe: F1-score = 0.5854, Precision = 0.6316, Recall = 0.5455, Support = 44.0\n",
      "hbs_Latin: F1-score = 0.5833, Precision = 0.4421, Recall = 0.8571, Support = 49.0\n",
      "aze_Arabe: F1-score = 0.5827, Precision = 0.5781, Recall = 0.5873, Support = 63.0\n",
      "swh_Latin: F1-score = 0.5773, Precision = 0.5490, Recall = 0.6087, Support = 46.0\n",
      "srp_Cyrillique: F1-score = 0.5750, Precision = 0.6571, Recall = 0.5111, Support = 45.0\n",
      "nob_Latin: F1-score = 0.5714, Precision = 0.5357, Recall = 0.6122, Support = 49.0\n",
      "ori_ORIYA: F1-score = 0.5714, Precision = 0.6111, Recall = 0.5366, Support = 41.0\n",
      "sot_Latin: F1-score = 0.5714, Precision = 0.6667, Recall = 0.5000, Support = 60.0\n",
      "sun_Latin: F1-score = 0.5679, Precision = 0.6053, Recall = 0.5349, Support = 43.0\n",
      "azj_Latin: F1-score = 0.5625, Precision = 0.5745, Recall = 0.5510, Support = 49.0\n",
      "bik_Latin: F1-score = 0.5455, Precision = 0.5333, Recall = 0.5581, Support = 43.0\n",
      "lao_Latin: F1-score = 0.5455, Precision = 0.6000, Recall = 0.5000, Support = 6.0\n",
      "zho_Kanji (Chinois, Japonais, Coréen): F1-score = 0.5417, Precision = 0.7647, Recall = 0.4194, Support = 62.0\n",
      "srp_Latin: F1-score = 0.5400, Precision = 0.6000, Recall = 0.4909, Support = 55.0\n",
      "pam_Latin: F1-score = 0.5294, Precision = 0.4821, Recall = 0.5870, Support = 46.0\n",
      "mad_Latin: F1-score = 0.5273, Precision = 0.5273, Recall = 0.5273, Support = 55.0\n",
      "bcl_Latin: F1-score = 0.5254, Precision = 0.5082, Recall = 0.5439, Support = 57.0\n",
      "guj_Devanagari (Hindi, Sanskrit): F1-score = 0.5243, Precision = 0.5400, Recall = 0.5094, Support = 53.0\n",
      "tat_Latin: F1-score = 0.5205, Precision = 0.7600, Recall = 0.3958, Support = 48.0\n",
      "cos_Latin: F1-score = 0.5169, Precision = 0.6389, Recall = 0.4340, Support = 53.0\n",
      "sna_Latin: F1-score = 0.5075, Precision = 0.8947, Recall = 0.3542, Support = 48.0\n",
      "nor_Latin: F1-score = 0.5057, Precision = 0.5366, Recall = 0.4783, Support = 46.0\n",
      "khm_Latin: F1-score = 0.5000, Precision = 0.3333, Recall = 1.0000, Support = 1.0\n",
      "san_Latin: F1-score = 0.5000, Precision = 0.5000, Recall = 0.5000, Support = 6.0\n",
      "vec_Latin: F1-score = 0.4948, Precision = 0.4138, Recall = 0.6154, Support = 39.0\n",
      "kur_Arabe: F1-score = 0.4828, Precision = 0.7241, Recall = 0.3621, Support = 58.0\n",
      "tgk_Cyrillique: F1-score = 0.4750, Precision = 0.6129, Recall = 0.3878, Support = 49.0\n",
      "tuk_Cyrillique: F1-score = 0.4681, Precision = 0.3667, Recall = 0.6471, Support = 17.0\n",
      "sco_Latin: F1-score = 0.4679, Precision = 0.3400, Recall = 0.7500, Support = 68.0\n",
      "ara_Arabe: F1-score = 0.4663, Precision = 0.3486, Recall = 0.7037, Support = 54.0\n",
      "uzn_Cyrillique: F1-score = 0.4646, Precision = 0.5000, Recall = 0.4340, Support = 53.0\n",
      "kin_Latin: F1-score = 0.4634, Precision = 0.4524, Recall = 0.4750, Support = 40.0\n",
      "apc_Arabe: F1-score = 0.4615, Precision = 0.4154, Recall = 0.5192, Support = 52.0\n",
      "zul_Latin: F1-score = 0.4595, Precision = 0.6296, Recall = 0.3617, Support = 47.0\n",
      "ary_Arabe: F1-score = 0.4571, Precision = 0.4706, Recall = 0.4444, Support = 54.0\n",
      "nde_Latin: F1-score = 0.4557, Precision = 0.5000, Recall = 0.4186, Support = 43.0\n",
      "tgk_Latin: F1-score = 0.4524, Precision = 0.5278, Recall = 0.3958, Support = 48.0\n",
      "fas_Arabe: F1-score = 0.4444, Precision = 0.4000, Recall = 0.5000, Support = 44.0\n",
      "guj_Latin: F1-score = 0.4444, Precision = 0.5000, Recall = 0.4000, Support = 5.0\n",
      "fil_Latin: F1-score = 0.4198, Precision = 0.4048, Recall = 0.4359, Support = 39.0\n",
      "acm_Arabe: F1-score = 0.4186, Precision = 0.5806, Recall = 0.3273, Support = 55.0\n",
      "ind_Latin: F1-score = 0.4146, Precision = 0.3696, Recall = 0.4722, Support = 36.0\n",
      "als_Latin: F1-score = 0.4127, Precision = 0.5652, Recall = 0.3250, Support = 40.0\n",
      "enm_Latin: F1-score = 0.4000, Precision = 0.5000, Recall = 0.3333, Support = 3.0\n",
      "hau_Arabe: F1-score = 0.3871, Precision = 0.6667, Recall = 0.2727, Support = 66.0\n",
      "eng_Latin: F1-score = 0.3786, Precision = 0.2566, Recall = 0.7222, Support = 54.0\n",
      "ajp_Arabe: F1-score = 0.3778, Precision = 0.3091, Recall = 0.4857, Support = 35.0\n",
      "msa_Latin: F1-score = 0.3750, Precision = 0.3158, Recall = 0.4615, Support = 52.0\n",
      "zsm_Latin: F1-score = 0.3678, Precision = 0.3404, Recall = 0.4000, Support = 40.0\n",
      "uzb_Cyrillique: F1-score = 0.3226, Precision = 0.2597, Recall = 0.4255, Support = 47.0\n",
      "hin_Latin: F1-score = 0.3188, Precision = 0.2444, Recall = 0.4583, Support = 48.0\n",
      "afb_Arabe: F1-score = 0.3023, Precision = 0.3421, Recall = 0.2708, Support = 48.0\n",
      "tgk_Arabe: F1-score = 0.2817, Precision = 0.4167, Recall = 0.2128, Support = 47.0\n",
      "bos_Latin: F1-score = 0.2278, Precision = 0.3103, Recall = 0.1800, Support = 50.0\n",
      "som_Arabe: F1-score = 0.2258, Precision = 0.7778, Recall = 0.1321, Support = 53.0\n",
      "hrv_Latin: F1-score = 0.1724, Precision = 0.2273, Recall = 0.1389, Support = 36.0\n",
      "hyw_Arménien: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 4.0\n",
      "ksw_MYANMAR: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "mai_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "ngl_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "pus_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "quz_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sin_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "tha_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtenir les indices des classes présentes dans y_val\n",
    "present_classes = np.unique(np.concatenate((y_val, predictions)))\n",
    "\n",
    "# Extraire uniquement les noms correspondants\n",
    "filtered_target_names = [le.classes_[i] for i in present_classes]\n",
    "\n",
    "# Générer le rapport de classification sous forme de dictionnaire\n",
    "report = classification_report(y_val, predictions, target_names=filtered_target_names, output_dict=True)\n",
    "\n",
    "# Filtrer les classes (en excluant 'accuracy', 'macro avg', 'weighted avg')\n",
    "filtered_report = {label: metrics for label, metrics in report.items() if isinstance(metrics, dict)}\n",
    "\n",
    "# Trier les langues par F1-score de manière décroissante\n",
    "sorted_report = sorted(filtered_report.items(), key=lambda x: x[1]['f1-score'], reverse=True)\n",
    "\n",
    "# Afficher le rapport trié\n",
    "print(\"Classification Report (trié par F1-score décroissant):\\n\")\n",
    "for label, metrics in sorted_report:\n",
    "    print(f\"{label}: F1-score = {metrics['f1-score']:.4f}, Precision = {metrics['precision']:.4f}, Recall = {metrics['recall']:.4f}, Support = {metrics['support']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('acm_Arabe'): {'precision': 0.5806451612903226,\n",
       "  'recall': 0.32727272727272727,\n",
       "  'f1-score': 0.4186046511627907,\n",
       "  'support': 55.0},\n",
       " np.str_('afb_Arabe'): {'precision': 0.34210526315789475,\n",
       "  'recall': 0.2708333333333333,\n",
       "  'f1-score': 0.3023255813953488,\n",
       "  'support': 48.0},\n",
       " np.str_('ajp_Arabe'): {'precision': 0.3090909090909091,\n",
       "  'recall': 0.4857142857142857,\n",
       "  'f1-score': 0.37777777777777777,\n",
       "  'support': 35.0},\n",
       " np.str_('als_Latin'): {'precision': 0.5652173913043478,\n",
       "  'recall': 0.325,\n",
       "  'f1-score': 0.4126984126984127,\n",
       "  'support': 40.0},\n",
       " np.str_('apc_Arabe'): {'precision': 0.4153846153846154,\n",
       "  'recall': 0.5192307692307693,\n",
       "  'f1-score': 0.46153846153846156,\n",
       "  'support': 52.0},\n",
       " np.str_('ara_Arabe'): {'precision': 0.3486238532110092,\n",
       "  'recall': 0.7037037037037037,\n",
       "  'f1-score': 0.4662576687116564,\n",
       "  'support': 54.0},\n",
       " np.str_('ary_Arabe'): {'precision': 0.47058823529411764,\n",
       "  'recall': 0.4444444444444444,\n",
       "  'f1-score': 0.45714285714285713,\n",
       "  'support': 54.0},\n",
       " np.str_('bos_Latin'): {'precision': 0.3103448275862069,\n",
       "  'recall': 0.18,\n",
       "  'f1-score': 0.22784810126582278,\n",
       "  'support': 50.0},\n",
       " np.str_('eng_Latin'): {'precision': 0.2565789473684211,\n",
       "  'recall': 0.7222222222222222,\n",
       "  'f1-score': 0.3786407766990291,\n",
       "  'support': 54.0},\n",
       " np.str_('enm_Latin'): {'precision': 0.5,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1-score': 0.4,\n",
       "  'support': 3.0},\n",
       " np.str_('fas_Arabe'): {'precision': 0.4,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.4444444444444444,\n",
       "  'support': 44.0},\n",
       " np.str_('fil_Latin'): {'precision': 0.40476190476190477,\n",
       "  'recall': 0.4358974358974359,\n",
       "  'f1-score': 0.41975308641975306,\n",
       "  'support': 39.0},\n",
       " np.str_('guj_Latin'): {'precision': 0.5,\n",
       "  'recall': 0.4,\n",
       "  'f1-score': 0.4444444444444444,\n",
       "  'support': 5.0},\n",
       " np.str_('hau_Arabe'): {'precision': 0.6666666666666666,\n",
       "  'recall': 0.2727272727272727,\n",
       "  'f1-score': 0.3870967741935484,\n",
       "  'support': 66.0},\n",
       " np.str_('hin_Latin'): {'precision': 0.24444444444444444,\n",
       "  'recall': 0.4583333333333333,\n",
       "  'f1-score': 0.3188405797101449,\n",
       "  'support': 48.0},\n",
       " np.str_('hrv_Latin'): {'precision': 0.22727272727272727,\n",
       "  'recall': 0.1388888888888889,\n",
       "  'f1-score': 0.1724137931034483,\n",
       "  'support': 36.0},\n",
       " np.str_('hyw_Arménien'): {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 4.0},\n",
       " np.str_('ind_Latin'): {'precision': 0.3695652173913043,\n",
       "  'recall': 0.4722222222222222,\n",
       "  'f1-score': 0.4146341463414634,\n",
       "  'support': 36.0},\n",
       " np.str_('kin_Latin'): {'precision': 0.4523809523809524,\n",
       "  'recall': 0.475,\n",
       "  'f1-score': 0.4634146341463415,\n",
       "  'support': 40.0},\n",
       " np.str_('ksw_MYANMAR'): {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " np.str_('kur_Arabe'): {'precision': 0.7241379310344828,\n",
       "  'recall': 0.3620689655172414,\n",
       "  'f1-score': 0.4827586206896552,\n",
       "  'support': 58.0},\n",
       " np.str_('mai_Latin'): {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " np.str_('msa_Latin'): {'precision': 0.3157894736842105,\n",
       "  'recall': 0.46153846153846156,\n",
       "  'f1-score': 0.375,\n",
       "  'support': 52.0},\n",
       " np.str_('nde_Latin'): {'precision': 0.5,\n",
       "  'recall': 0.4186046511627907,\n",
       "  'f1-score': 0.45569620253164556,\n",
       "  'support': 43.0},\n",
       " np.str_('ngl_Latin'): {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " np.str_('pus_Latin'): {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 0.0},\n",
       " np.str_('quz_Latin'): {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " np.str_('sco_Latin'): {'precision': 0.34,\n",
       "  'recall': 0.75,\n",
       "  'f1-score': 0.46788990825688076,\n",
       "  'support': 68.0},\n",
       " np.str_('sin_Latin'): {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " np.str_('som_Arabe'): {'precision': 0.7777777777777778,\n",
       "  'recall': 0.1320754716981132,\n",
       "  'f1-score': 0.22580645161290322,\n",
       "  'support': 53.0},\n",
       " np.str_('tgk_Arabe'): {'precision': 0.4166666666666667,\n",
       "  'recall': 0.2127659574468085,\n",
       "  'f1-score': 0.28169014084507044,\n",
       "  'support': 47.0},\n",
       " np.str_('tgk_Cyrillique'): {'precision': 0.6129032258064516,\n",
       "  'recall': 0.3877551020408163,\n",
       "  'f1-score': 0.475,\n",
       "  'support': 49.0},\n",
       " np.str_('tgk_Latin'): {'precision': 0.5277777777777778,\n",
       "  'recall': 0.3958333333333333,\n",
       "  'f1-score': 0.4523809523809524,\n",
       "  'support': 48.0},\n",
       " np.str_('tha_Latin'): {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1.0},\n",
       " np.str_('tuk_Cyrillique'): {'precision': 0.36666666666666664,\n",
       "  'recall': 0.6470588235294118,\n",
       "  'f1-score': 0.46808510638297873,\n",
       "  'support': 17.0},\n",
       " np.str_('uzb_Cyrillique'): {'precision': 0.2597402597402597,\n",
       "  'recall': 0.425531914893617,\n",
       "  'f1-score': 0.3225806451612903,\n",
       "  'support': 47.0},\n",
       " np.str_('uzn_Cyrillique'): {'precision': 0.5,\n",
       "  'recall': 0.4339622641509434,\n",
       "  'f1-score': 0.46464646464646464,\n",
       "  'support': 53.0},\n",
       " np.str_('vec_Latin'): {'precision': 0.41379310344827586,\n",
       "  'recall': 0.6153846153846154,\n",
       "  'f1-score': 0.4948453608247423,\n",
       "  'support': 39.0},\n",
       " np.str_('zsm_Latin'): {'precision': 0.3404255319148936,\n",
       "  'recall': 0.4,\n",
       "  'f1-score': 0.367816091954023,\n",
       "  'support': 40.0},\n",
       " np.str_('zul_Latin'): {'precision': 0.6296296296296297,\n",
       "  'recall': 0.3617021276595745,\n",
       "  'f1-score': 0.4594594594594595,\n",
       "  'support': 47.0}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract labels that have lower than 0.5 F1-score\n",
    "labels_to_improve = {label: metrics for label, metrics in filtered_report.items() if metrics['f1-score'] < 0.5}\n",
    "labels_to_improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85817</th>\n",
       "      <td>Public</td>\n",
       "      <td>وزیراعظم پیروں کی اولاد ہیں لینے پر آئیں تو در...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80221</th>\n",
       "      <td>Public</td>\n",
       "      <td>یہ آئین و قانون اور متاثرہ عوام کے درمیان بڑے...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137438</th>\n",
       "      <td>Public</td>\n",
       "      <td>لَوْ لاَ الشُّيُوخُ الرُكَّعُ وَاْلبَهائِمُ ال...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26667</th>\n",
       "      <td>Public</td>\n",
       "      <td>فقر اوہ جنہاں فکر ن کوئی جیڑھے رب دے راہ وکانے</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50294</th>\n",
       "      <td>Public</td>\n",
       "      <td>قال سلمان وإن هذا لكائن يا رسول الله قال صلى ا...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text      Label\n",
       "85817   Public  وزیراعظم پیروں کی اولاد ہیں لینے پر آئیں تو در...  tgk_Arabe\n",
       "80221   Public  یہ آئین و قانون اور متاثرہ عوام کے درمیان بڑے...  tgk_Arabe\n",
       "137438  Public  لَوْ لاَ الشُّيُوخُ الرُكَّعُ وَاْلبَهائِمُ ال...  tgk_Arabe\n",
       "26667   Public     فقر اوہ جنہاں فکر ن کوئی جیڑھے رب دے راہ وکانے  tgk_Arabe\n",
       "50294   Public  قال سلمان وإن هذا لكائن يا رسول الله قال صلى ا...  tgk_Arabe"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set_first_version[val_set_first_version['Label'] == \"tgk_Arabe\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième approche avec SentencePiece comme tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération d'un fichier brut .txt pour entraîner SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus enregistré : corpus_multilingue.txt, avec 190599 phrases.\n"
     ]
    }
   ],
   "source": [
    "# Extraire uniquement la colonne \"Text\"\n",
    "corpus_path = \"corpus_multilingue.txt\"  # Chemin de sortie pour le corpus\n",
    "data_train_preprocessed_for_corpus = data_train.copy()\n",
    "data_train_preprocessed_for_corpus = pre_processing(data_train_preprocessed_for_corpus, remove_espace=False, not_test=False, need_to_clean=True)\n",
    "data_train_preprocessed_for_corpus[\"Text\"].dropna().to_csv(corpus_path, index=False, header=False, sep=\"\\n\")\n",
    "\n",
    "print(f\"Corpus enregistré : {corpus_path}, avec {len(data_train)} phrases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement de SentencePiece et chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./corpus_multilingue.txt\n",
      "  input_format: \n",
      "  model_prefix: sp_model\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 60000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ./corpus_multilingue.txt\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (4363 > 4192).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 190421 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 178 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=26027198\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=8558\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 190421 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=12303137\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 1008558 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 190421\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 1108119\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 1108119 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=558877 obj=17.4577 num_tokens=2624531 num_tokens/piece=4.69608\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=481688 obj=16.2142 num_tokens=2638776 num_tokens/piece=5.47819\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=360984 obj=16.2329 num_tokens=2718022 num_tokens/piece=7.52948\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=360201 obj=16.1747 num_tokens=2719808 num_tokens/piece=7.55081\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=270081 obj=16.364 num_tokens=2849142 num_tokens/piece=10.5492\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=270018 obj=16.2952 num_tokens=2850182 num_tokens/piece=10.5555\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=202503 obj=16.6078 num_tokens=3006355 num_tokens/piece=14.846\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=202492 obj=16.5142 num_tokens=3007668 num_tokens/piece=14.8533\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=151869 obj=16.9066 num_tokens=3172942 num_tokens/piece=20.8926\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=151868 obj=16.8042 num_tokens=3173692 num_tokens/piece=20.8977\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=113900 obj=17.254 num_tokens=3344325 num_tokens/piece=29.3619\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=113900 obj=17.1512 num_tokens=3345143 num_tokens/piece=29.3691\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=85425 obj=17.651 num_tokens=3521664 num_tokens/piece=41.2252\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=85424 obj=17.5465 num_tokens=3522692 num_tokens/piece=41.2377\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=66000 obj=18.0291 num_tokens=3685929 num_tokens/piece=55.8474\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=66000 obj=17.9329 num_tokens=3687266 num_tokens/piece=55.8677\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: sp_model.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: sp_model.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input='./corpus_multilingue.txt',  \n",
    "    model_prefix='sp_model',\n",
    "    vocab_size=60000,  \n",
    "    character_coverage=1.0,  \n",
    "    model_type='unigram'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='sp_model.model')\n",
    "\n",
    "def sentencepiece_tokenize(text):\n",
    "    \"\"\"Tokenise un texte en sous-mots avec SentencePiece\"\"\"\n",
    "    return ' '.join(sp.encode(text, out_type=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le tokenizer sur du texte pré-traité en revanche on l'infère sur du texte brut car il est capable de le gérer directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_second_version = train_set.copy()\n",
    "val_set_second_version = val_set.copy()\n",
    "# train_set_second_version = pre_processing(train_set_second_version, remove_espace=False, not_test=True, need_to_clean=False)\n",
    "# val_set_second_version = pre_processing(val_set_second_version, remove_espace=False, not_test=True, need_to_clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171089/171089 [00:06<00:00, 25803.89it/s]\n",
      "100%|██████████| 19010/19010 [00:00<00:00, 24985.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set_second_version = add_alphabet_to_label(train_set_second_version)\n",
    "val_set_second_version = add_alphabet_to_label(val_set_second_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171089/171089 [00:03<00:00, 44226.84it/s]\n",
      "100%|██████████| 19010/19010 [00:00<00:00, 43784.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Appliquer SentencePiece \n",
    "train_set_second_version['Text'] = train_set_second_version['Text'].progress_apply(sentencepiece_tokenize)\n",
    "val_set_second_version['Text'] = val_set_second_version['Text'].progress_apply(sentencepiece_tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en place de la même pipeline que précédemment, on a juste tokenizé en amont les phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000, ngram_range=(1, 4))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.001, fit_prior=False)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char', max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                ('mnb', MultinomialNB(alpha=0.001, fit_prior=False))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer_sp = TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4), max_features=200000)\n",
    "naive_bayes_sp = MultinomialNB(alpha= 0.001, fit_prior = False) \n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer_sp),\n",
    "    ('mnb', naive_bayes_sp)\n",
    "])\n",
    "\n",
    "x_train_sp = train_set_second_version['Text'].tolist()\n",
    "y_train_sp = train_set_second_version['Label'].tolist()\n",
    "x_val_sp = val_set_second_version['Text'].tolist()\n",
    "y_val_sp = val_set_second_version['Label'].tolist()\n",
    "y_total_sp = y_train_sp + y_val_sp\n",
    "\n",
    "# converting categorical variables to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_sp = LabelEncoder()\n",
    "le_sp.fit(y_total_sp)\n",
    "\n",
    "y_train_sp = le_sp.transform(y_train_sp)\n",
    "y_val_sp = le_sp.transform(y_val_sp)\n",
    "label_mapping = dict(zip(le_sp.classes_, range(len(le_sp.classes_))))\n",
    "\n",
    "\n",
    "pipeline.fit(x_train_sp, y_train_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8531825355076276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "predictions_sp = pipeline.predict(x_val_sp)\n",
    "accuracy_sp = accuracy_score(y_val_sp, predictions_sp)\n",
    "print(\"Accuracy:\", accuracy_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des labels originaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_sp = le_sp.inverse_transform(predictions_sp)\n",
    "labels_to_predict = le_sp.inverse_transform(y_val_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def restore_original_label(label):\n",
    "    return label.split(\"_\")[0]  # Prend seulement la première partie avant '_'\n",
    "\n",
    "def restore_labels(liste):\n",
    "    new_liste = []\n",
    "    for element in tqdm(liste): \n",
    "        new_liste.append(restore_original_label(element))\n",
    "    return np.array(new_liste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19010/19010 [00:00<00:00, 2964740.06it/s]\n",
      "100%|██████████| 19010/19010 [00:00<00:00, 1633720.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8548658600736454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_prediction = restore_labels(predicted_labels_sp)\n",
    "val_to_predict = restore_labels(labels_to_predict)\n",
    "final_accuracy = accuracy_score(val_to_predict, final_prediction)\n",
    "print(\"Accuracy:\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_classes_sp = np.unique(np.concatenate((y_val_sp, predictions_sp)))\n",
    "\n",
    "# Extraire uniquement les noms correspondants\n",
    "filtered_target_names_sp = [le_sp.classes_[i] for i in present_classes_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (trié par F1-score décroissant):\n",
      "\n",
      "abk_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "ach_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 8.0\n",
      "ahk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "alt_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "aoj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "arn_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 63.0\n",
      "asm_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 44.0\n",
      "bem_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 38.0\n",
      "bpy_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "bqc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "bzj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 43.0\n",
      "cab_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "cak_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "ces_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "chk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "cjk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "csy_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "ctu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "cuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "div_THAANA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 39.0\n",
      "djk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "fon_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 44.0\n",
      "gom_Devanagari (Hindi, Sanskrit): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 40.0\n",
      "guc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "guj_GUJARATI: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "gym_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "hbo_Hébreu: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "hnj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "hui_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 43.0\n",
      "hus_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "iba_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "ikk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "iku_CANADIAN: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 61.0\n",
      "ixl_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "kac_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "kal_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "kan_KANNADA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "kbp_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "kek_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 43.0\n",
      "khm_KHMER: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 35.0\n",
      "khm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "kjb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 40.0\n",
      "kjh_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 51.0\n",
      "kmb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 47.0\n",
      "knv_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 51.0\n",
      "kor_Hangul (Coréen): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "kpg_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 56.0\n",
      "ksd_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "ksw_MYANMAR: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "lhu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 20.0\n",
      "lue_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "luo_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "lus_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "lvs_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "mah_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 2.0\n",
      "mal_MALAYALAM: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 44.0\n",
      "mam_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "mau_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "mco_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "meu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 61.0\n",
      "mgh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 45.0\n",
      "mon_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "mps_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "mzh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 44.0\n",
      "naq_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 59.0\n",
      "nav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "nch_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "ncj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 39.0\n",
      "ngu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 49.0\n",
      "nnb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "nyu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 42.0\n",
      "orm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 63.0\n",
      "ote_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "pan_GURMUKHI: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 52.0\n",
      "poh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "pon_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 47.0\n",
      "qub_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 2.0\n",
      "qvi_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "rop_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 42.0\n",
      "rug_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 50.0\n",
      "seh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 51.0\n",
      "srm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 63.0\n",
      "srn_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 46.0\n",
      "suz_Devanagari (Hindi, Sanskrit): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "tam_Tamoul: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "tbz_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 55.0\n",
      "tca_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 43.0\n",
      "tdt_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 38.0\n",
      "tlh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 41.0\n",
      "toj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 48.0\n",
      "tok_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "top_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 51.0\n",
      "tso_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 61.0\n",
      "tuc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 59.0\n",
      "tuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "tzo_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "uig_Arabe: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 58.0\n",
      "umb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 52.0\n",
      "vie_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 40.0\n",
      "wal_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 63.0\n",
      "xav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 61.0\n",
      "yao_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 57.0\n",
      "yom_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 53.0\n",
      "zai_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 54.0\n",
      "kir_Cyrillique: F1-score = 0.9920, Precision = 0.9841, Recall = 1.0000, Support = 62.0\n",
      "sgs_Latin: F1-score = 0.9917, Precision = 1.0000, Recall = 0.9836, Support = 61.0\n",
      "kbd_Cyrillique: F1-score = 0.9908, Precision = 1.0000, Recall = 0.9818, Support = 55.0\n",
      "pap_Latin: F1-score = 0.9908, Precision = 1.0000, Recall = 0.9818, Support = 55.0\n",
      "roh_Latin: F1-score = 0.9908, Precision = 0.9818, Recall = 1.0000, Support = 54.0\n",
      "eus_Latin: F1-score = 0.9907, Precision = 1.0000, Recall = 0.9815, Support = 54.0\n",
      "quw_Latin: F1-score = 0.9907, Precision = 1.0000, Recall = 0.9815, Support = 54.0\n",
      "slk_Latin: F1-score = 0.9907, Precision = 1.0000, Recall = 0.9815, Support = 54.0\n",
      "sat_OL: F1-score = 0.9905, Precision = 0.9811, Recall = 1.0000, Support = 52.0\n",
      "mos_Latin: F1-score = 0.9903, Precision = 1.0000, Recall = 0.9808, Support = 52.0\n",
      "kos_Latin: F1-score = 0.9901, Precision = 1.0000, Recall = 0.9804, Support = 51.0\n",
      "yap_Latin: F1-score = 0.9901, Precision = 0.9804, Recall = 1.0000, Support = 50.0\n",
      "che_Cyrillique: F1-score = 0.9899, Precision = 1.0000, Recall = 0.9800, Support = 50.0\n",
      "sin_SINHALA: F1-score = 0.9897, Precision = 0.9796, Recall = 1.0000, Support = 48.0\n",
      "xmf_Géorgien: F1-score = 0.9897, Precision = 1.0000, Recall = 0.9796, Support = 49.0\n",
      "hun_Latin: F1-score = 0.9895, Precision = 0.9792, Recall = 1.0000, Support = 47.0\n",
      "ewe_Latin: F1-score = 0.9892, Precision = 1.0000, Recall = 0.9787, Support = 47.0\n",
      "lua_Latin: F1-score = 0.9892, Precision = 1.0000, Recall = 0.9787, Support = 47.0\n",
      "mya_MYANMAR: F1-score = 0.9890, Precision = 0.9783, Recall = 1.0000, Support = 45.0\n",
      "heb_Hébreu: F1-score = 0.9888, Precision = 0.9778, Recall = 1.0000, Support = 44.0\n",
      "kik_Latin: F1-score = 0.9880, Precision = 1.0000, Recall = 0.9762, Support = 42.0\n",
      "mar_Devanagari (Hindi, Sanskrit): F1-score = 0.9877, Precision = 1.0000, Recall = 0.9756, Support = 41.0\n",
      "yid_Hébreu: F1-score = 0.9870, Precision = 1.0000, Recall = 0.9744, Support = 39.0\n",
      "tha_Thaï: F1-score = 0.9863, Precision = 0.9730, Recall = 1.0000, Support = 36.0\n",
      "pls_Latin: F1-score = 0.9859, Precision = 1.0000, Recall = 0.9722, Support = 36.0\n",
      "sag_Latin: F1-score = 0.9841, Precision = 0.9841, Recall = 0.9841, Support = 63.0\n",
      "mkd_Cyrillique: F1-score = 0.9831, Precision = 0.9831, Recall = 0.9831, Support = 59.0\n",
      "isl_Latin: F1-score = 0.9825, Precision = 0.9655, Recall = 1.0000, Support = 56.0\n",
      "krc_Cyrillique: F1-score = 0.9825, Precision = 1.0000, Recall = 0.9655, Support = 58.0\n",
      "sah_Cyrillique: F1-score = 0.9825, Precision = 1.0000, Recall = 0.9655, Support = 58.0\n",
      "snd_Arabe: F1-score = 0.9821, Precision = 0.9821, Recall = 0.9821, Support = 56.0\n",
      "crh_Latin: F1-score = 0.9815, Precision = 1.0000, Recall = 0.9636, Support = 55.0\n",
      "jbo_Latin: F1-score = 0.9811, Precision = 1.0000, Recall = 0.9630, Support = 54.0\n",
      "fij_Latin: F1-score = 0.9804, Precision = 0.9615, Recall = 1.0000, Support = 50.0\n",
      "fur_Latin: F1-score = 0.9804, Precision = 1.0000, Recall = 0.9615, Support = 52.0\n",
      "vol_Latin: F1-score = 0.9804, Precision = 1.0000, Recall = 0.9615, Support = 52.0\n",
      "fin_Latin: F1-score = 0.9792, Precision = 1.0000, Recall = 0.9592, Support = 49.0\n",
      "gom_Latin: F1-score = 0.9792, Precision = 1.0000, Recall = 0.9592, Support = 49.0\n",
      "ndo_Latin: F1-score = 0.9792, Precision = 0.9792, Recall = 0.9792, Support = 48.0\n",
      "cym_Latin: F1-score = 0.9787, Precision = 1.0000, Recall = 0.9583, Support = 48.0\n",
      "hmo_Latin: F1-score = 0.9787, Precision = 0.9583, Recall = 1.0000, Support = 46.0\n",
      "diq_Latin: F1-score = 0.9783, Precision = 1.0000, Recall = 0.9574, Support = 47.0\n",
      "csb_Latin: F1-score = 0.9773, Precision = 0.9773, Recall = 0.9773, Support = 44.0\n",
      "eml_Latin: F1-score = 0.9739, Precision = 1.0000, Recall = 0.9492, Support = 59.0\n",
      "grc_Grec: F1-score = 0.9739, Precision = 1.0000, Recall = 0.9492, Support = 59.0\n",
      "lit_Latin: F1-score = 0.9735, Precision = 0.9483, Recall = 1.0000, Support = 55.0\n",
      "oss_Cyrillique: F1-score = 0.9735, Precision = 1.0000, Recall = 0.9483, Support = 58.0\n",
      "azb_Arabe: F1-score = 0.9730, Precision = 0.9818, Recall = 0.9643, Support = 56.0\n",
      "gug_Latin: F1-score = 0.9730, Precision = 0.9643, Recall = 0.9818, Support = 55.0\n",
      "pms_Latin: F1-score = 0.9730, Precision = 1.0000, Recall = 0.9474, Support = 38.0\n",
      "pis_Latin: F1-score = 0.9714, Precision = 0.9444, Recall = 1.0000, Support = 17.0\n",
      "szl_Latin: F1-score = 0.9706, Precision = 0.9706, Recall = 0.9706, Support = 34.0\n",
      "vep_Latin: F1-score = 0.9691, Precision = 1.0000, Recall = 0.9400, Support = 50.0\n",
      "dtp_Latin: F1-score = 0.9677, Precision = 0.9783, Recall = 0.9574, Support = 47.0\n",
      "glv_Latin: F1-score = 0.9677, Precision = 0.9783, Recall = 0.9574, Support = 47.0\n",
      "kat_Géorgien: F1-score = 0.9677, Precision = 0.9375, Recall = 1.0000, Support = 45.0\n",
      "sme_Latin: F1-score = 0.9677, Precision = 1.0000, Recall = 0.9375, Support = 48.0\n",
      "tpi_Latin: F1-score = 0.9677, Precision = 1.0000, Recall = 0.9375, Support = 48.0\n",
      "kaz_Cyrillique: F1-score = 0.9663, Precision = 1.0000, Recall = 0.9348, Support = 46.0\n",
      "mwl_Latin: F1-score = 0.9655, Precision = 0.9655, Recall = 0.9655, Support = 58.0\n",
      "new_Devanagari (Hindi, Sanskrit): F1-score = 0.9649, Precision = 1.0000, Recall = 0.9322, Support = 59.0\n",
      "bul_Cyrillique: F1-score = 0.9647, Precision = 0.9762, Recall = 0.9535, Support = 43.0\n",
      "ell_Grec: F1-score = 0.9643, Precision = 0.9310, Recall = 1.0000, Support = 54.0\n",
      "quh_Latin: F1-score = 0.9639, Precision = 0.9302, Recall = 1.0000, Support = 40.0\n",
      "arz_Arabe: F1-score = 0.9623, Precision = 1.0000, Recall = 0.9273, Support = 55.0\n",
      "kea_Latin: F1-score = 0.9615, Precision = 0.9804, Recall = 0.9434, Support = 53.0\n",
      "jam_Latin: F1-score = 0.9593, Precision = 1.0000, Recall = 0.9219, Support = 64.0\n",
      "frr_Latin: F1-score = 0.9592, Precision = 0.9792, Recall = 0.9400, Support = 50.0\n",
      "kam_Latin: F1-score = 0.9589, Precision = 1.0000, Recall = 0.9211, Support = 38.0\n",
      "kom_Cyrillique: F1-score = 0.9583, Precision = 1.0000, Recall = 0.9200, Support = 50.0\n",
      "tur_Latin: F1-score = 0.9583, Precision = 0.9583, Recall = 0.9583, Support = 48.0\n",
      "amh_Éthiopien: F1-score = 0.9574, Precision = 1.0000, Recall = 0.9184, Support = 49.0\n",
      "lin_Latin: F1-score = 0.9574, Precision = 0.9783, Recall = 0.9375, Support = 48.0\n",
      "ukr_Cyrillique: F1-score = 0.9574, Precision = 0.9184, Recall = 1.0000, Support = 45.0\n",
      "lfn_Latin: F1-score = 0.9565, Precision = 0.9778, Recall = 0.9362, Support = 47.0\n",
      "kon_Latin: F1-score = 0.9558, Precision = 0.9818, Recall = 0.9310, Support = 58.0\n",
      "swe_Latin: F1-score = 0.9541, Precision = 0.9455, Recall = 0.9630, Support = 54.0\n",
      "epo_Latin: F1-score = 0.9535, Precision = 0.9535, Recall = 0.9535, Support = 43.0\n",
      "tir_Éthiopien: F1-score = 0.9535, Precision = 0.9111, Recall = 1.0000, Support = 41.0\n",
      "chv_Cyrillique: F1-score = 0.9524, Precision = 1.0000, Recall = 0.9091, Support = 44.0\n",
      "ssw_Latin: F1-score = 0.9524, Precision = 0.9836, Recall = 0.9231, Support = 65.0\n",
      "quc_Latin: F1-score = 0.9516, Precision = 0.9365, Recall = 0.9672, Support = 61.0\n",
      "san_Devanagari (Hindi, Sanskrit): F1-score = 0.9516, Precision = 0.9077, Recall = 1.0000, Support = 59.0\n",
      "fao_Latin: F1-score = 0.9515, Precision = 0.9800, Recall = 0.9245, Support = 53.0\n",
      "hye_Arménien: F1-score = 0.9515, Precision = 0.9074, Recall = 1.0000, Support = 49.0\n",
      "yor_Latin: F1-score = 0.9515, Precision = 1.0000, Recall = 0.9074, Support = 54.0\n",
      "ace_Latin: F1-score = 0.9505, Precision = 0.9796, Recall = 0.9231, Support = 52.0\n",
      "ilo_Latin: F1-score = 0.9505, Precision = 1.0000, Recall = 0.9057, Support = 53.0\n",
      "cat_Latin: F1-score = 0.9500, Precision = 0.9500, Recall = 0.9500, Support = 40.0\n",
      "grn_Latin: F1-score = 0.9495, Precision = 0.9592, Recall = 0.9400, Support = 50.0\n",
      "lug_Latin: F1-score = 0.9495, Precision = 0.9592, Recall = 0.9400, Support = 50.0\n",
      "gla_Latin: F1-score = 0.9485, Precision = 0.9787, Recall = 0.9200, Support = 50.0\n",
      "bis_Latin: F1-score = 0.9474, Precision = 0.9643, Recall = 0.9310, Support = 58.0\n",
      "ile_Latin: F1-score = 0.9434, Precision = 0.9434, Recall = 0.9434, Support = 53.0\n",
      "aln_Latin: F1-score = 0.9423, Precision = 0.9423, Recall = 0.9423, Support = 52.0\n",
      "acr_Latin: F1-score = 0.9412, Precision = 0.9600, Recall = 0.9231, Support = 52.0\n",
      "tum_Latin: F1-score = 0.9412, Precision = 0.9412, Recall = 0.9412, Support = 51.0\n",
      "ibo_Latin: F1-score = 0.9400, Precision = 1.0000, Recall = 0.8868, Support = 53.0\n",
      "gcf_Latin: F1-score = 0.9375, Precision = 1.0000, Recall = 0.8824, Support = 17.0\n",
      "slv_Latin: F1-score = 0.9367, Precision = 0.9737, Recall = 0.9024, Support = 41.0\n",
      "afr_Latin: F1-score = 0.9358, Precision = 0.9623, Recall = 0.9107, Support = 56.0\n",
      "kaa_Latin: F1-score = 0.9358, Precision = 1.0000, Recall = 0.8793, Support = 58.0\n",
      "mhr_Cyrillique: F1-score = 0.9358, Precision = 0.9444, Recall = 0.9273, Support = 55.0\n",
      "tyv_Cyrillique: F1-score = 0.9355, Precision = 0.9508, Recall = 0.9206, Support = 63.0\n",
      "vls_Latin: F1-score = 0.9346, Precision = 0.9259, Recall = 0.9434, Support = 53.0\n",
      "npi_Devanagari (Hindi, Sanskrit): F1-score = 0.9313, Precision = 0.9385, Recall = 0.9242, Support = 66.0\n",
      "fry_Latin: F1-score = 0.9293, Precision = 0.9583, Recall = 0.9020, Support = 51.0\n",
      "lao_LAO: F1-score = 0.9286, Precision = 0.8864, Recall = 0.9750, Support = 40.0\n",
      "hsb_Latin: F1-score = 0.9278, Precision = 1.0000, Recall = 0.8654, Support = 52.0\n",
      "quy_Latin: F1-score = 0.9278, Precision = 0.8654, Recall = 1.0000, Support = 45.0\n",
      "bre_Latin: F1-score = 0.9231, Precision = 0.9474, Recall = 0.9000, Support = 60.0\n",
      "dyu_Latin: F1-score = 0.9231, Precision = 0.8710, Recall = 0.9818, Support = 55.0\n",
      "mzn_Arabe: F1-score = 0.9231, Precision = 0.9767, Recall = 0.8750, Support = 48.0\n",
      "udm_Cyrillique: F1-score = 0.9213, Precision = 0.9535, Recall = 0.8913, Support = 46.0\n",
      "gle_Latin: F1-score = 0.9204, Precision = 0.8667, Recall = 0.9811, Support = 53.0\n",
      "pol_Latin: F1-score = 0.9200, Precision = 0.8519, Recall = 1.0000, Support = 46.0\n",
      "ksh_Latin: F1-score = 0.9194, Precision = 0.9500, Recall = 0.8906, Support = 64.0\n",
      "pus_Arabe: F1-score = 0.9189, Precision = 0.9444, Recall = 0.8947, Support = 57.0\n",
      "kaa_Cyrillique: F1-score = 0.9174, Precision = 1.0000, Recall = 0.8475, Support = 59.0\n",
      "bam_Latin: F1-score = 0.9149, Precision = 1.0000, Recall = 0.8431, Support = 51.0\n",
      "rue_Cyrillique: F1-score = 0.9149, Precision = 0.8600, Recall = 0.9773, Support = 44.0\n",
      "ven_Latin: F1-score = 0.9149, Precision = 1.0000, Recall = 0.8431, Support = 51.0\n",
      "mai_Devanagari (Hindi, Sanskrit): F1-score = 0.9138, Precision = 0.9298, Recall = 0.8983, Support = 59.0\n",
      "crh_Cyrillique: F1-score = 0.9114, Precision = 0.9730, Recall = 0.8571, Support = 42.0\n",
      "hne_Devanagari (Hindi, Sanskrit): F1-score = 0.9107, Precision = 0.9623, Recall = 0.8644, Support = 59.0\n",
      "tah_Latin: F1-score = 0.9091, Precision = 1.0000, Recall = 0.8333, Support = 48.0\n",
      "ful_Latin: F1-score = 0.9072, Precision = 0.9167, Recall = 0.8980, Support = 49.0\n",
      "zlm_Latin: F1-score = 0.9065, Precision = 0.9130, Recall = 0.9000, Support = 70.0\n",
      "ron_Latin: F1-score = 0.9038, Precision = 0.8704, Recall = 0.9400, Support = 50.0\n",
      "som_Latin: F1-score = 0.9011, Precision = 0.9535, Recall = 0.8542, Support = 48.0\n",
      "jpn_Katakana (Japonais): F1-score = 0.9000, Precision = 0.9000, Recall = 0.9000, Support = 10.0\n",
      "ext_Latin: F1-score = 0.8980, Precision = 0.9167, Recall = 0.8800, Support = 50.0\n",
      "min_Latin: F1-score = 0.8958, Precision = 0.8958, Recall = 0.8958, Support = 48.0\n",
      "ton_Latin: F1-score = 0.8958, Precision = 0.9149, Recall = 0.8776, Support = 49.0\n",
      "pnb_Arabe: F1-score = 0.8932, Precision = 0.8679, Recall = 0.9200, Support = 50.0\n",
      "tat_Cyrillique: F1-score = 0.8929, Precision = 0.8197, Recall = 0.9804, Support = 51.0\n",
      "lij_Latin: F1-score = 0.8909, Precision = 0.8596, Recall = 0.9245, Support = 53.0\n",
      "nap_Latin: F1-score = 0.8889, Precision = 0.9231, Recall = 0.8571, Support = 56.0\n",
      "bih_Devanagari (Hindi, Sanskrit): F1-score = 0.8866, Precision = 0.8431, Recall = 0.9348, Support = 46.0\n",
      "bod_TIBETAN: F1-score = 0.8842, Precision = 0.8400, Recall = 0.9333, Support = 45.0\n",
      "hmn_Latin: F1-score = 0.8817, Precision = 0.9762, Recall = 0.8039, Support = 51.0\n",
      "pcd_Latin: F1-score = 0.8814, Precision = 0.8254, Recall = 0.9455, Support = 55.0\n",
      "nld_Latin: F1-score = 0.8800, Precision = 0.8462, Recall = 0.9167, Support = 48.0\n",
      "por_Latin: F1-score = 0.8791, Precision = 0.9091, Recall = 0.8511, Support = 47.0\n",
      "ceb_Latin: F1-score = 0.8780, Precision = 0.9231, Recall = 0.8372, Support = 43.0\n",
      "ido_Latin: F1-score = 0.8780, Precision = 0.8571, Recall = 0.9000, Support = 40.0\n",
      "dan_Latin: F1-score = 0.8736, Precision = 0.9048, Recall = 0.8444, Support = 45.0\n",
      "wol_Latin: F1-score = 0.8718, Precision = 0.9444, Recall = 0.8095, Support = 42.0\n",
      "lzh_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8710, Precision = 0.8182, Recall = 0.9310, Support = 58.0\n",
      "swc_Latin: F1-score = 0.8704, Precision = 0.9216, Recall = 0.8246, Support = 57.0\n",
      "arg_Latin: F1-score = 0.8689, Precision = 0.8413, Recall = 0.8983, Support = 59.0\n",
      "pag_Latin: F1-score = 0.8687, Precision = 0.9773, Recall = 0.7818, Support = 55.0\n",
      "deu_Latin: F1-score = 0.8660, Precision = 0.8400, Recall = 0.8936, Support = 47.0\n",
      "myv_Cyrillique: F1-score = 0.8657, Precision = 0.8169, Recall = 0.9206, Support = 63.0\n",
      "mon_Latin: F1-score = 0.8642, Precision = 0.9459, Recall = 0.7955, Support = 44.0\n",
      "pcm_Latin: F1-score = 0.8593, Precision = 0.8529, Recall = 0.8657, Support = 67.0\n",
      "lmo_Latin: F1-score = 0.8571, Precision = 0.8372, Recall = 0.8780, Support = 41.0\n",
      "rmy_Latin: F1-score = 0.8571, Precision = 0.9545, Recall = 0.7778, Support = 54.0\n",
      "weighted avg: F1-score = 0.8546, Precision = 0.8679, Recall = 0.8532, Support = 19010.0\n",
      "dzo_TIBETAN: F1-score = 0.8544, Precision = 0.8627, Recall = 0.8462, Support = 52.0\n",
      "lim_Latin: F1-score = 0.8542, Precision = 0.8367, Recall = 0.8723, Support = 47.0\n",
      "tls_Latin: F1-score = 0.8478, Precision = 0.9750, Recall = 0.7500, Support = 52.0\n",
      "lat_Latin: F1-score = 0.8462, Precision = 0.8000, Recall = 0.8980, Support = 49.0\n",
      "gsw_Latin: F1-score = 0.8451, Precision = 0.8333, Recall = 0.8571, Support = 35.0\n",
      "yue_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8444, Precision = 0.8507, Recall = 0.8382, Support = 68.0\n",
      "pfl_Latin: F1-score = 0.8434, Precision = 0.8333, Recall = 0.8537, Support = 41.0\n",
      "ayr_Latin: F1-score = 0.8431, Precision = 0.7544, Recall = 0.9556, Support = 45.0\n",
      "nno_Latin: F1-score = 0.8409, Precision = 0.7551, Recall = 0.9487, Support = 39.0\n",
      "rap_Latin: F1-score = 0.8372, Precision = 0.9474, Recall = 0.7500, Support = 24.0\n",
      "hif_Latin: F1-score = 0.8352, Precision = 0.7917, Recall = 0.8837, Support = 43.0\n",
      "uzb_Latin: F1-score = 0.8320, Precision = 0.7761, Recall = 0.8966, Support = 58.0\n",
      "macro avg: F1-score = 0.8314, Precision = 0.8464, Recall = 0.8297, Support = 19010.0\n",
      "glg_Latin: F1-score = 0.8247, Precision = 0.8333, Recall = 0.8163, Support = 49.0\n",
      "kat_Latin: F1-score = 0.8235, Precision = 0.9130, Recall = 0.7500, Support = 56.0\n",
      "zea_Latin: F1-score = 0.8193, Precision = 0.8718, Recall = 0.7727, Support = 44.0\n",
      "nep_Devanagari (Hindi, Sanskrit): F1-score = 0.8182, Precision = 0.8000, Recall = 0.8372, Support = 43.0\n",
      "mlt_Latin: F1-score = 0.8172, Precision = 0.8085, Recall = 0.8261, Support = 46.0\n",
      "nds_Latin: F1-score = 0.8172, Precision = 0.7755, Recall = 0.8636, Support = 44.0\n",
      "bak_Cyrillique: F1-score = 0.8163, Precision = 0.9756, Recall = 0.7018, Support = 57.0\n",
      "hrx_Latin: F1-score = 0.8148, Precision = 1.0000, Recall = 0.6875, Support = 16.0\n",
      "bar_Latin: F1-score = 0.8130, Precision = 0.7353, Recall = 0.9091, Support = 55.0\n",
      "fra_Latin: F1-score = 0.8125, Precision = 0.7800, Recall = 0.8478, Support = 46.0\n",
      "scn_Latin: F1-score = 0.8099, Precision = 0.8448, Recall = 0.7778, Support = 63.0\n",
      "kur_Latin: F1-score = 0.8095, Precision = 0.7391, Recall = 0.8947, Support = 57.0\n",
      "hau_Latin: F1-score = 0.8077, Precision = 0.7778, Recall = 0.8400, Support = 50.0\n",
      "oci_Latin: F1-score = 0.8000, Precision = 0.8718, Recall = 0.7391, Support = 46.0\n",
      "smo_Latin: F1-score = 0.8000, Precision = 0.9714, Recall = 0.6800, Support = 50.0\n",
      "kmr_Latin: F1-score = 0.7957, Precision = 0.9487, Recall = 0.6852, Support = 54.0\n",
      "hat_Latin: F1-score = 0.7912, Precision = 0.9000, Recall = 0.7059, Support = 51.0\n",
      "nso_Latin: F1-score = 0.7778, Precision = 0.7778, Recall = 0.7778, Support = 45.0\n",
      "plt_Latin: F1-score = 0.7778, Precision = 0.9767, Recall = 0.6462, Support = 65.0\n",
      "jpn_Hiragana (Japonais): F1-score = 0.7727, Precision = 0.6800, Recall = 0.8947, Support = 19.0\n",
      "uig_Latin: F1-score = 0.7674, Precision = 0.8462, Recall = 0.7021, Support = 47.0\n",
      "haw_Latin: F1-score = 0.7654, Precision = 0.8857, Recall = 0.6739, Support = 46.0\n",
      "aka_Latin: F1-score = 0.7629, Precision = 0.7708, Recall = 0.7551, Support = 49.0\n",
      "bsb_Latin: F1-score = 0.7527, Precision = 0.7955, Recall = 0.7143, Support = 49.0\n",
      "ber_Latin: F1-score = 0.7500, Precision = 0.8298, Recall = 0.6842, Support = 57.0\n",
      "ina_Latin: F1-score = 0.7473, Precision = 0.7907, Recall = 0.7083, Support = 48.0\n",
      "que_Latin: F1-score = 0.7407, Precision = 0.9375, Recall = 0.6122, Support = 49.0\n",
      "prs_Arabe: F1-score = 0.7385, Precision = 0.6316, Recall = 0.8889, Support = 54.0\n",
      "bjn_Latin: F1-score = 0.7368, Precision = 0.7447, Recall = 0.7292, Support = 48.0\n",
      "kab_Latin: F1-score = 0.7290, Precision = 0.6500, Recall = 0.8298, Support = 47.0\n",
      "hil_Latin: F1-score = 0.7273, Precision = 1.0000, Recall = 0.5714, Support = 7.0\n",
      "srd_Latin: F1-score = 0.7234, Precision = 0.9189, Recall = 0.5965, Support = 57.0\n",
      "hbs_Cyrillique: F1-score = 0.7227, Precision = 0.6515, Recall = 0.8113, Support = 53.0\n",
      "gor_Latin: F1-score = 0.7213, Precision = 0.9167, Recall = 0.5946, Support = 37.0\n",
      "twi_Latin: F1-score = 0.7184, Precision = 0.7255, Recall = 0.7115, Support = 52.0\n",
      "wuu_Kanji (Chinois, Japonais, Coréen): F1-score = 0.7184, Precision = 0.6607, Recall = 0.7872, Support = 47.0\n",
      "run_Latin: F1-score = 0.7179, Precision = 0.6176, Recall = 0.8571, Support = 49.0\n",
      "tsn_Latin: F1-score = 0.7174, Precision = 0.7174, Recall = 0.7174, Support = 46.0\n",
      "ast_Latin: F1-score = 0.7167, Precision = 0.6056, Recall = 0.8776, Support = 49.0\n",
      "mlg_Latin: F1-score = 0.7143, Precision = 0.6250, Recall = 0.8333, Support = 54.0\n",
      "bak_Latin: F1-score = 0.7129, Precision = 0.6923, Recall = 0.7347, Support = 49.0\n",
      "bew_Cyrillique: F1-score = 0.7129, Precision = 0.7200, Recall = 0.7059, Support = 51.0\n",
      "est_Latin: F1-score = 0.7103, Precision = 0.7451, Recall = 0.6786, Support = 56.0\n",
      "cbk_Latin: F1-score = 0.7059, Precision = 0.8333, Recall = 0.6122, Support = 49.0\n",
      "arb_Arabe: F1-score = 0.7049, Precision = 0.6324, Recall = 0.7963, Support = 54.0\n",
      "bel_Cyrillique: F1-score = 0.6990, Precision = 0.7059, Recall = 0.6923, Support = 52.0\n",
      "hin_Devanagari (Hindi, Sanskrit): F1-score = 0.6990, Precision = 0.6792, Recall = 0.7200, Support = 50.0\n",
      "jav_Latin: F1-score = 0.6947, Precision = 0.7021, Recall = 0.6875, Support = 48.0\n",
      "aym_Latin: F1-score = 0.6914, Precision = 0.9032, Recall = 0.5600, Support = 50.0\n",
      "ekk_Latin: F1-score = 0.6889, Precision = 0.6458, Recall = 0.7381, Support = 42.0\n",
      "nya_Latin: F1-score = 0.6818, Precision = 0.7692, Recall = 0.6122, Support = 49.0\n",
      "cmn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6757, Precision = 0.6410, Recall = 0.7143, Support = 35.0\n",
      "spa_Latin: F1-score = 0.6733, Precision = 0.6415, Recall = 0.7083, Support = 48.0\n",
      "mri_Latin: F1-score = 0.6667, Precision = 0.7941, Recall = 0.5745, Support = 47.0\n",
      "mya_Latin: F1-score = 0.6667, Precision = 1.0000, Recall = 0.5000, Support = 2.0\n",
      "nbl_Latin: F1-score = 0.6667, Precision = 0.5439, Recall = 0.8611, Support = 36.0\n",
      "ori_ORIYA: F1-score = 0.6585, Precision = 0.6585, Recall = 0.6585, Support = 41.0\n",
      "wln_Latin: F1-score = 0.6526, Precision = 0.6889, Recall = 0.6200, Support = 50.0\n",
      "aze_Arabe: F1-score = 0.6508, Precision = 0.6508, Recall = 0.6508, Support = 63.0\n",
      "srp_Latin: F1-score = 0.6481, Precision = 0.6604, Recall = 0.6364, Support = 55.0\n",
      "ita_Latin: F1-score = 0.6465, Precision = 0.5714, Recall = 0.7442, Support = 43.0\n",
      "sqi_Latin: F1-score = 0.6458, Precision = 0.5536, Recall = 0.7750, Support = 40.0\n",
      "ckb_Arabe: F1-score = 0.6441, Precision = 0.5278, Recall = 0.8261, Support = 46.0\n",
      "jpn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6429, Precision = 0.8182, Recall = 0.5294, Support = 17.0\n",
      "war_Latin: F1-score = 0.6429, Precision = 0.6429, Recall = 0.6429, Support = 42.0\n",
      "xho_Latin: F1-score = 0.6420, Precision = 0.8667, Recall = 0.5098, Support = 51.0\n",
      "aze_Latin: F1-score = 0.6408, Precision = 0.6111, Recall = 0.6735, Support = 49.0\n",
      "ory_ORIYA: F1-score = 0.6316, Precision = 0.6316, Recall = 0.6316, Support = 38.0\n",
      "azj_Latin: F1-score = 0.6170, Precision = 0.6444, Recall = 0.5918, Support = 49.0\n",
      "hbs_Latin: F1-score = 0.6154, Precision = 0.4938, Recall = 0.8163, Support = 49.0\n",
      "zho_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6154, Precision = 0.7619, Recall = 0.5161, Support = 62.0\n",
      "nob_Latin: F1-score = 0.6139, Precision = 0.5962, Recall = 0.6327, Support = 49.0\n",
      "swa_Latin: F1-score = 0.6122, Precision = 0.6000, Recall = 0.6250, Support = 48.0\n",
      "ban_Latin: F1-score = 0.6019, Precision = 0.6739, Recall = 0.5439, Support = 57.0\n",
      "tgl_Latin: F1-score = 0.5946, Precision = 0.6600, Recall = 0.5410, Support = 61.0\n",
      "urd_Arabe: F1-score = 0.5909, Precision = 0.4756, Recall = 0.7800, Support = 50.0\n",
      "mad_Latin: F1-score = 0.5905, Precision = 0.6200, Recall = 0.5636, Support = 55.0\n",
      "glk_Arabe: F1-score = 0.5882, Precision = 0.6250, Recall = 0.5556, Support = 45.0\n",
      "guj_Devanagari (Hindi, Sanskrit): F1-score = 0.5636, Precision = 0.5345, Recall = 0.5962, Support = 52.0\n",
      "srp_Cyrillique: F1-score = 0.5570, Precision = 0.6471, Recall = 0.4889, Support = 45.0\n",
      "sot_Latin: F1-score = 0.5455, Precision = 0.6000, Recall = 0.5000, Support = 60.0\n",
      "tat_Latin: F1-score = 0.5385, Precision = 0.7500, Recall = 0.4200, Support = 50.0\n",
      "swh_Latin: F1-score = 0.5376, Precision = 0.5319, Recall = 0.5435, Support = 46.0\n",
      "kur_Arabe: F1-score = 0.5333, Precision = 0.7500, Recall = 0.4138, Support = 58.0\n",
      "hau_Arabe: F1-score = 0.5273, Precision = 0.6591, Recall = 0.4394, Support = 66.0\n",
      "ltz_Latin: F1-score = 0.5217, Precision = 0.3789, Recall = 0.8372, Support = 43.0\n",
      "sun_Latin: F1-score = 0.5192, Precision = 0.4426, Recall = 0.6279, Support = 43.0\n",
      "cos_Latin: F1-score = 0.5172, Precision = 0.4762, Recall = 0.5660, Support = 53.0\n",
      "kin_Latin: F1-score = 0.5063, Precision = 0.5128, Recall = 0.5000, Support = 40.0\n",
      "tgk_Latin: F1-score = 0.5060, Precision = 0.6364, Recall = 0.4200, Support = 50.0\n",
      "bik_Latin: F1-score = 0.5053, Precision = 0.4615, Recall = 0.5581, Support = 43.0\n",
      "enm_Latin: F1-score = 0.5000, Precision = 1.0000, Recall = 0.3333, Support = 3.0\n",
      "nor_Latin: F1-score = 0.5000, Precision = 0.5526, Recall = 0.4565, Support = 46.0\n",
      "tuk_Cyrillique: F1-score = 0.5000, Precision = 0.3488, Recall = 0.8824, Support = 17.0\n",
      "ary_Arabe: F1-score = 0.4954, Precision = 0.4909, Recall = 0.5000, Support = 54.0\n",
      "tgk_Cyrillique: F1-score = 0.4935, Precision = 0.6333, Recall = 0.4043, Support = 47.0\n",
      "uzn_Cyrillique: F1-score = 0.4902, Precision = 0.5102, Recall = 0.4717, Support = 53.0\n",
      "ara_Arabe: F1-score = 0.4810, Precision = 0.3654, Recall = 0.7037, Support = 54.0\n",
      "sna_Latin: F1-score = 0.4789, Precision = 0.7391, Recall = 0.3542, Support = 48.0\n",
      "apc_Arabe: F1-score = 0.4727, Precision = 0.4483, Recall = 0.5000, Support = 52.0\n",
      "nde_Latin: F1-score = 0.4706, Precision = 0.4762, Recall = 0.4651, Support = 43.0\n",
      "pam_Latin: F1-score = 0.4660, Precision = 0.4211, Recall = 0.5217, Support = 46.0\n",
      "vec_Latin: F1-score = 0.4634, Precision = 0.4419, Recall = 0.4872, Support = 39.0\n",
      "san_Latin: F1-score = 0.4615, Precision = 0.4286, Recall = 0.5000, Support = 6.0\n",
      "msa_Latin: F1-score = 0.4576, Precision = 0.4091, Recall = 0.5192, Support = 52.0\n",
      "pes_Arabe: F1-score = 0.4545, Precision = 0.4545, Recall = 0.4545, Support = 44.0\n",
      "acm_Arabe: F1-score = 0.4471, Precision = 0.6333, Recall = 0.3455, Support = 55.0\n",
      "hin_Latin: F1-score = 0.4444, Precision = 0.4762, Recall = 0.4167, Support = 48.0\n",
      "als_Latin: F1-score = 0.4308, Precision = 0.5600, Recall = 0.3500, Support = 40.0\n",
      "eng_Latin: F1-score = 0.4233, Precision = 0.2963, Recall = 0.7407, Support = 54.0\n",
      "ind_Latin: F1-score = 0.4103, Precision = 0.3810, Recall = 0.4444, Support = 36.0\n",
      "sco_Latin: F1-score = 0.4096, Precision = 0.2818, Recall = 0.7500, Support = 68.0\n",
      "ajp_Arabe: F1-score = 0.4086, Precision = 0.3276, Recall = 0.5429, Support = 35.0\n",
      "fil_Latin: F1-score = 0.3951, Precision = 0.3810, Recall = 0.4103, Support = 39.0\n",
      "bcl_Latin: F1-score = 0.3942, Precision = 0.3375, Recall = 0.4737, Support = 57.0\n",
      "fas_Arabe: F1-score = 0.3855, Precision = 0.4103, Recall = 0.3636, Support = 44.0\n",
      "uzb_Cyrillique: F1-score = 0.3833, Precision = 0.3151, Recall = 0.4894, Support = 47.0\n",
      "zul_Latin: F1-score = 0.3636, Precision = 0.4667, Recall = 0.2979, Support = 47.0\n",
      "zsm_Latin: F1-score = 0.3596, Precision = 0.3265, Recall = 0.4000, Support = 40.0\n",
      "afb_Arabe: F1-score = 0.3133, Precision = 0.3714, Recall = 0.2708, Support = 48.0\n",
      "som_Arabe: F1-score = 0.2812, Precision = 0.8182, Recall = 0.1698, Support = 53.0\n",
      "tgk_Arabe: F1-score = 0.2609, Precision = 0.4091, Recall = 0.1915, Support = 47.0\n",
      "lao_Latin: F1-score = 0.2500, Precision = 0.5000, Recall = 0.1667, Support = 6.0\n",
      "bos_Latin: F1-score = 0.2439, Precision = 0.3125, Recall = 0.2000, Support = 50.0\n",
      "guj_Latin: F1-score = 0.2222, Precision = 0.3333, Recall = 0.1667, Support = 6.0\n",
      "hrv_Latin: F1-score = 0.1695, Precision = 0.2174, Recall = 0.1389, Support = 36.0\n",
      "dzo_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 4.0\n",
      "hyw_Arménien: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 4.0\n",
      "mai_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "ngl_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "quz_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sat_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sin_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "tha_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "wbm_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Générer le rapport de classification sous forme de dictionnaire\n",
    "report_sp = classification_report(y_val_sp, predictions_sp, target_names=filtered_target_names_sp, output_dict=True)\n",
    "\n",
    "# Filtrer les classes (en excluant 'accuracy', 'macro avg', 'weighted avg')\n",
    "filtered_report = {label: metrics for label, metrics in report_sp.items() if isinstance(metrics, dict)}\n",
    "\n",
    "# Trier les langues par F1-score de manière décroissante\n",
    "sorted_report = sorted(filtered_report.items(), key=lambda x: x[1]['f1-score'], reverse=True)\n",
    "\n",
    "# Afficher le rapport trié\n",
    "print(\"Classification Report (trié par F1-score décroissant):\\n\")\n",
    "for label, metrics in sorted_report:\n",
    "    print(f\"{label}: F1-score = {metrics['f1-score']:.4f}, Precision = {metrics['precision']:.4f}, Recall = {metrics['recall']:.4f}, Support = {metrics['support']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ B. ▁ 2 4SI ▁ - ▁ I stra ži vanje ▁od s je ka...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187584</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ I ▁svak og ▁dana ▁na kon ▁to ga ▁je ▁laga no...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172443</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ S lu ša j ! ▁ G de ▁je ▁čo ve k ▁koji ▁je ▁p...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ E ki pa ▁ J a pan ske ▁se ▁sa sto ja la ▁od ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49647</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ Ž ene ▁će ▁pu ca ti ▁ako ▁su ▁iz gu bile ▁si...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184506</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ “ C ije na ▁ide ▁za ▁jedn u ▁mar ku ▁gore .</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101390</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ B a sic ▁je ▁program ski ▁je zik . ▁ P r va ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38189</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ \"R ef ere ndum ▁kao ▁i ▁svak o ▁drug o ▁iz r...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90005</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ \"R o dos lo vi ▁i ▁istori ja ▁ve lik ih ▁ku ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158661</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ Ž el iš ▁me ▁pita ti ▁mo žeš ▁li ▁do bi ti ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124628</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ V e ći na ▁nji h ▁se ▁već ▁ne ko ▁vrijeme ▁b...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19286</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ S ta o ▁čovjek ▁na ▁stran u ▁pra vde ▁i ▁ist...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182794</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ Z a o ▁mi ▁je . ▁ V rata ▁su ▁bila ▁otvoren a .</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104900</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ N e ▁znaš ▁kro z ▁šta ▁on ▁pro la zi ▁i ▁pod...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88791</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ D. ▁ U tak mica ▁za vr še na ▁rezultat om ▁ ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144031</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ B ile ▁su ▁d vi je ▁super ▁si le ▁na ▁No vu ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17068</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ N isi ▁bila ▁pri ▁se bi . ▁ O vo ▁nije ▁kri ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69799</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ \"G o dina ma ▁na kon ▁tu ž nih ▁isku stava ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174038</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ P oneka d ▁mora te ▁da ▁se ▁suo ci te ▁sami ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161616</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ - ▁ P eta ▁ž rt va ▁ima ▁ A- pozit iv nu . ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172272</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ Š ta ▁smo ▁u či ni li ▁da ▁ B og ▁tra ži ▁od...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101449</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ “S pa simo ▁do sto jan stvo ▁stop ▁na si lju...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55512</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ {Y: bi }I ▁na ▁far mi ▁je ▁ubi ja o ▁ne ke ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135169</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ I ▁vol im ▁mo je ▁vin ske ▁čas e ▁i ▁poker ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147791</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ Z i vim ▁ovdje ▁i ▁u ▁bli zini ▁oko ▁se st ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ K ada ▁se ▁ta ▁či nje nica ▁ut vr di ▁od ▁st...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85578</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ Z a ▁ula zak ▁u ▁hram ▁oni ▁mora ju ▁uk lon ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ P ita m ▁se ▁zašto ▁ovo ▁ni sam ▁ra ni je ▁u...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53523</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ - ▁ T o ▁je ▁moj ▁prijatelj ▁ S am ▁i ▁stvar...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79054</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ V ije ć nica ▁u ▁ B r č kom ▁spa da ▁u ▁jedn...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181252</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ K o ment ari šu ći ▁zah tje v ▁ne ki h ▁ne v...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67089</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ N e ▁vu če m ▁te ! ▁ - ▁ Š to ▁to ▁radi š ? ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20332</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ T re ba ▁mi ▁glu pa va ▁le p ljiv a ▁tra ka ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48654</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ T i ▁će š ▁mora ti ▁da ▁š titi š ▁ Č aka .</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121131</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ T o ▁je ▁do bra ▁stvar . ▁ G ood ▁point . ▁c...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74545</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ Č e tiri ▁iz dan ja ▁ W in dow sa ▁ 2 000 ▁s...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61818</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ A ko ▁ne ko ▁poč ne ▁da ▁is pit uje ... ▁ N ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133876</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ A ko ▁ga ▁us pi je mo ▁pra titi ▁on ▁nsa s ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50549</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ J a ▁sam ▁ N aina ▁ C a ther ine ▁ K a pur ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11194</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ T hi e me ▁ C he mist ry ▁ ( iz da va č ): ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144618</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ T ri ▁hidro e lek tra ne ▁na ▁ S ani ▁ R je ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87681</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ P r ve ▁studi je ▁o ▁eksp resi ji ▁ T n m d ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85876</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ S ve ▁to ▁ovaj ▁moral ni ▁go ros tas ▁nije ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32187</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ - ▁ D o ▁če ke . ▁ H o će š ▁li ▁sa ▁nama ?</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126929</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ P rova lili ▁ste ▁ovdje ▁kako ▁bi ste ▁nam ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149225</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ P oneka d ▁se ▁ci ni ▁kao ▁da ▁bi ▁to ▁ra do...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165704</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ N e . ▁ B io ▁sam ▁kon zul tant ▁malo pro da...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28533</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ U ▁redu ▁nemo j ▁tako ▁razmišlja ti ▁jer ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148988</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ J eb em ▁ti ▁ma ter ! ▁ N AJVIŠE ▁ S T A N J...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36788</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ T o čno ▁izv an ▁do ma ša ja ▁ra dara . ▁ M ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text      Label\n",
       "34789   Public  ▁ B. ▁ 2 4SI ▁ - ▁ I stra ži vanje ▁od s je ka...  bos_Latin\n",
       "187584  Public  ▁ I ▁svak og ▁dana ▁na kon ▁to ga ▁je ▁laga no...  bos_Latin\n",
       "172443  Public  ▁ S lu ša j ! ▁ G de ▁je ▁čo ve k ▁koji ▁je ▁p...  bos_Latin\n",
       "1390    Public  ▁ E ki pa ▁ J a pan ske ▁se ▁sa sto ja la ▁od ...  bos_Latin\n",
       "49647   Public  ▁ Ž ene ▁će ▁pu ca ti ▁ako ▁su ▁iz gu bile ▁si...  bos_Latin\n",
       "184506  Public      ▁ “ C ije na ▁ide ▁za ▁jedn u ▁mar ku ▁gore .  bos_Latin\n",
       "101390  Public  ▁ B a sic ▁je ▁program ski ▁je zik . ▁ P r va ...  bos_Latin\n",
       "38189   Public  ▁ \"R ef ere ndum ▁kao ▁i ▁svak o ▁drug o ▁iz r...  bos_Latin\n",
       "90005   Public  ▁ \"R o dos lo vi ▁i ▁istori ja ▁ve lik ih ▁ku ...  bos_Latin\n",
       "158661  Public  ▁ Ž el iš ▁me ▁pita ti ▁mo žeš ▁li ▁do bi ti ▁...  bos_Latin\n",
       "124628  Public  ▁ V e ći na ▁nji h ▁se ▁već ▁ne ko ▁vrijeme ▁b...  bos_Latin\n",
       "19286   Public  ▁ S ta o ▁čovjek ▁na ▁stran u ▁pra vde ▁i ▁ist...  bos_Latin\n",
       "182794  Public  ▁ Z a o ▁mi ▁je . ▁ V rata ▁su ▁bila ▁otvoren a .  bos_Latin\n",
       "104900  Public  ▁ N e ▁znaš ▁kro z ▁šta ▁on ▁pro la zi ▁i ▁pod...  bos_Latin\n",
       "88791   Public  ▁ D. ▁ U tak mica ▁za vr še na ▁rezultat om ▁ ...  bos_Latin\n",
       "144031  Public  ▁ B ile ▁su ▁d vi je ▁super ▁si le ▁na ▁No vu ...  bos_Latin\n",
       "17068   Public  ▁ N isi ▁bila ▁pri ▁se bi . ▁ O vo ▁nije ▁kri ...  bos_Latin\n",
       "69799   Public  ▁ \"G o dina ma ▁na kon ▁tu ž nih ▁isku stava ▁...  bos_Latin\n",
       "174038  Public  ▁ P oneka d ▁mora te ▁da ▁se ▁suo ci te ▁sami ...  bos_Latin\n",
       "161616  Public  ▁ - ▁ P eta ▁ž rt va ▁ima ▁ A- pozit iv nu . ▁...  bos_Latin\n",
       "172272  Public  ▁ Š ta ▁smo ▁u či ni li ▁da ▁ B og ▁tra ži ▁od...  bos_Latin\n",
       "101449  Public  ▁ “S pa simo ▁do sto jan stvo ▁stop ▁na si lju...  bos_Latin\n",
       "55512   Public  ▁ {Y: bi }I ▁na ▁far mi ▁je ▁ubi ja o ▁ne ke ▁...  bos_Latin\n",
       "135169  Public  ▁ I ▁vol im ▁mo je ▁vin ske ▁čas e ▁i ▁poker ▁...  bos_Latin\n",
       "147791  Public  ▁ Z i vim ▁ovdje ▁i ▁u ▁bli zini ▁oko ▁se st ▁...  bos_Latin\n",
       "44816   Public  ▁ K ada ▁se ▁ta ▁či nje nica ▁ut vr di ▁od ▁st...  bos_Latin\n",
       "85578   Public  ▁ Z a ▁ula zak ▁u ▁hram ▁oni ▁mora ju ▁uk lon ...  bos_Latin\n",
       "688     Public  ▁ P ita m ▁se ▁zašto ▁ovo ▁ni sam ▁ra ni je ▁u...  bos_Latin\n",
       "53523   Public  ▁ - ▁ T o ▁je ▁moj ▁prijatelj ▁ S am ▁i ▁stvar...  bos_Latin\n",
       "79054   Public  ▁ V ije ć nica ▁u ▁ B r č kom ▁spa da ▁u ▁jedn...  bos_Latin\n",
       "181252  Public  ▁ K o ment ari šu ći ▁zah tje v ▁ne ki h ▁ne v...  bos_Latin\n",
       "67089   Public  ▁ N e ▁vu če m ▁te ! ▁ - ▁ Š to ▁to ▁radi š ? ...  bos_Latin\n",
       "20332   Public  ▁ T re ba ▁mi ▁glu pa va ▁le p ljiv a ▁tra ka ...  bos_Latin\n",
       "48654   Public       ▁ T i ▁će š ▁mora ti ▁da ▁š titi š ▁ Č aka .  bos_Latin\n",
       "121131  Public  ▁ T o ▁je ▁do bra ▁stvar . ▁ G ood ▁point . ▁c...  bos_Latin\n",
       "74545   Public  ▁ Č e tiri ▁iz dan ja ▁ W in dow sa ▁ 2 000 ▁s...  bos_Latin\n",
       "61818   Public  ▁ A ko ▁ne ko ▁poč ne ▁da ▁is pit uje ... ▁ N ...  bos_Latin\n",
       "133876  Public  ▁ A ko ▁ga ▁us pi je mo ▁pra titi ▁on ▁nsa s ▁...  bos_Latin\n",
       "50549   Public  ▁ J a ▁sam ▁ N aina ▁ C a ther ine ▁ K a pur ▁...  bos_Latin\n",
       "11194   Public  ▁ T hi e me ▁ C he mist ry ▁ ( iz da va č ): ▁...  bos_Latin\n",
       "144618  Public  ▁ T ri ▁hidro e lek tra ne ▁na ▁ S ani ▁ R je ...  bos_Latin\n",
       "87681   Public  ▁ P r ve ▁studi je ▁o ▁eksp resi ji ▁ T n m d ...  bos_Latin\n",
       "85876   Public  ▁ S ve ▁to ▁ovaj ▁moral ni ▁go ros tas ▁nije ▁...  bos_Latin\n",
       "32187   Public      ▁ - ▁ D o ▁če ke . ▁ H o će š ▁li ▁sa ▁nama ?  bos_Latin\n",
       "126929  Public  ▁ P rova lili ▁ste ▁ovdje ▁kako ▁bi ste ▁nam ▁...  bos_Latin\n",
       "149225  Public  ▁ P oneka d ▁se ▁ci ni ▁kao ▁da ▁bi ▁to ▁ra do...  bos_Latin\n",
       "165704  Public  ▁ N e . ▁ B io ▁sam ▁kon zul tant ▁malo pro da...  bos_Latin\n",
       "28533   Public     ▁ U ▁redu ▁nemo j ▁tako ▁razmišlja ti ▁jer ...  bos_Latin\n",
       "148988  Public  ▁ J eb em ▁ti ▁ma ter ! ▁ N AJVIŠE ▁ S T A N J...  bos_Latin\n",
       "36788   Public  ▁ T o čno ▁izv an ▁do ma ša ja ▁ra dara . ▁ M ...  bos_Latin"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set_second_version[val_set_second_version['Label'] == 'bos_Latin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch pour choisir le meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'utilisation de GridSearch est très intensive en ressources. \n",
    "- On réduit donc la dimension des vecteurs (max_features du tf idf) à 2000 et on choisit uniquement des modèles avec des complexités raisonnables pour n ~ 190,000 et d ~ 2000. \n",
    "- Ceci nous donne un proxy de la meilleure combinaison modèle x hyperparamètres à utiliser parmi ces options légères.\n",
    "- On ne considère pas ici l'ajout de l'alphabet car cela pose des problèmes de trop petites classes avec la cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extremely underrepresented languages (<10 instances)\n",
    "data_train_without_nan_for_label = data_train_without_nan_for_label[~data_train_without_nan_for_label.isin(underrepresented_languages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, val_set = train_test_split(data_train_without_nan_for_label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_third_version = train_set.copy()\n",
    "val_set_third_version = val_set.copy()\n",
    "train_set_third_version = pre_processing(train_set_third_version, remove_espace=False, not_test=False) \n",
    "val_set_third_version = pre_processing(val_set_third_version, remove_espace=False, not_test=False)\n",
    "#train_set_third_version = add_alphabet_to_label(train_set_third_version)\n",
    "#val_set_third_version = add_alphabet_to_label(val_set_third_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set_third_version['Text'].tolist()\n",
    "y_train = train_set_third_version['Label'].tolist()\n",
    "x_val = val_set_third_version['Text'].tolist()\n",
    "y_val = val_set_third_version['Label'].tolist()\n",
    "y_total = y_train + y_val\n",
    "\n",
    "# converting categorical variables to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_total)\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "label_mapping = dict(zip(le.classes_, range(len(le.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 375)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compte le nombre de labels dans le train et le val\n",
    "import numpy as np\n",
    "len(np.unique(y_train)), len(np.unique(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 13 candidates, totalling 26 fits\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.001, classifier__fit_prior=True; total time= 2.1min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.01, classifier__fit_prior=False; total time= 2.4min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.01, classifier__fit_prior=True; total time= 2.4min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.01, classifier__fit_prior=False; total time= 2.4min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.001, classifier__fit_prior=True; total time= 2.5min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.001, classifier__fit_prior=False; total time= 2.5min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.01, classifier__fit_prior=True; total time= 2.5min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.001, classifier__fit_prior=False; total time= 2.5min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, classifier__fit_prior=True; total time= 1.5min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, classifier__fit_prior=False; total time= 2.1min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, classifier__fit_prior=True; total time= 2.1min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, classifier__fit_prior=False; total time= 2.1min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, classifier__fit_prior=True; total time= 2.2min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, classifier__fit_prior=True; total time= 2.2min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, classifier__fit_prior=False; total time= 2.2min\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, classifier__fit_prior=False; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:53:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:53:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=SGDClassifier(), classifier__alpha=0.0001, classifier__loss=log_loss, classifier__penalty=l2; total time= 5.6min\n",
      "[CV] END classifier=SGDClassifier(), classifier__alpha=0.0001, classifier__loss=log_loss, classifier__penalty=l2; total time= 5.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:57:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=SGDClassifier(), classifier__alpha=0.001, classifier__loss=log_loss, classifier__penalty=l2; total time= 6.1min\n",
      "[CV] END classifier=SGDClassifier(), classifier__alpha=0.001, classifier__loss=log_loss, classifier__penalty=l2; total time= 6.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:58:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=SGDClassifier(), classifier__alpha=0.01, classifier__loss=log_loss, classifier__penalty=l2; total time= 7.4min\n",
      "[CV] END classifier=SGDClassifier(), classifier__alpha=0.01, classifier__loss=log_loss, classifier__penalty=l2; total time= 7.5min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Grille d'hyperparamètres optimisée pour le temps\n",
    "param_grid = [\n",
    "    # MultinomialNB (rapide et robuste pour texte)\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.001, 0.01, 0.1, 1.0],\n",
    "        'classifier__fit_prior': [True, False]\n",
    "    },\n",
    "    # SGDClassifier (rapide et efficace)\n",
    "    {\n",
    "        'classifier': [SGDClassifier(max_iter=1000, tol=1e-3)],\n",
    "        'classifier__loss': ['log_loss'],  # Régression logistique\n",
    "        'classifier__alpha': [1e-4, 1e-3, 1e-2],\n",
    "        'classifier__penalty': ['l2']\n",
    "    },\n",
    "    # XGBoost (léger compromis vitesse/précision)\n",
    "    {\n",
    "        'classifier': [XGBClassifier(tree_method='hist', eval_metric='logloss')],\n",
    "        'classifier__n_estimators': [100],  # Nombre d'arbres réduit pour éviter la lenteur\n",
    "        'classifier__learning_rate': [0.05, 0.1],\n",
    "        'classifier__max_depth': [6]\n",
    "    }\n",
    "] \n",
    "\n",
    "\n",
    "# Pipeline général\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 5), max_features=2000)), # Max_features à 2000 pour réduire le temps de calcul\n",
    "    ('classifier', MultinomialNB())  # Placeholder, remplacé par GridSearchCV\n",
    "])\n",
    "\n",
    "# Recherche des meilleurs hyperparamètres avec GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=2, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Meilleur modèle : {best_model}\")\n",
    "\n",
    "# Prédictions sur le set de validation\n",
    "predictions = best_model.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Meilleurs hyperparamètres :\", grid_search.best_params_)\n",
    "print(\"Accuracy sur le set de validation:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190099/190099 [00:07<00:00, 26369.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB(alpha=0.001))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB(alpha=0.001))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000, ngram_range=(1, 5))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.001)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char', max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                ('classifier', MultinomialNB(alpha=0.001))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train = data_train_without_nan_for_label.copy()\n",
    "train = pre_processing(train, remove_espace=False, not_test=False)\n",
    "train = add_alphabet_to_label(train)\n",
    "# train['Text'] = train['Text'].progress_apply(sentencepiece_tokenize)\n",
    "x = train['Text'].tolist()\n",
    "y = train['Label'].tolist()\n",
    "\n",
    "vectorizer= TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 5), max_features=200000)\n",
    "best_model = grid_search.best_estimator_['classifier']\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('classifier', best_model)\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_test = LabelEncoder()\n",
    "y = le_test.fit_transform(y)\n",
    "label_mapping_test = dict(zip(le_test.classes_, range(len(le_test.classes_))))\n",
    "\n",
    "best_pipeline.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190567/190567 [00:00<00:00, 2933874.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Chargement du dataset de test\n",
    "data_test= pd.read_csv(file_path_test)\n",
    "test_set = pre_processing(data_test, remove_espace=False, not_test=False)\n",
    "x_test = test_set['Text'].tolist()\n",
    "\n",
    "# Prédictions sur le set de test\n",
    "predictions_test = best_pipeline.predict(x_test)\n",
    "\n",
    "# Conversion des labels en texte\n",
    "predicted_labels_test = le_test.inverse_transform(predictions_test)\n",
    "predicted_labels_test = restore_labels(predicted_labels_test)\n",
    "test_set['Label'] = predicted_labels_test\n",
    "\n",
    "# Ajout de la colonne ID\n",
    "column_ID = [i for i in range(1, len(test_set)+1)]\n",
    "test_set['ID'] = column_ID\n",
    "\n",
    "# Sauvegarde des prédictions\n",
    "test_set[['ID', 'Label']].to_csv('test_set_v9_sans_tokenizer_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexe: Submition d'un modèle ad-hoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du modèle choisi sur tout le train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190099/190099 [00:07<00:00, 26182.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000, ngram_range=(1, 5))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.001, fit_prior=False)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char', max_features=200000,\n",
       "                                 ngram_range=(1, 5))),\n",
       "                ('mnb', MultinomialNB(alpha=0.001, fit_prior=False))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train = data_train_without_nan_for_label.copy()\n",
    "train = pre_processing(train, remove_espace=False, not_test=False)\n",
    "train = add_alphabet_to_label(train)\n",
    "# train['Text'] = train['Text'].progress_apply(sentencepiece_tokenize)\n",
    "x = train['Text'].tolist()\n",
    "y = train['Label'].tolist()\n",
    "\n",
    "vectorizer= TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 5), max_features=200000)\n",
    "naive_bayes = MultinomialNB(alpha= 0.001, fit_prior = False) \n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('mnb', naive_bayes)\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_test = LabelEncoder()\n",
    "y = le_test.fit_transform(y)\n",
    "label_mapping_test = dict(zip(le_test.classes_, range(len(le_test.classes_))))\n",
    "\n",
    "best_pipeline.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction des labels pour le test et génération du csv à déposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test= pd.read_csv(file_path_test)\n",
    "test_set = pre_processing(data_test, remove_espace=False, not_test=False)\n",
    "# test_set['Text'] = test_set['Text'].progress_apply(sentencepiece_tokenize)\n",
    "\n",
    "x_test = test_set['Text'].tolist()\n",
    "predictions_test = best_pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('test_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190567/190567 [00:00<00:00, 1807588.91it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_test = le_test.inverse_transform(predictions_test)\n",
    "predicted_labels_test = restore_labels(predicted_labels_test)\n",
    "test_set['Label'] = predicted_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_ID = [i for i in range(1, len(test_set)+1)]\n",
    "test_set['ID'] = column_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[['ID', 'Label']].to_csv('test_set_v8_sans_tokenizer_predicted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
