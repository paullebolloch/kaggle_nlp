{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "file_path_train = \"./data/train_submission.csv\"\n",
    "file_path_test = \"./data/test_without_labels.csv\"\n",
    "\n",
    "data_train = pd.read_csv(file_path_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse du dataset d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On observe d'abord les données non labellisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_without_label = data_train[data_train[\"Label\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Public</td>\n",
       "      <td>Kòe bô jōa kú  hō͘-sū sió-chiá lâi kā góan mn̄...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Public</td>\n",
       "      <td>Söğütçük sī chi̍t ê tī Türkiye Aydın séng Çine...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Public</td>\n",
       "      <td>Golden Valley Kūn ū khó-lêng sī kóng:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>Public</td>\n",
       "      <td>Tī Montégut-Lauragais ê sì-ûi ū Nogaret  Revel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Public</td>\n",
       "      <td>Soveria Simeri ùi séng lāi ê hoān-ûi.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189637</th>\n",
       "      <td>Public</td>\n",
       "      <td>Bellebrune sī ūi-tī Hoat-kok Nord-Pas-de-Calai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189946</th>\n",
       "      <td>Public</td>\n",
       "      <td>Bô phah-sǹg  tī sin-le̍k 10 go̍eh 29 hō ē-po͘ ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189959</th>\n",
       "      <td>Public</td>\n",
       "      <td>Wiejki sī chi̍t ê tī Pho-lân Kiōng-hô-kok Podl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190397</th>\n",
       "      <td>Public</td>\n",
       "      <td>Tī pún só͘-chāi sì-ûi ê tē-hng ū Valy  Veselí ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190493</th>\n",
       "      <td>Public</td>\n",
       "      <td>Ojén sī tī Se-pan-gâ Andalucía siā-lí Málaga s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text Label\n",
       "107     Public  Kòe bô jōa kú  hō͘-sū sió-chiá lâi kā góan mn̄...   NaN\n",
       "803     Public  Söğütçük sī chi̍t ê tī Türkiye Aydın séng Çine...   NaN\n",
       "1095    Public              Golden Valley Kūn ū khó-lêng sī kóng:   NaN\n",
       "1894    Public  Tī Montégut-Lauragais ê sì-ûi ū Nogaret  Revel...   NaN\n",
       "2499    Public              Soveria Simeri ùi séng lāi ê hoān-ûi.   NaN\n",
       "...        ...                                                ...   ...\n",
       "189637  Public  Bellebrune sī ūi-tī Hoat-kok Nord-Pas-de-Calai...   NaN\n",
       "189946  Public  Bô phah-sǹg  tī sin-le̍k 10 go̍eh 29 hō ē-po͘ ...   NaN\n",
       "189959  Public  Wiejki sī chi̍t ê tī Pho-lân Kiōng-hô-kok Podl...   NaN\n",
       "190397  Public  Tī pún só͘-chāi sì-ûi ê tē-hng ū Valy  Veselí ...   NaN\n",
       "190493  Public  Ojén sī tī Se-pan-gâ Andalucía siā-lí Málaga s...   NaN\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_without_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a 500 instances qui ne sont pas labellisées. \n",
    "\n",
    "On choisit de se débarasser de ces données pour l'entraînement de nos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_without_nan_for_label = data_train.dropna() # suppression des données non labellisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 390 différentes langues dans le dataset de train\n"
     ]
    }
   ],
   "source": [
    "number_of_languages = len(data_train[\"Label\"].unique())\n",
    "print(f\"Il y a {number_of_languages} différentes langues dans le dataset de train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des données labellisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tgk</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guj</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tat</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crh</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaa</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gil</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toi</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaa</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kua</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcr</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Usage  Text\n",
       "Label             \n",
       "tgk     1500  1500\n",
       "guj     1000  1000\n",
       "tat     1000  1000\n",
       "crh     1000  1000\n",
       "kaa     1000  1000\n",
       "...      ...   ...\n",
       "gil        2     2\n",
       "toi        1     1\n",
       "gaa        1     1\n",
       "kua        1     1\n",
       "gcr        1     1\n",
       "\n",
       "[389 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sorted_by_number_instances_by_language = data_train_without_nan_for_label.groupby(\"Label\").count().sort_values('Usage', ascending=False)\n",
    "dataset_sorted_by_number_instances_by_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observer que le nombre d'exemples par langue varie. Certaines langues sont sur-représentées (avec 1500 instances pour la première) par rapport à d'autres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de langues avec au moins 100 instances est 93.31619537275064%\n"
     ]
    }
   ],
   "source": [
    "percentage_of_languages_with_at_least_100_instances = len(dataset_sorted_by_number_instances_by_language[dataset_sorted_by_number_instances_by_language[\"Usage\"] >= 100])/len(dataset_sorted_by_number_instances_by_language) * 100\n",
    "print(f\"Le pourcentage de langues avec au moins 100 instances est {percentage_of_languages_with_at_least_100_instances}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitement du dataset de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re \n",
    "import unicodedata\n",
    "\n",
    "def cleaning(text): \n",
    "    \"\"\"\n",
    "    Fonction pour pré-traiter le texte en enlevant tous les éléments de ponctuation, les chiffres, les double espaces, les URL etc. \n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip() # enlève les double espaces\n",
    "    # text = re.sub(r\"\\(.*?\\)|\\[.*?\\]|\\{.*?\\}|['\\\"«»„“”‘’]|\\<.*?\\>\", \" \", text) # 1. Supprimer les textes entre (), [], {}, \"\", « »\n",
    "    text = re.sub(r\"https?://[^\\s]+|www\\.[^\\s]+\", \" \", text) # Supprimer les URLs\n",
    "    text = re.sub(r\"\\b[A-Z]+\\d*[A-Z\\d]*\", \" \", text) # Supprimer les sigles type \"IK10\", \"ABC123\", \"X4D\" (au moins 1 lettre + au moins 1 chiffre)\n",
    "    text = re.sub(r\"\\b[A-ZÀ-ÖØ-Þ][a-zà-öø-ÿ]*\", \" \", text) # Supprimer les mots qui commencent par une majuscule (prénoms, noms propres, etc.)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)  # Supprimer les nombres isolés\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Supprimer la ponctuation et les caractères spéciaux\n",
    "    text = ''.join(c for c in text if unicodedata.category(c)[0] not in [\"C\", \"S\"])  # Supprimer les caractères de contrôle Unicode, symboles et emojis\n",
    "\n",
    "    asian_punctuation = \"，。？！《》【】（）；：、。\" # Liste de ponctuation à inclure pour les langues asiatiques\n",
    "    text = text.replace('-', ' ') # enlève les tirets \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + asian_punctuation)) # supprime la ponctuation asiatique\n",
    "    \n",
    "    text_cleaned = text.lower() # met le texte en minuscule \n",
    "\n",
    "    return(text_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit de ne pas enlever le texte entre (), [], {}, \"\", « » car on s'aperçoit que les résultats sont moins bons, cela nous fait perdre de l'information utile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un ensemble de mots anglais pour pouvoir enlever les mots anglais dans les phrases avec des mots anglais mélangés à d'autres langues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/hippolytelecomte/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Télécharger la liste des mots en anglais (une seule fois nécessaire)\n",
    "nltk.download('words')\n",
    "\n",
    "# Liste des mots en anglais\n",
    "english_words = set(word.lower() for word in words.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ang = data_train_without_nan_for_label[data_train_without_nan_for_label[\"Label\"] == 'eng'][\"Text\"]\n",
    "\n",
    "# Collecte des mots uniques\n",
    "for text in data_ang:\n",
    "    for word in text.split():\n",
    "        english_words.add(word.lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_most_english_words(text): \n",
    "    \"\"\"\n",
    "    Fonction pour enlever les mots anglais lorsque la langue du texte n'est pas l'anglais. \n",
    "    \"\"\"\n",
    "    tokens = text.split() \n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in english_words]\n",
    "\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement on s'aperçoit qu'enlever les mots anglais dans les phrases qui ne sont pas labellisées comme du texte anglais baisse nos résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première approche sans tokenizer avec TFIDF et MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation entre le train et le val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, val_set = train_test_split(data_train_without_nan_for_label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application du pré-traitement sur tout le dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()  \n",
    "\n",
    "def pre_processing(df, remove_espace = True, not_test = True, need_to_clean = True): \n",
    "    \"\"\"\n",
    "    Utilisation des méthodes de pré-traitement définies auparavant pour rendre le texte propre. \n",
    "    \"\"\"\n",
    "\n",
    "    if need_to_clean: \n",
    "        df['Text'] = df['Text'].apply(cleaning)\n",
    "    \n",
    "    if not_test: \n",
    "        df['Text'] = df.progress_apply(\n",
    "            lambda row: remove_most_english_words(row['Text']) if row['Label'] != 'eng' else row['Text'], axis=1\n",
    "        )\n",
    "    \n",
    "    if remove_espace: \n",
    "        df['Text'] = df['Text'].str.replace(' ', '', regex=False)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'apperçoit également que dans le dataset d'entraînement il y a des langues qui peuvent écrites dans différents alphabets, c'est le cas pour certaines langues asiatiques notamment. On choisit ainsi de créer une fonction qui permet de détecter les alphabets présents dans la phrase et de déterminer l'alphabet majoritaire en fonction du nombre de caractères (même si cette méthode n'est pas optimale car certains alphabets contiennent plus d'informations dans leur caractère que d'autres). Ensuite on change le label des phrases en ajoutant l'alphabet utilisé pour la langue et créant ainsi de nouvelles catégories comme fra_Latin pour le français écrit avec l'alphabet latin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "\n",
    "# Catégorisation fine des scripts\n",
    "SCRIPT_MAP = {\n",
    "    \"LATIN\": \"Latin\",\n",
    "    \"CYRILLIC\": \"Cyrillique\",\n",
    "    \"ARABIC\": \"Arabe\",\n",
    "    \"HEBREW\": \"Hébreu\",\n",
    "    \"GREEK\": \"Grec\",\n",
    "    \"DEVANAGARI\": \"Devanagari (Hindi, Sanskrit)\",\n",
    "    \"HIRAGANA\": \"Hiragana (Japonais)\",\n",
    "    \"KATAKANA\": \"Katakana (Japonais)\",\n",
    "    \"CJK\": \"Kanji (Chinois, Japonais, Coréen)\",\n",
    "    \"HANGUL\": \"Hangul (Coréen)\",\n",
    "    \"THAI\": \"Thaï\",\n",
    "    \"ARMENIAN\": \"Arménien\",\n",
    "    \"GEORGIAN\": \"Géorgien\",\n",
    "    \"ETHIOPIC\": \"Éthiopien\",\n",
    "    \"TAMIL\": \"Tamoul\",\n",
    "    \"BENGALI\": \"Bengali\",\n",
    "    \"TELUGU\": \"Télougou\",\n",
    "}\n",
    "\n",
    "def count_alphabet_characters(text):\n",
    "    script_counts = defaultdict(int)\n",
    "\n",
    "    for char in text:\n",
    "        if char.isalpha():  # On ignore les symboles et ponctuations\n",
    "            try:\n",
    "                char_name = unicodedata.name(char) \n",
    "                script_key = char_name.split()[0]  # Prend le premier mot du nom Unicode\n",
    "                \n",
    "                if \"CJK\" in char_name:\n",
    "                    script_key = \"CJK\"  # Les kanji sont classés sous \"CJK UNIFIED IDEOGRAPH\"\n",
    "                \n",
    "                script_name = SCRIPT_MAP.get(script_key, script_key)  # Utilise le mapping o\n",
    "                script_counts[script_name] += 1  # Incrémente le compteur\n",
    "                \n",
    "            except ValueError:\n",
    "                continue  # Si le caractère n'a pas de nom Unicode\n",
    "    \n",
    "    return dict(script_counts)  # Retourne un dictionnaire des comptages\n",
    "\n",
    "def most_frequent_script(text):\n",
    "    script_counts = count_alphabet_characters(text)  # Appel de la fonction précédente\n",
    "    \n",
    "    if script_counts:  # Vérifie si le dictionnaire n'est pas vide\n",
    "        most_common_script = max(script_counts.items(), key=lambda x: x[1])  # Trouve l'alphabet avec le max de caractères\n",
    "        return most_common_script  # Retourne (nom de l'alphabet, nombre d'occurrences)\n",
    "    else:\n",
    "        return None  # Retourne None si aucun alphabet trouvé\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def add_alphabet_to_label(df):\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):  # Parcourt chaque ligne du DataFrame\n",
    "        alphabet_most_frequent = most_frequent_script(row['Text'])  # Détecte l'alphabet dominant\n",
    "        \n",
    "        if alphabet_most_frequent:  # Vérifie si un alphabet a été trouvé\n",
    "            df.at[index, 'Label'] = f\"{row['Label']}_{alphabet_most_frequent[0]}\"  # Met à jour le label\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application du pré-traitement et du changement de labellisation sur le train et le val. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152079/152079 [00:12<00:00, 11924.24it/s]\n",
      "100%|██████████| 38020/38020 [00:03<00:00, 11916.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set_first_version = train_set.copy()\n",
    "val_set_first_version = val_set.copy()\n",
    "train_set_first_version = pre_processing(train_set_first_version, remove_espace=False, not_test=False) \n",
    "val_set_first_version = pre_processing(val_set_first_version, remove_espace=False, not_test=False)\n",
    "train_set_first_version = add_alphabet_to_label(train_set_first_version)\n",
    "val_set_first_version = add_alphabet_to_label(val_set_first_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en place de la pipeline pour le modèle où on choisit d'utiliser comme Vectorizer TFIDF et comme modèle MultinomialNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4), max_features=200000)\n",
    "x_train = train_set_first_version['Text'].tolist()\n",
    "y_train = train_set_first_version['Label'].tolist()\n",
    "x_val = val_set_first_version['Text'].tolist()\n",
    "y_val = val_set_first_version['Label'].tolist()\n",
    "y_total = y_train + y_val\n",
    "\n",
    "# converting categorical variables to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_total)\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "label_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "\n",
    "\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_val = vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.001, fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.001, fit_prior=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.001, fit_prior=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB(alpha= 0.001, fit_prior = False) \n",
    "naive_bayes.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8497369805365597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "predictions = naive_bayes.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de fonctions pour récupéer les labels originaux. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = le.inverse_transform(predictions)\n",
    "labels_predict = le.inverse_transform(y_val)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def restore_original_label(label):\n",
    "    return label.split(\"_\")[0]  # Prend seulement la première partie avant '_'\n",
    "\n",
    "def restore_labels(liste):\n",
    "    new_liste = []\n",
    "    for element in tqdm(liste): \n",
    "        new_liste.append(restore_original_label(element))\n",
    "    return np.array(new_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38020/38020 [00:00<00:00, 922950.79it/s]\n",
      "100%|██████████| 38020/38020 [00:00<00:00, 1489528.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8514992109416096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_pred = restore_labels(predicted_labels)\n",
    "val_predict = restore_labels(labels_predict)\n",
    "final_accuracy = accuracy_score(val_predict, final_pred)\n",
    "print(\"Accuracy:\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des résultats (sûrement à améliorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (trié par F1-score décroissant):\n",
      "\n",
      "abk_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 116.0\n",
      "ada_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "ahk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 89.0\n",
      "alt_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "aoj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "arn_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "asm_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 99.0\n",
      "bpy_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "bzj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 104.0\n",
      "cab_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 83.0\n",
      "cak_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 103.0\n",
      "chk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "ctu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "cuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "div_THAANA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "djk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 87.0\n",
      "fon_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "guc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "gym_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 92.0\n",
      "hbo_Hébreu: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 4.0\n",
      "hnj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 5.0\n",
      "hui_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 85.0\n",
      "hus_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "iku_CANADIAN: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "ixl_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "kac_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 107.0\n",
      "kal_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "kan_KANNADA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 92.0\n",
      "kek_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "kjb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "knv_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "kor_Hangul (Coréen): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "ksw_MYANMAR: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 3.0\n",
      "lhu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 39.0\n",
      "lue_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 3.0\n",
      "mah_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 4.0\n",
      "mal_MALAYALAM: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "mau_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 104.0\n",
      "mco_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 108.0\n",
      "mgh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "mps_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 89.0\n",
      "mzh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 99.0\n",
      "naq_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 111.0\n",
      "nav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "nch_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "ncj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "ngu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "nyu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "ote_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 91.0\n",
      "pan_GURMUKHI: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 119.0\n",
      "pls_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 80.0\n",
      "poh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "qub_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 6.0\n",
      "qvi_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "rop_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "sat_OL: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "seh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "sin_SINHALA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 89.0\n",
      "srm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "suz_Devanagari (Hindi, Sanskrit): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 116.0\n",
      "tbz_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "tca_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 91.0\n",
      "tdt_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 77.0\n",
      "tlh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "toj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 107.0\n",
      "tok_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 111.0\n",
      "top_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "tuc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "tuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 117.0\n",
      "tzo_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 97.0\n",
      "xav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 108.0\n",
      "yao_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "yap_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "csy_Latin: F1-score = 0.9959, Precision = 0.9917, Recall = 1.0000, Support = 120.0\n",
      "wal_Latin: F1-score = 0.9956, Precision = 0.9912, Recall = 1.0000, Support = 112.0\n",
      "zai_Latin: F1-score = 0.9955, Precision = 0.9911, Recall = 1.0000, Support = 111.0\n",
      "guj_GUJARATI: F1-score = 0.9955, Precision = 1.0000, Recall = 0.9910, Support = 111.0\n",
      "tso_Latin: F1-score = 0.9955, Precision = 0.9910, Recall = 1.0000, Support = 110.0\n",
      "ksd_Latin: F1-score = 0.9954, Precision = 0.9909, Recall = 1.0000, Support = 109.0\n",
      "mam_Latin: F1-score = 0.9954, Precision = 0.9909, Recall = 1.0000, Support = 109.0\n",
      "kpg_Latin: F1-score = 0.9953, Precision = 0.9907, Recall = 1.0000, Support = 107.0\n",
      "nnb_Latin: F1-score = 0.9953, Precision = 1.0000, Recall = 0.9907, Support = 108.0\n",
      "kos_Latin: F1-score = 0.9953, Precision = 1.0000, Recall = 0.9906, Support = 106.0\n",
      "lvs_Latin: F1-score = 0.9951, Precision = 0.9903, Recall = 1.0000, Support = 102.0\n",
      "tam_Tamoul: F1-score = 0.9951, Precision = 0.9903, Recall = 1.0000, Support = 102.0\n",
      "quw_Latin: F1-score = 0.9950, Precision = 1.0000, Recall = 0.9901, Support = 101.0\n",
      "umb_Latin: F1-score = 0.9950, Precision = 1.0000, Recall = 0.9901, Support = 101.0\n",
      "kjh_Cyrillique: F1-score = 0.9950, Precision = 1.0000, Recall = 0.9900, Support = 100.0\n",
      "cjk_Latin: F1-score = 0.9948, Precision = 0.9897, Recall = 1.0000, Support = 96.0\n",
      "vol_Latin: F1-score = 0.9948, Precision = 1.0000, Recall = 0.9897, Support = 97.0\n",
      "bqc_Latin: F1-score = 0.9948, Precision = 0.9896, Recall = 1.0000, Support = 95.0\n",
      "pon_Latin: F1-score = 0.9948, Precision = 0.9896, Recall = 1.0000, Support = 95.0\n",
      "gom_Devanagari (Hindi, Sanskrit): F1-score = 0.9947, Precision = 0.9895, Recall = 1.0000, Support = 94.0\n",
      "mya_MYANMAR: F1-score = 0.9947, Precision = 0.9894, Recall = 1.0000, Support = 93.0\n",
      "eus_Latin: F1-score = 0.9946, Precision = 1.0000, Recall = 0.9892, Support = 93.0\n",
      "ikk_Latin: F1-score = 0.9946, Precision = 0.9892, Recall = 1.0000, Support = 92.0\n",
      "mos_Latin: F1-score = 0.9946, Precision = 0.9892, Recall = 1.0000, Support = 92.0\n",
      "hun_Latin: F1-score = 0.9945, Precision = 0.9891, Recall = 1.0000, Support = 91.0\n",
      "kam_Latin: F1-score = 0.9942, Precision = 1.0000, Recall = 0.9885, Support = 87.0\n",
      "bem_Latin: F1-score = 0.9942, Precision = 1.0000, Recall = 0.9884, Support = 86.0\n",
      "khm_KHMER: F1-score = 0.9938, Precision = 0.9877, Recall = 1.0000, Support = 80.0\n",
      "vie_Latin: F1-score = 0.9933, Precision = 1.0000, Recall = 0.9867, Support = 75.0\n",
      "kir_Cyrillique: F1-score = 0.9909, Precision = 0.9820, Recall = 1.0000, Support = 109.0\n",
      "kbp_Latin: F1-score = 0.9908, Precision = 0.9818, Recall = 1.0000, Support = 108.0\n",
      "sag_Latin: F1-score = 0.9907, Precision = 0.9907, Recall = 0.9907, Support = 108.0\n",
      "yom_Latin: F1-score = 0.9907, Precision = 0.9815, Recall = 1.0000, Support = 106.0\n",
      "kbd_Cyrillique: F1-score = 0.9905, Precision = 1.0000, Recall = 0.9811, Support = 106.0\n",
      "sgs_Latin: F1-score = 0.9904, Precision = 0.9904, Recall = 0.9904, Support = 104.0\n",
      "ndo_Latin: F1-score = 0.9903, Precision = 0.9903, Recall = 0.9903, Support = 103.0\n",
      "xmf_Géorgien: F1-score = 0.9903, Precision = 1.0000, Recall = 0.9808, Support = 104.0\n",
      "che_Cyrillique: F1-score = 0.9899, Precision = 1.0000, Recall = 0.9800, Support = 100.0\n",
      "snd_Arabe: F1-score = 0.9897, Precision = 1.0000, Recall = 0.9796, Support = 98.0\n",
      "dtp_Latin: F1-score = 0.9896, Precision = 0.9896, Recall = 0.9896, Support = 96.0\n",
      "rug_Latin: F1-score = 0.9896, Precision = 0.9794, Recall = 1.0000, Support = 95.0\n",
      "ewe_Latin: F1-score = 0.9895, Precision = 0.9895, Recall = 0.9895, Support = 95.0\n",
      "tha_Thaï: F1-score = 0.9895, Precision = 0.9792, Recall = 1.0000, Support = 94.0\n",
      "gom_Latin: F1-score = 0.9894, Precision = 1.0000, Recall = 0.9789, Support = 95.0\n",
      "krc_Cyrillique: F1-score = 0.9871, Precision = 1.0000, Recall = 0.9746, Support = 118.0\n",
      "meu_Latin: F1-score = 0.9867, Precision = 0.9911, Recall = 0.9823, Support = 113.0\n",
      "luo_Latin: F1-score = 0.9860, Precision = 0.9815, Recall = 0.9907, Support = 107.0\n",
      "quc_Latin: F1-score = 0.9860, Precision = 0.9815, Recall = 0.9907, Support = 107.0\n",
      "sah_Cyrillique: F1-score = 0.9858, Precision = 0.9905, Recall = 0.9811, Support = 106.0\n",
      "jbo_Latin: F1-score = 0.9849, Precision = 1.0000, Recall = 0.9703, Support = 101.0\n",
      "yid_Hébreu: F1-score = 0.9838, Precision = 0.9785, Recall = 0.9891, Support = 92.0\n",
      "tpi_Latin: F1-score = 0.9836, Precision = 1.0000, Recall = 0.9677, Support = 93.0\n",
      "pap_Latin: F1-score = 0.9835, Precision = 0.9754, Recall = 0.9917, Support = 120.0\n",
      "kmb_Latin: F1-score = 0.9834, Precision = 0.9889, Recall = 0.9780, Support = 91.0\n",
      "hmo_Latin: F1-score = 0.9825, Precision = 0.9767, Recall = 0.9882, Support = 85.0\n",
      "quh_Latin: F1-score = 0.9825, Precision = 0.9655, Recall = 1.0000, Support = 84.0\n",
      "srn_Latin: F1-score = 0.9825, Precision = 0.9882, Recall = 0.9767, Support = 86.0\n",
      "heb_Hébreu: F1-score = 0.9814, Precision = 0.9875, Recall = 0.9753, Support = 81.0\n",
      "roh_Latin: F1-score = 0.9813, Precision = 0.9813, Recall = 0.9813, Support = 107.0\n",
      "ell_Grec: F1-score = 0.9810, Precision = 0.9626, Recall = 1.0000, Support = 103.0\n",
      "orm_Latin: F1-score = 0.9804, Precision = 0.9709, Recall = 0.9901, Support = 101.0\n",
      "acr_Latin: F1-score = 0.9800, Precision = 0.9800, Recall = 0.9800, Support = 100.0\n",
      "mon_Cyrillique: F1-score = 0.9800, Precision = 0.9703, Recall = 0.9899, Support = 99.0\n",
      "kaz_Cyrillique: F1-score = 0.9798, Precision = 1.0000, Recall = 0.9604, Support = 101.0\n",
      "grc_Grec: F1-score = 0.9789, Precision = 1.0000, Recall = 0.9588, Support = 97.0\n",
      "lus_Latin: F1-score = 0.9789, Precision = 0.9789, Recall = 0.9789, Support = 95.0\n",
      "oss_Cyrillique: F1-score = 0.9780, Precision = 1.0000, Recall = 0.9570, Support = 93.0\n",
      "new_Devanagari (Hindi, Sanskrit): F1-score = 0.9778, Precision = 1.0000, Recall = 0.9565, Support = 115.0\n",
      "lit_Latin: F1-score = 0.9776, Precision = 0.9646, Recall = 0.9909, Support = 110.0\n",
      "azb_Arabe: F1-score = 0.9763, Precision = 0.9717, Recall = 0.9810, Support = 105.0\n",
      "udm_Cyrillique: F1-score = 0.9754, Precision = 0.9802, Recall = 0.9706, Support = 102.0\n",
      "lua_Latin: F1-score = 0.9749, Precision = 0.9510, Recall = 1.0000, Support = 97.0\n",
      "cym_Latin: F1-score = 0.9738, Precision = 0.9789, Recall = 0.9688, Support = 96.0\n",
      "kik_Latin: F1-score = 0.9735, Precision = 1.0000, Recall = 0.9485, Support = 97.0\n",
      "gug_Latin: F1-score = 0.9722, Precision = 0.9722, Recall = 0.9722, Support = 108.0\n",
      "uig_Arabe: F1-score = 0.9714, Precision = 1.0000, Recall = 0.9444, Support = 108.0\n",
      "fij_Latin: F1-score = 0.9712, Precision = 0.9528, Recall = 0.9902, Support = 102.0\n",
      "fur_Latin: F1-score = 0.9709, Precision = 1.0000, Recall = 0.9434, Support = 106.0\n",
      "crh_Latin: F1-score = 0.9706, Precision = 1.0000, Recall = 0.9429, Support = 105.0\n",
      "epo_Latin: F1-score = 0.9704, Precision = 0.9880, Recall = 0.9535, Support = 86.0\n",
      "fin_Latin: F1-score = 0.9688, Precision = 0.9688, Recall = 0.9688, Support = 96.0\n",
      "isl_Latin: F1-score = 0.9688, Precision = 0.9588, Recall = 0.9789, Support = 95.0\n",
      "vep_Latin: F1-score = 0.9684, Precision = 0.9892, Recall = 0.9485, Support = 97.0\n",
      "szl_Latin: F1-score = 0.9677, Precision = 0.9890, Recall = 0.9474, Support = 95.0\n",
      "tum_Latin: F1-score = 0.9677, Precision = 0.9783, Recall = 0.9574, Support = 94.0\n",
      "pms_Latin: F1-score = 0.9670, Precision = 1.0000, Recall = 0.9362, Support = 94.0\n",
      "ces_Latin: F1-score = 0.9652, Precision = 0.9798, Recall = 0.9510, Support = 102.0\n",
      "sme_Latin: F1-score = 0.9652, Precision = 1.0000, Recall = 0.9327, Support = 104.0\n",
      "kom_Cyrillique: F1-score = 0.9645, Precision = 0.9794, Recall = 0.9500, Support = 100.0\n",
      "tir_Éthiopien: F1-score = 0.9645, Precision = 0.9406, Recall = 0.9896, Support = 96.0\n",
      "kon_Latin: F1-score = 0.9626, Precision = 0.9890, Recall = 0.9375, Support = 96.0\n",
      "kea_Latin: F1-score = 0.9622, Precision = 0.9780, Recall = 0.9468, Support = 94.0\n",
      "lao_LAO: F1-score = 0.9612, Precision = 0.9252, Recall = 1.0000, Support = 99.0\n",
      "lug_Latin: F1-score = 0.9608, Precision = 0.9703, Recall = 0.9515, Support = 103.0\n",
      "mkd_Cyrillique: F1-score = 0.9608, Precision = 0.9333, Recall = 0.9899, Support = 99.0\n",
      "amh_Éthiopien: F1-score = 0.9605, Precision = 0.9884, Recall = 0.9341, Support = 91.0\n",
      "hye_Arménien: F1-score = 0.9600, Precision = 0.9231, Recall = 1.0000, Support = 84.0\n",
      "glv_Latin: F1-score = 0.9596, Precision = 0.9500, Recall = 0.9694, Support = 98.0\n",
      "mhr_Cyrillique: F1-score = 0.9596, Precision = 0.9596, Recall = 0.9596, Support = 99.0\n",
      "lij_Latin: F1-score = 0.9592, Precision = 0.9495, Recall = 0.9691, Support = 97.0\n",
      "eml_Latin: F1-score = 0.9585, Precision = 0.9811, Recall = 0.9369, Support = 111.0\n",
      "bul_Cyrillique: F1-score = 0.9583, Precision = 0.9485, Recall = 0.9684, Support = 95.0\n",
      "swe_Latin: F1-score = 0.9569, Precision = 0.9487, Recall = 0.9652, Support = 115.0\n",
      "tyv_Cyrillique: F1-score = 0.9569, Precision = 0.9911, Recall = 0.9250, Support = 120.0\n",
      "ace_Latin: F1-score = 0.9565, Precision = 1.0000, Recall = 0.9167, Support = 108.0\n",
      "kat_Géorgien: F1-score = 0.9554, Precision = 0.9224, Recall = 0.9907, Support = 108.0\n",
      "kaa_Latin: F1-score = 0.9545, Precision = 0.9813, Recall = 0.9292, Support = 113.0\n",
      "fao_Latin: F1-score = 0.9537, Precision = 0.9626, Recall = 0.9450, Support = 109.0\n",
      "mar_Devanagari (Hindi, Sanskrit): F1-score = 0.9534, Precision = 0.9388, Recall = 0.9684, Support = 95.0\n",
      "ido_Latin: F1-score = 0.9508, Precision = 0.9886, Recall = 0.9158, Support = 95.0\n",
      "csb_Latin: F1-score = 0.9506, Precision = 0.9625, Recall = 0.9390, Support = 82.0\n",
      "lin_Latin: F1-score = 0.9503, Precision = 1.0000, Recall = 0.9053, Support = 95.0\n",
      "frr_Latin: F1-score = 0.9500, Precision = 0.9694, Recall = 0.9314, Support = 102.0\n",
      "tur_Latin: F1-score = 0.9495, Precision = 0.9216, Recall = 0.9792, Support = 96.0\n",
      "ilo_Latin: F1-score = 0.9469, Precision = 0.9727, Recall = 0.9224, Support = 116.0\n",
      "hsb_Latin: F1-score = 0.9458, Precision = 0.9796, Recall = 0.9143, Support = 105.0\n",
      "pis_Latin: F1-score = 0.9444, Precision = 0.8947, Recall = 1.0000, Support = 34.0\n",
      "grn_Latin: F1-score = 0.9434, Precision = 0.9615, Recall = 0.9259, Support = 108.0\n",
      "ssw_Latin: F1-score = 0.9434, Precision = 0.9615, Recall = 0.9259, Support = 108.0\n",
      "cat_Latin: F1-score = 0.9423, Precision = 0.9159, Recall = 0.9703, Support = 101.0\n",
      "slv_Latin: F1-score = 0.9419, Precision = 0.9878, Recall = 0.9000, Support = 90.0\n",
      "slk_Latin: F1-score = 0.9417, Precision = 0.9238, Recall = 0.9604, Support = 101.0\n",
      "ksh_Latin: F1-score = 0.9412, Precision = 0.9455, Recall = 0.9369, Support = 111.0\n",
      "pus_Arabe: F1-score = 0.9412, Precision = 0.9697, Recall = 0.9143, Support = 105.0\n",
      "afr_Latin: F1-score = 0.9395, Precision = 0.9528, Recall = 0.9266, Support = 109.0\n",
      "gle_Latin: F1-score = 0.9394, Precision = 0.9118, Recall = 0.9688, Support = 96.0\n",
      "chv_Cyrillique: F1-score = 0.9385, Precision = 1.0000, Recall = 0.8842, Support = 95.0\n",
      "diq_Latin: F1-score = 0.9379, Precision = 1.0000, Recall = 0.8830, Support = 94.0\n",
      "rmy_Latin: F1-score = 0.9375, Precision = 0.9783, Recall = 0.9000, Support = 100.0\n",
      "ach_Latin: F1-score = 0.9362, Precision = 0.8800, Recall = 1.0000, Support = 22.0\n",
      "arz_Arabe: F1-score = 0.9351, Precision = 0.9818, Recall = 0.8926, Support = 121.0\n",
      "mai_Devanagari (Hindi, Sanskrit): F1-score = 0.9345, Precision = 0.9640, Recall = 0.9068, Support = 118.0\n",
      "bis_Latin: F1-score = 0.9339, Precision = 0.9636, Recall = 0.9060, Support = 117.0\n",
      "crh_Cyrillique: F1-score = 0.9333, Precision = 1.0000, Recall = 0.8750, Support = 96.0\n",
      "mwl_Latin: F1-score = 0.9320, Precision = 0.9231, Recall = 0.9412, Support = 102.0\n",
      "ful_Latin: F1-score = 0.9305, Precision = 0.9886, Recall = 0.8788, Support = 99.0\n",
      "yor_Latin: F1-score = 0.9286, Precision = 0.9891, Recall = 0.8750, Support = 104.0\n",
      "jam_Latin: F1-score = 0.9266, Precision = 0.9528, Recall = 0.9018, Support = 112.0\n",
      "aln_Latin: F1-score = 0.9252, Precision = 0.9083, Recall = 0.9429, Support = 105.0\n",
      "san_Devanagari (Hindi, Sanskrit): F1-score = 0.9252, Precision = 0.8609, Recall = 1.0000, Support = 99.0\n",
      "ukr_Cyrillique: F1-score = 0.9246, Precision = 0.8932, Recall = 0.9583, Support = 96.0\n",
      "gla_Latin: F1-score = 0.9239, Precision = 0.9681, Recall = 0.8835, Support = 103.0\n",
      "ven_Latin: F1-score = 0.9222, Precision = 1.0000, Recall = 0.8557, Support = 97.0\n",
      "bre_Latin: F1-score = 0.9216, Precision = 0.9592, Recall = 0.8868, Support = 106.0\n",
      "tah_Latin: F1-score = 0.9208, Precision = 0.9894, Recall = 0.8611, Support = 108.0\n",
      "pol_Latin: F1-score = 0.9206, Precision = 0.8529, Recall = 1.0000, Support = 87.0\n",
      "ceb_Latin: F1-score = 0.9195, Precision = 0.9412, Recall = 0.8989, Support = 89.0\n",
      "lfn_Latin: F1-score = 0.9189, Precision = 0.9239, Recall = 0.9140, Support = 93.0\n",
      "npi_Devanagari (Hindi, Sanskrit): F1-score = 0.9182, Precision = 0.9352, Recall = 0.9018, Support = 112.0\n",
      "dyu_Latin: F1-score = 0.9146, Precision = 0.8750, Recall = 0.9579, Support = 95.0\n",
      "por_Latin: F1-score = 0.9137, Precision = 0.9000, Recall = 0.9278, Support = 97.0\n",
      "mzn_Arabe: F1-score = 0.9121, Precision = 0.9432, Recall = 0.8830, Support = 94.0\n",
      "gcf_Latin: F1-score = 0.9091, Precision = 1.0000, Recall = 0.8333, Support = 30.0\n",
      "min_Latin: F1-score = 0.9091, Precision = 0.9091, Recall = 0.9091, Support = 88.0\n",
      "pnb_Arabe: F1-score = 0.9091, Precision = 0.9009, Recall = 0.9174, Support = 109.0\n",
      "kaa_Cyrillique: F1-score = 0.9043, Precision = 1.0000, Recall = 0.8252, Support = 103.0\n",
      "hne_Devanagari (Hindi, Sanskrit): F1-score = 0.9005, Precision = 0.9149, Recall = 0.8866, Support = 97.0\n",
      "bam_Latin: F1-score = 0.8995, Precision = 0.9444, Recall = 0.8586, Support = 99.0\n",
      "vls_Latin: F1-score = 0.8986, Precision = 0.8774, Recall = 0.9208, Support = 101.0\n",
      "ext_Latin: F1-score = 0.8981, Precision = 0.9065, Recall = 0.8899, Support = 109.0\n",
      "quy_Latin: F1-score = 0.8969, Precision = 0.8131, Recall = 1.0000, Support = 87.0\n",
      "pfl_Latin: F1-score = 0.8953, Precision = 0.8652, Recall = 0.9277, Support = 83.0\n",
      "ile_Latin: F1-score = 0.8942, Precision = 0.9490, Recall = 0.8455, Support = 110.0\n",
      "pag_Latin: F1-score = 0.8934, Precision = 0.9670, Recall = 0.8302, Support = 106.0\n",
      "lat_Latin: F1-score = 0.8911, Precision = 0.8654, Recall = 0.9184, Support = 98.0\n",
      "fry_Latin: F1-score = 0.8909, Precision = 0.9245, Recall = 0.8596, Support = 114.0\n",
      "ibo_Latin: F1-score = 0.8889, Precision = 0.9744, Recall = 0.8172, Support = 93.0\n",
      "ton_Latin: F1-score = 0.8889, Precision = 0.9091, Recall = 0.8696, Support = 92.0\n",
      "som_Latin: F1-score = 0.8877, Precision = 0.9765, Recall = 0.8137, Support = 102.0\n",
      "jpn_Katakana (Japonais): F1-score = 0.8846, Precision = 0.8519, Recall = 0.9200, Support = 25.0\n",
      "bod_TIBETAN: F1-score = 0.8832, Precision = 0.8365, Recall = 0.9355, Support = 93.0\n",
      "bih_Devanagari (Hindi, Sanskrit): F1-score = 0.8824, Precision = 0.8523, Recall = 0.9146, Support = 82.0\n",
      "rap_Latin: F1-score = 0.8800, Precision = 0.9706, Recall = 0.8049, Support = 41.0\n",
      "lmo_Latin: F1-score = 0.8786, Precision = 0.8837, Recall = 0.8736, Support = 87.0\n",
      "tls_Latin: F1-score = 0.8786, Precision = 0.9744, Recall = 0.8000, Support = 95.0\n",
      "myv_Cyrillique: F1-score = 0.8778, Precision = 0.8584, Recall = 0.8981, Support = 108.0\n",
      "hmn_Latin: F1-score = 0.8725, Precision = 1.0000, Recall = 0.7739, Support = 115.0\n",
      "tat_Cyrillique: F1-score = 0.8714, Precision = 0.7836, Recall = 0.9813, Support = 107.0\n",
      "arg_Latin: F1-score = 0.8711, Precision = 0.8305, Recall = 0.9159, Support = 107.0\n",
      "ayr_Latin: F1-score = 0.8634, Precision = 0.7840, Recall = 0.9608, Support = 102.0\n",
      "dzo_TIBETAN: F1-score = 0.8627, Precision = 0.8800, Recall = 0.8462, Support = 104.0\n",
      "dan_Latin: F1-score = 0.8619, Precision = 0.9512, Recall = 0.7879, Support = 99.0\n",
      "wol_Latin: F1-score = 0.8606, Precision = 0.9595, Recall = 0.7802, Support = 91.0\n",
      "lzh_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8585, Precision = 0.8198, Recall = 0.9010, Support = 101.0\n",
      "zlm_Latin: F1-score = 0.8548, Precision = 0.8281, Recall = 0.8833, Support = 120.0\n",
      "ron_Latin: F1-score = 0.8544, Precision = 0.7928, Recall = 0.9263, Support = 95.0\n",
      "hau_Latin: F1-score = 0.8529, Precision = 0.8131, Recall = 0.8969, Support = 97.0\n",
      "weighted avg: F1-score = 0.8502, Precision = 0.8629, Recall = 0.8497, Support = 38020.0\n",
      "gsw_Latin: F1-score = 0.8492, Precision = 0.8261, Recall = 0.8736, Support = 87.0\n",
      "nap_Latin: F1-score = 0.8479, Precision = 0.8932, Recall = 0.8070, Support = 114.0\n",
      "nds_Latin: F1-score = 0.8451, Precision = 0.8411, Recall = 0.8491, Support = 106.0\n",
      "deu_Latin: F1-score = 0.8444, Precision = 0.7787, Recall = 0.9223, Support = 103.0\n",
      "bsb_Latin: F1-score = 0.8421, Precision = 0.8462, Recall = 0.8381, Support = 105.0\n",
      "yue_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8417, Precision = 0.8279, Recall = 0.8559, Support = 118.0\n",
      "mon_Latin: F1-score = 0.8364, Precision = 0.9200, Recall = 0.7667, Support = 90.0\n",
      "nep_Devanagari (Hindi, Sanskrit): F1-score = 0.8352, Precision = 0.8085, Recall = 0.8636, Support = 88.0\n",
      "nno_Latin: F1-score = 0.8333, Precision = 0.7265, Recall = 0.9770, Support = 87.0\n",
      "mlt_Latin: F1-score = 0.8283, Precision = 0.8283, Recall = 0.8283, Support = 99.0\n",
      "fra_Latin: F1-score = 0.8276, Precision = 0.7568, Recall = 0.9130, Support = 92.0\n",
      "pcd_Latin: F1-score = 0.8276, Precision = 0.8400, Recall = 0.8155, Support = 103.0\n",
      "uzb_Latin: F1-score = 0.8261, Precision = 0.7917, Recall = 0.8636, Support = 110.0\n",
      "bak_Cyrillique: F1-score = 0.8230, Precision = 0.9663, Recall = 0.7167, Support = 120.0\n",
      "zea_Latin: F1-score = 0.8214, Precision = 0.8734, Recall = 0.7753, Support = 89.0\n",
      "nld_Latin: F1-score = 0.8161, Precision = 0.7778, Recall = 0.8585, Support = 106.0\n",
      "nso_Latin: F1-score = 0.8159, Precision = 0.7736, Recall = 0.8632, Support = 95.0\n",
      "lim_Latin: F1-score = 0.8152, Precision = 0.7544, Recall = 0.8866, Support = 97.0\n",
      "gor_Latin: F1-score = 0.8111, Precision = 0.9012, Recall = 0.7374, Support = 99.0\n",
      "plt_Latin: F1-score = 0.8108, Precision = 0.9783, Recall = 0.6923, Support = 130.0\n",
      "hif_Latin: F1-score = 0.8100, Precision = 0.7431, Recall = 0.8901, Support = 91.0\n",
      "swc_Latin: F1-score = 0.8081, Precision = 0.9195, Recall = 0.7207, Support = 111.0\n",
      "smo_Latin: F1-score = 0.8068, Precision = 0.9103, Recall = 0.7245, Support = 98.0\n",
      "glg_Latin: F1-score = 0.8065, Precision = 0.7979, Recall = 0.8152, Support = 92.0\n",
      "pcm_Latin: F1-score = 0.8047, Precision = 0.7153, Recall = 0.9196, Support = 112.0\n",
      "mya_Latin: F1-score = 0.8000, Precision = 1.0000, Recall = 0.6667, Support = 3.0\n",
      "bar_Latin: F1-score = 0.7982, Precision = 0.7355, Recall = 0.8725, Support = 102.0\n",
      "rue_Cyrillique: F1-score = 0.7958, Precision = 0.6909, Recall = 0.9383, Support = 81.0\n",
      "scn_Latin: F1-score = 0.7930, Precision = 0.7895, Recall = 0.7965, Support = 113.0\n",
      "hat_Latin: F1-score = 0.7853, Precision = 0.8427, Recall = 0.7353, Support = 102.0\n",
      "haw_Latin: F1-score = 0.7848, Precision = 0.9254, Recall = 0.6813, Support = 91.0\n",
      "ast_Latin: F1-score = 0.7792, Precision = 0.6870, Recall = 0.9000, Support = 100.0\n",
      "uig_Latin: F1-score = 0.7758, Precision = 0.8767, Recall = 0.6957, Support = 92.0\n",
      "hil_Latin: F1-score = 0.7692, Precision = 1.0000, Recall = 0.6250, Support = 16.0\n",
      "macro avg: F1-score = 0.7687, Precision = 0.7818, Recall = 0.7696, Support = 38020.0\n",
      "kur_Latin: F1-score = 0.7672, Precision = 0.6899, Recall = 0.8641, Support = 103.0\n",
      "wuu_Kanji (Chinois, Japonais, Coréen): F1-score = 0.7619, Precision = 0.7652, Recall = 0.7586, Support = 116.0\n",
      "bjn_Latin: F1-score = 0.7602, Precision = 0.7850, Recall = 0.7368, Support = 114.0\n",
      "srd_Latin: F1-score = 0.7582, Precision = 0.9583, Recall = 0.6273, Support = 110.0\n",
      "ekk_Latin: F1-score = 0.7556, Precision = 0.7391, Recall = 0.7727, Support = 110.0\n",
      "jpn_Hiragana (Japonais): F1-score = 0.7529, Precision = 0.6531, Recall = 0.8889, Support = 36.0\n",
      "kab_Latin: F1-score = 0.7512, Precision = 0.6581, Recall = 0.8750, Support = 88.0\n",
      "tsn_Latin: F1-score = 0.7500, Precision = 0.8118, Recall = 0.6970, Support = 99.0\n",
      "oci_Latin: F1-score = 0.7486, Precision = 0.7701, Recall = 0.7283, Support = 92.0\n",
      "cbk_Latin: F1-score = 0.7485, Precision = 0.8101, Recall = 0.6957, Support = 92.0\n",
      "kat_Latin: F1-score = 0.7435, Precision = 0.7889, Recall = 0.7030, Support = 101.0\n",
      "ber_Latin: F1-score = 0.7419, Precision = 0.8625, Recall = 0.6509, Support = 106.0\n",
      "hbs_Cyrillique: F1-score = 0.7295, Precision = 0.6268, Recall = 0.8725, Support = 102.0\n",
      "aka_Latin: F1-score = 0.7243, Precision = 0.7882, Recall = 0.6700, Support = 100.0\n",
      "est_Latin: F1-score = 0.7236, Precision = 0.7273, Recall = 0.7200, Support = 100.0\n",
      "jav_Latin: F1-score = 0.7228, Precision = 0.7766, Recall = 0.6759, Support = 108.0\n",
      "kmr_Latin: F1-score = 0.7152, Precision = 0.8429, Recall = 0.6211, Support = 95.0\n",
      "ori_ORIYA: F1-score = 0.7122, Precision = 0.6952, Recall = 0.7300, Support = 100.0\n",
      "prs_Arabe: F1-score = 0.7097, Precision = 0.5752, Recall = 0.9263, Support = 95.0\n",
      "twi_Latin: F1-score = 0.7094, Precision = 0.6923, Recall = 0.7273, Support = 99.0\n",
      "ina_Latin: F1-score = 0.7091, Precision = 0.6341, Recall = 0.8041, Support = 97.0\n",
      "cmn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.7065, Precision = 0.6771, Recall = 0.7386, Support = 88.0\n",
      "arb_Arabe: F1-score = 0.7011, Precision = 0.6209, Recall = 0.8051, Support = 118.0\n",
      "mlg_Latin: F1-score = 0.6979, Precision = 0.6406, Recall = 0.7664, Support = 107.0\n",
      "nya_Latin: F1-score = 0.6977, Precision = 0.8108, Recall = 0.6122, Support = 98.0\n",
      "mri_Latin: F1-score = 0.6957, Precision = 0.7805, Recall = 0.6275, Support = 102.0\n",
      "hin_Devanagari (Hindi, Sanskrit): F1-score = 0.6952, Precision = 0.6577, Recall = 0.7374, Support = 99.0\n",
      "bak_Latin: F1-score = 0.6936, Precision = 0.6977, Recall = 0.6897, Support = 87.0\n",
      "bew_Cyrillique: F1-score = 0.6927, Precision = 0.7848, Recall = 0.6200, Support = 100.0\n",
      "xho_Latin: F1-score = 0.6918, Precision = 0.9322, Recall = 0.5500, Support = 100.0\n",
      "que_Latin: F1-score = 0.6897, Precision = 0.9615, Recall = 0.5376, Support = 93.0\n",
      "bel_Cyrillique: F1-score = 0.6875, Precision = 0.6346, Recall = 0.7500, Support = 88.0\n",
      "nbl_Latin: F1-score = 0.6864, Precision = 0.5870, Recall = 0.8265, Support = 98.0\n",
      "ckb_Arabe: F1-score = 0.6772, Precision = 0.5658, Recall = 0.8431, Support = 102.0\n",
      "khm_Latin: F1-score = 0.6667, Precision = 1.0000, Recall = 0.5000, Support = 2.0\n",
      "ory_ORIYA: F1-score = 0.6667, Precision = 0.6824, Recall = 0.6517, Support = 89.0\n",
      "teo_Latin: F1-score = 0.6667, Precision = 1.0000, Recall = 0.5000, Support = 2.0\n",
      "glk_Arabe: F1-score = 0.6570, Precision = 0.6296, Recall = 0.6869, Support = 99.0\n",
      "run_Latin: F1-score = 0.6552, Precision = 0.5672, Recall = 0.7755, Support = 98.0\n",
      "hrx_Latin: F1-score = 0.6522, Precision = 1.0000, Recall = 0.4839, Support = 31.0\n",
      "ltz_Latin: F1-score = 0.6455, Precision = 0.5726, Recall = 0.7396, Support = 96.0\n",
      "spa_Latin: F1-score = 0.6364, Precision = 0.5882, Recall = 0.6931, Support = 101.0\n",
      "war_Latin: F1-score = 0.6243, Precision = 0.6556, Recall = 0.5960, Support = 99.0\n",
      "jpn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6102, Precision = 0.8182, Recall = 0.4865, Support = 37.0\n",
      "aym_Latin: F1-score = 0.6099, Precision = 0.8958, Recall = 0.4624, Support = 93.0\n",
      "sqi_Latin: F1-score = 0.6083, Precision = 0.5500, Recall = 0.6804, Support = 97.0\n",
      "tgl_Latin: F1-score = 0.6073, Precision = 0.6667, Recall = 0.5577, Support = 104.0\n",
      "zho_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6064, Precision = 0.6867, Recall = 0.5429, Support = 105.0\n",
      "ita_Latin: F1-score = 0.6019, Precision = 0.5285, Recall = 0.6989, Support = 93.0\n",
      "tuk_Cyrillique: F1-score = 0.5983, Precision = 0.4930, Recall = 0.7609, Support = 46.0\n",
      "ban_Latin: F1-score = 0.5933, Precision = 0.6526, Recall = 0.5439, Support = 114.0\n",
      "urd_Arabe: F1-score = 0.5929, Precision = 0.4747, Recall = 0.7895, Support = 95.0\n",
      "sot_Latin: F1-score = 0.5833, Precision = 0.6364, Recall = 0.5385, Support = 104.0\n",
      "wln_Latin: F1-score = 0.5778, Precision = 0.5714, Recall = 0.5843, Support = 89.0\n",
      "swa_Latin: F1-score = 0.5772, Precision = 0.5379, Recall = 0.6228, Support = 114.0\n",
      "guj_Devanagari (Hindi, Sanskrit): F1-score = 0.5744, Precision = 0.6292, Recall = 0.5283, Support = 106.0\n",
      "nob_Latin: F1-score = 0.5741, Precision = 0.5391, Recall = 0.6139, Support = 101.0\n",
      "tat_Latin: F1-score = 0.5732, Precision = 0.8333, Recall = 0.4369, Support = 103.0\n",
      "aze_Latin: F1-score = 0.5727, Precision = 0.5526, Recall = 0.5943, Support = 106.0\n",
      "srp_Latin: F1-score = 0.5714, Precision = 0.6582, Recall = 0.5049, Support = 103.0\n",
      "sun_Latin: F1-score = 0.5612, Precision = 0.6044, Recall = 0.5238, Support = 105.0\n",
      "aze_Arabe: F1-score = 0.5600, Precision = 0.5250, Recall = 0.6000, Support = 105.0\n",
      "tgk_Cyrillique: F1-score = 0.5509, Precision = 0.6765, Recall = 0.4646, Support = 99.0\n",
      "vec_Latin: F1-score = 0.5437, Precision = 0.4870, Recall = 0.6154, Support = 91.0\n",
      "hbs_Latin: F1-score = 0.5402, Precision = 0.4098, Recall = 0.7925, Support = 106.0\n",
      "uzn_Cyrillique: F1-score = 0.5285, Precision = 0.6000, Recall = 0.4722, Support = 108.0\n",
      "hau_Arabe: F1-score = 0.5263, Precision = 0.6944, Recall = 0.4237, Support = 118.0\n",
      "swh_Latin: F1-score = 0.5263, Precision = 0.5140, Recall = 0.5392, Support = 102.0\n",
      "mad_Latin: F1-score = 0.5258, Precision = 0.5234, Recall = 0.5283, Support = 106.0\n",
      "sna_Latin: F1-score = 0.5200, Precision = 0.8125, Recall = 0.3824, Support = 102.0\n",
      "san_Latin: F1-score = 0.5185, Precision = 0.5385, Recall = 0.5000, Support = 14.0\n",
      "ary_Arabe: F1-score = 0.5164, Precision = 0.5093, Recall = 0.5238, Support = 105.0\n",
      "kur_Arabe: F1-score = 0.5091, Precision = 0.7500, Recall = 0.3853, Support = 109.0\n",
      "bik_Latin: F1-score = 0.5050, Precision = 0.4554, Recall = 0.5667, Support = 90.0\n",
      "fil_Latin: F1-score = 0.5000, Precision = 0.4636, Recall = 0.5426, Support = 94.0\n",
      "cos_Latin: F1-score = 0.4973, Precision = 0.6216, Recall = 0.4144, Support = 111.0\n",
      "kin_Latin: F1-score = 0.4972, Precision = 0.4835, Recall = 0.5116, Support = 86.0\n",
      "azj_Latin: F1-score = 0.4945, Precision = 0.5294, Recall = 0.4639, Support = 97.0\n",
      "pam_Latin: F1-score = 0.4932, Precision = 0.4500, Recall = 0.5455, Support = 99.0\n",
      "uzb_Cyrillique: F1-score = 0.4887, Precision = 0.3892, Recall = 0.6566, Support = 99.0\n",
      "nor_Latin: F1-score = 0.4859, Precision = 0.5513, Recall = 0.4343, Support = 99.0\n",
      "srp_Cyrillique: F1-score = 0.4818, Precision = 0.7021, Recall = 0.3667, Support = 90.0\n",
      "pes_Arabe: F1-score = 0.4625, Precision = 0.6607, Recall = 0.3558, Support = 104.0\n",
      "apc_Arabe: F1-score = 0.4623, Precision = 0.5111, Recall = 0.4220, Support = 109.0\n",
      "tgk_Latin: F1-score = 0.4605, Precision = 0.5303, Recall = 0.4070, Support = 86.0\n",
      "ara_Arabe: F1-score = 0.4599, Precision = 0.3708, Recall = 0.6055, Support = 109.0\n",
      "ajp_Arabe: F1-score = 0.4476, Precision = 0.3588, Recall = 0.5949, Support = 79.0\n",
      "acm_Arabe: F1-score = 0.4459, Precision = 0.5469, Recall = 0.3763, Support = 93.0\n",
      "als_Latin: F1-score = 0.4417, Precision = 0.5538, Recall = 0.3673, Support = 98.0\n",
      "fas_Arabe: F1-score = 0.4365, Precision = 0.4257, Recall = 0.4479, Support = 96.0\n",
      "sco_Latin: F1-score = 0.4171, Precision = 0.2872, Recall = 0.7615, Support = 109.0\n",
      "eng_Latin: F1-score = 0.4011, Precision = 0.2788, Recall = 0.7143, Support = 105.0\n",
      "msa_Latin: F1-score = 0.4000, Precision = 0.3525, Recall = 0.4623, Support = 106.0\n",
      "nde_Latin: F1-score = 0.3949, Precision = 0.4133, Recall = 0.3780, Support = 82.0\n",
      "zsm_Latin: F1-score = 0.3871, Precision = 0.3462, Recall = 0.4390, Support = 82.0\n",
      "hin_Latin: F1-score = 0.3855, Precision = 0.3200, Recall = 0.4848, Support = 99.0\n",
      "bcl_Latin: F1-score = 0.3767, Precision = 0.3717, Recall = 0.3818, Support = 110.0\n",
      "afb_Arabe: F1-score = 0.3743, Precision = 0.3889, Recall = 0.3608, Support = 97.0\n",
      "zul_Latin: F1-score = 0.3718, Precision = 0.4531, Recall = 0.3152, Support = 92.0\n",
      "ind_Latin: F1-score = 0.3614, Precision = 0.3797, Recall = 0.3448, Support = 87.0\n",
      "tgk_Arabe: F1-score = 0.3506, Precision = 0.5192, Recall = 0.2647, Support = 102.0\n",
      "som_Arabe: F1-score = 0.3089, Precision = 0.9048, Recall = 0.1863, Support = 102.0\n",
      "enm_Latin: F1-score = 0.2857, Precision = 0.3333, Recall = 0.2500, Support = 4.0\n",
      "bos_Latin: F1-score = 0.2674, Precision = 0.3485, Recall = 0.2170, Support = 106.0\n",
      "guj_Latin: F1-score = 0.2500, Precision = 0.1667, Recall = 0.5000, Support = 2.0\n",
      "lin: F1-score = 0.2286, Precision = 0.1290, Recall = 1.0000, Support = 4.0\n",
      "hrv_Latin: F1-score = 0.2014, Precision = 0.2593, Recall = 0.1647, Support = 85.0\n",
      "bod_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "cos: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "dzo_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 5.0\n",
      "ful: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "hat: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "hau: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "hif: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "hin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "hne_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "hyw_Arménien: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 7.0\n",
      "iba_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "ibo: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "lao_Cyrillique: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "lao_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 7.0\n",
      "lij: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "lue: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "lug: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "mai_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "miq_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "mlg: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "mon: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 4.0\n",
      "msa: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "mwl_Arabe: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "nep_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "ngl_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 3.0\n",
      "niu_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "nya: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "ori_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "quz_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "rmy: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "smo: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "som: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sot: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sun: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "tam_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "tgk: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "tha_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "wbm_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "wol: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "xho: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "zul: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtenir les indices des classes présentes dans y_val\n",
    "present_classes = np.unique(np.concatenate((y_val, predictions)))\n",
    "\n",
    "# Extraire uniquement les noms correspondants\n",
    "filtered_target_names = [le.classes_[i] for i in present_classes]\n",
    "\n",
    "# Générer le rapport de classification sous forme de dictionnaire\n",
    "report = classification_report(y_val, predictions, target_names=filtered_target_names, output_dict=True)\n",
    "\n",
    "# Filtrer les classes (en excluant 'accuracy', 'macro avg', 'weighted avg')\n",
    "filtered_report = {label: metrics for label, metrics in report.items() if isinstance(metrics, dict)}\n",
    "\n",
    "# Trier les langues par F1-score de manière décroissante\n",
    "sorted_report = sorted(filtered_report.items(), key=lambda x: x[1]['f1-score'], reverse=True)\n",
    "\n",
    "# Afficher le rapport trié\n",
    "print(\"Classification Report (trié par F1-score décroissant):\\n\")\n",
    "for label, metrics in sorted_report:\n",
    "    print(f\"{label}: F1-score = {metrics['f1-score']:.4f}, Precision = {metrics['precision']:.4f}, Recall = {metrics['recall']:.4f}, Support = {metrics['support']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85817</th>\n",
       "      <td>Public</td>\n",
       "      <td>وزیراعظم پیروں کی اولاد ہیں لینے پر آئیں تو در...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80221</th>\n",
       "      <td>Public</td>\n",
       "      <td>یہ آئین و قانون اور متاثرہ عوام کے درمیان بڑے...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137438</th>\n",
       "      <td>Public</td>\n",
       "      <td>لَوْ لاَ الشُّيُوخُ الرُكَّعُ وَاْلبَهائِمُ ال...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26667</th>\n",
       "      <td>Public</td>\n",
       "      <td>فقر اوہ جنہاں فکر ن کوئی، جیڑھے رب دے راہ وکانے</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50294</th>\n",
       "      <td>Public</td>\n",
       "      <td>قال سلمان وإن هذا لكائن يا رسول الله؟ قال صلى ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189041</th>\n",
       "      <td>Public</td>\n",
       "      <td>جی پی ایس موجود نہیں، براہِ کرم اپنے موبائل کی...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81019</th>\n",
       "      <td>Public</td>\n",
       "      <td>پھر اگر یہ بھی فرض کر لیا جائے کہ اس نے طاقت ک...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78097</th>\n",
       "      <td>Public</td>\n",
       "      <td>آج کے افسانہ نگارپرکیچڑ اچھالنے والے حقیقتِ ح...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32309</th>\n",
       "      <td>Public</td>\n",
       "      <td>ملک پورملک مشتاق کے گھر ایک عظیم الشان محفل من...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63494</th>\n",
       "      <td>Public</td>\n",
       "      <td>۔ قیمت کا تعین بھی کرتے ہیں کیونکہ اس سے کتاب ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69108</th>\n",
       "      <td>Public</td>\n",
       "      <td>نوجوانوں کی ترقی، خوشحالی اور خود مختاری حکومت...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45458</th>\n",
       "      <td>Public</td>\n",
       "      <td>ھون پاس پر چڑھنے کیلئے منتخب کرنے کی وجہ بیان ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30973</th>\n",
       "      <td>Public</td>\n",
       "      <td>عَلَى الاِسلاَمِ السَّلامُ اِذْ قَدْ بُلِيَتِ ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178389</th>\n",
       "      <td>Public</td>\n",
       "      <td>جدہکرناٹکا نان ریسڈینڈنٹ انڈین فورم جدہ کے صدر...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184356</th>\n",
       "      <td>Public</td>\n",
       "      <td>ہمارے علم کے مطابق ان میں سے کسی کتاب کا اردو ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180827</th>\n",
       "      <td>Public</td>\n",
       "      <td>یہ بلکل غلط تصور ہے یاد رہے کے</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93807</th>\n",
       "      <td>Public</td>\n",
       "      <td>زمین پر وعدہ تنازعے سے متعلق معاہدے کا حصہ ہے ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98255</th>\n",
       "      <td>Public</td>\n",
       "      <td>اقوام متحدہ کے سیکرٹری جنرل کی خصوصی نمائندہ پ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31115</th>\n",
       "      <td>Public</td>\n",
       "      <td>ایک بڑے ہال میں لے گئے جہاں سیکڑوں لڑکے لڑکیاں...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96347</th>\n",
       "      <td>Public</td>\n",
       "      <td>اسلام میں جادو کے توڑ کے لیے بہت سارے حل موجود...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28586</th>\n",
       "      <td>Public</td>\n",
       "      <td>۔ کارروائی دانستہ ہو ۔ ۔ انسانی حقوق کی خلاف و...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53192</th>\n",
       "      <td>Public</td>\n",
       "      <td>کا نام دیا گیا ہے کورونا وائرس کو کووڈ</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135120</th>\n",
       "      <td>Public</td>\n",
       "      <td>کیٹاگری میں تازہ ترین agged ایف آئی اے، بینظیر...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135422</th>\n",
       "      <td>Public</td>\n",
       "      <td>چیف جسٹس نے پوچھا کہ پیمرا قانون میں ترمیم کے ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30731</th>\n",
       "      <td>Public</td>\n",
       "      <td>بےنظیرکےبعد زرداری اوربلاول آگئے،بلاول کوتواُر...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25972</th>\n",
       "      <td>Public</td>\n",
       "      <td>lang منتخب موضوعات کو منتقل کر دیا گیا ہے</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18544</th>\n",
       "      <td>Public</td>\n",
       "      <td>کلثوم نواز کی میت کو پی آئی اے کی پرواز پی کے ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149758</th>\n",
       "      <td>Public</td>\n",
       "      <td>مذکورہ پیلی ساڑی والی عورت بگ باس میں جانا چاہ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151358</th>\n",
       "      <td>Public</td>\n",
       "      <td>arz سرائیکی خط جناب حبیب امام مظلوم چر جگ حبیب...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163891</th>\n",
       "      <td>Public</td>\n",
       "      <td>الزكاة واجبة على الحرّ العاقل البالغ المسلم إذ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186587</th>\n",
       "      <td>Public</td>\n",
       "      <td>واشنگٹن امریکی کانگریس میں پاکستان کاکس کی شری...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48109</th>\n",
       "      <td>Public</td>\n",
       "      <td>ظاہر اور باطن بھی تم ہو</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128642</th>\n",
       "      <td>Public</td>\n",
       "      <td>نئے پیدائش زیادہ سرمایہ کاری حاصل کی اور بائیو...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85823</th>\n",
       "      <td>Public</td>\n",
       "      <td>ایران امریکا تنازع کی صورت میں کسی کی حمایت نہ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105396</th>\n",
       "      <td>Public</td>\n",
       "      <td>خاشقجی کی لاش قونصل جنرل کی رہائش گاہ کی بھٹی ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70625</th>\n",
       "      <td>Public</td>\n",
       "      <td>وفاق کے زیر انتظام قبائلی علاقوں کے تعلیم یافت...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21107</th>\n",
       "      <td>Public</td>\n",
       "      <td>انصاف کا قتل نواز یافتہ تحقیقاتی کمیشن نے ماڈل...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167102</th>\n",
       "      <td>Public</td>\n",
       "      <td>الجبر والتشبيه أمويان، والعدل والتوحيد علويان</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48915</th>\n",
       "      <td>Public</td>\n",
       "      <td>سامنے ہم جو رکھیں گر ترا کردار حسینؓ</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147174</th>\n",
       "      <td>Public</td>\n",
       "      <td>فروغ انسانی وسائل کی وزارت نے چیلنجز کو مواقع ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31700</th>\n",
       "      <td>Public</td>\n",
       "      <td>سیاحون سمیت مری شہر اور گرد و نواح کی مقامی آب...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41454</th>\n",
       "      <td>Public</td>\n",
       "      <td>مرموزکار، مزید ایسے ایڈوب فلیش سرور ، owza میڈ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83784</th>\n",
       "      <td>Public</td>\n",
       "      <td>الریاض شاہ رخ خان نے سعودی عرب کے بارے میں کیا...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136691</th>\n",
       "      <td>Public</td>\n",
       "      <td>نے کہہ دیا کہ یہ معاہدہ سیکولر نظریات کیخلاف ہ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60912</th>\n",
       "      <td>Public</td>\n",
       "      <td>چه مسعود نام و چه احمد مقام</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184860</th>\n",
       "      <td>Public</td>\n",
       "      <td>فطرت کے مقاصد کی کرتاے نگہبانی</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108988</th>\n",
       "      <td>Public</td>\n",
       "      <td>۔ میں آپ کے لیے تین بہترین شعبے تجویز کروں گا</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19726</th>\n",
       "      <td>Public</td>\n",
       "      <td>انہوں نے کہا کہ کھاد کی قیمتوں میں کمی کے لیے ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97997</th>\n",
       "      <td>Public</td>\n",
       "      <td>نیو اسلام آباد ائیرپورٹ کو آفیشل نام دے دیا گی...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38750</th>\n",
       "      <td>Public</td>\n",
       "      <td>إن الدين يسر، ولن يشاد أحد الدين إلا غلبه…</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43629</th>\n",
       "      <td>Public</td>\n",
       "      <td>ہم چین میں arduino مطابقت کے سپلائرز کے لئے اہ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67639</th>\n",
       "      <td>Public</td>\n",
       "      <td>وقد أول الخلف الاستواء بالقهر والاستيلاء على ا...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51743</th>\n",
       "      <td>Public</td>\n",
       "      <td>یہ غلطیاں تہذیبی تغیر میں کثرت سے رُونما ہوئیں...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64751</th>\n",
       "      <td>Public</td>\n",
       "      <td>دو طرفہ ٹاک کے ساتھ او ایم جی وائی فائی بلوٹوت...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149119</th>\n",
       "      <td>Public</td>\n",
       "      <td>قَالَ بُرَيْدَةُ سَمِعْتُ رَسُولَ اللَّهِ صلى ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66864</th>\n",
       "      <td>Public</td>\n",
       "      <td>اپنے گاہک کی بنیاد بنائیں اور رابطے میں رہیں ۔...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166797</th>\n",
       "      <td>Public</td>\n",
       "      <td>حجت الاسلام و المسلمین حسین انصاریان نے کہا حق...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163383</th>\n",
       "      <td>Public</td>\n",
       "      <td>دستاویز کی جانب سے منظور ہو گئی ہے۔ مزید کسی ک...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86002</th>\n",
       "      <td>Public</td>\n",
       "      <td>ان تمام ہیکر گروپس کے علاوہ آج کل ایک نئی اصطلاح</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25170</th>\n",
       "      <td>Public</td>\n",
       "      <td>سڑکوں پر ہر طرف کالا دھواں،اور آسمان پہ چھائی ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98531</th>\n",
       "      <td>Public</td>\n",
       "      <td>راس العین سے فورسز نکال لیں ، ترکی نے فائر بند...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39874</th>\n",
       "      <td>Public</td>\n",
       "      <td>چھوڑے بُکس بورنگ اتنے بُکس دیکھو گی سر چکڑا جا...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118299</th>\n",
       "      <td>Public</td>\n",
       "      <td>تو نادان مفت میں رو رہی ہے کہ جس کک باکسر کو ا...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81597</th>\n",
       "      <td>Public</td>\n",
       "      <td>واشنگٹن، اکتوبر ءپی آرنیوزوائر– سی جی اے پی نے...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94636</th>\n",
       "      <td>Public</td>\n",
       "      <td>پوسٹ کارڈز میں نریندر مودی سے کہا گیا ہے کہ ہن...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24881</th>\n",
       "      <td>Public</td>\n",
       "      <td>پاکستان تحرک انصاف عوامی امنگوں کی مکمل ترجمان...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95363</th>\n",
       "      <td>Public</td>\n",
       "      <td>جناب یحییٰ بختیار ٹھیک نہیں ہے، تیز نہیں ہوسکتا۔</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38283</th>\n",
       "      <td>Public</td>\n",
       "      <td>وَالْأَفْضَلُ فِي الزَّكَاةِ وَالْفِطْرِ وَالن...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td>Public</td>\n",
       "      <td>یو لائیو گیمز ایک کھیل اور اسپورٹس پلیٹ فارم ہ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118378</th>\n",
       "      <td>Public</td>\n",
       "      <td>کپ ملے جلے گری دار میوے دھلے ہوئے</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20394</th>\n",
       "      <td>Public</td>\n",
       "      <td>من ضحك أن يعيد الوضوء ويعيد الصلاة</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103284</th>\n",
       "      <td>Public</td>\n",
       "      <td>من كان منكم مصليا بعد الجمعة فليصلّ اربعا</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67289</th>\n",
       "      <td>Public</td>\n",
       "      <td>آزادی اور اسلام کے دو عنوانات تھے جنکے ساتھ ہم...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66747</th>\n",
       "      <td>Public</td>\n",
       "      <td>ان كل واحد من القوى النفسانية مهما انضم اليها ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80013</th>\n",
       "      <td>Public</td>\n",
       "      <td>رائے احمد کھرل وی پنجاب دے ایس علاقے دا سی۔</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169965</th>\n",
       "      <td>Public</td>\n",
       "      <td>ایک بات خوشآئیند ہے کہ حال میں اردو بلاگرز کے ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46676</th>\n",
       "      <td>Public</td>\n",
       "      <td>ohn ccain وال سٹریٹ جرنل نے بدھ کو رپورٹ کیا ک...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190496</th>\n",
       "      <td>Public</td>\n",
       "      <td>اور یہ طریقہ آج ہمارے اکثر دیہات میں رائج ہیں ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87391</th>\n",
       "      <td>Public</td>\n",
       "      <td>بیشک رانا بھائی کا ورک کافی اچھا جا رہا تھا می...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67077</th>\n",
       "      <td>Public</td>\n",
       "      <td>یہ خود درستگی کے مارے افراد</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54220</th>\n",
       "      <td>Public</td>\n",
       "      <td>ٹریڈ کردہ لاٹ انعامی لاٹس</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>Public</td>\n",
       "      <td>ایرانی صدر نے کہا کہ مشترکہ ایٹمی معاہدے کا مق...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157547</th>\n",
       "      <td>Public</td>\n",
       "      <td>﴿أَمْ كُنْتُمْ شُهَدَاءَ إِذْ حَضَرَ يَعْقُوبَ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122388</th>\n",
       "      <td>Public</td>\n",
       "      <td>جہاں بڑے بڑے تمام کھلاڑ ی ناکام ہو گئے وہاں فہ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66810</th>\n",
       "      <td>Public</td>\n",
       "      <td>· مصنف نے چونکہ درایت حدیث سے متعلق مواد اپنی ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154741</th>\n",
       "      <td>Public</td>\n",
       "      <td>صدر مملکت جناب آصف علی زرداری نے کراچی میں پیپ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68868</th>\n",
       "      <td>Public</td>\n",
       "      <td>عَنِ السَّائِبِ بْنِ يَزِيدَ رَضِي اللهُ عَنْه...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>Public</td>\n",
       "      <td>epsi oke aseous rinks پیپسی اور کوکا کولا اور ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64295</th>\n",
       "      <td>Public</td>\n",
       "      <td>parkoviště آپ کی outube ویڈیوز یا ملٹی میڈیا م...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150083</th>\n",
       "      <td>Public</td>\n",
       "      <td>اثر پاکستان آزاد جموں و کشمیر عوامی تحریک برائ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38924</th>\n",
       "      <td>Public</td>\n",
       "      <td>صوابی تربت میں شہید ھونے والے ایف سی اہلکار نا...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>Public</td>\n",
       "      <td>عَنْ عَائِشَةَ رضي الله عنها أَنَّ فَاطِمَةَ ب...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116014</th>\n",
       "      <td>Public</td>\n",
       "      <td>ایران جب سے خلافت کے دائرہ کار سے آزاد ہوا تو...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>Public</td>\n",
       "      <td>ome میرے سا تھہ آئیے</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115061</th>\n",
       "      <td>Public</td>\n",
       "      <td>ان کے بقول وہ تین ہفتوں تک وہاں ایک نجی کلینک ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145958</th>\n",
       "      <td>Public</td>\n",
       "      <td>فَاطِمَةُ بِضْعَةٌ مِنِّى فَمَنْ أَ غْضَبَهَا ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26782</th>\n",
       "      <td>Public</td>\n",
       "      <td>وزارت محنت کے مطابق وہ غیر ملکی افراد جنہو ں ن...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169747</th>\n",
       "      <td>Public</td>\n",
       "      <td>بھائی سب سو گئے میں بور ہو رہی ہوں۔۔۔ آپ میرے ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172386</th>\n",
       "      <td>Public</td>\n",
       "      <td>پٹن پنچایت صدارتی انتخابات کے لئے تنظیم نے مید...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29134</th>\n",
       "      <td>Public</td>\n",
       "      <td>سنی لیون کو ماں ہونے پر فخر</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63609</th>\n",
       "      <td>Public</td>\n",
       "      <td>لَا تَظُنَّنَّ بِکَلِمَهٍ خَرَجَتْ مِنْ أَحَدٍ...</td>\n",
       "      <td>tgk_Arabe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text      Label\n",
       "85817   Public  وزیراعظم پیروں کی اولاد ہیں لینے پر آئیں تو در...  tgk_Arabe\n",
       "80221   Public  یہ آئین و قانون اور متاثرہ عوام کے درمیان بڑے...  tgk_Arabe\n",
       "137438  Public  لَوْ لاَ الشُّيُوخُ الرُكَّعُ وَاْلبَهائِمُ ال...  tgk_Arabe\n",
       "26667   Public    فقر اوہ جنہاں فکر ن کوئی، جیڑھے رب دے راہ وکانے  tgk_Arabe\n",
       "50294   Public  قال سلمان وإن هذا لكائن يا رسول الله؟ قال صلى ...  tgk_Arabe\n",
       "189041  Public  جی پی ایس موجود نہیں، براہِ کرم اپنے موبائل کی...  tgk_Arabe\n",
       "81019   Public  پھر اگر یہ بھی فرض کر لیا جائے کہ اس نے طاقت ک...  tgk_Arabe\n",
       "78097   Public  آج کے افسانہ نگارپرکیچڑ اچھالنے والے حقیقتِ ح...  tgk_Arabe\n",
       "32309   Public  ملک پورملک مشتاق کے گھر ایک عظیم الشان محفل من...  tgk_Arabe\n",
       "63494   Public  ۔ قیمت کا تعین بھی کرتے ہیں کیونکہ اس سے کتاب ...  tgk_Arabe\n",
       "69108   Public  نوجوانوں کی ترقی، خوشحالی اور خود مختاری حکومت...  tgk_Arabe\n",
       "45458   Public  ھون پاس پر چڑھنے کیلئے منتخب کرنے کی وجہ بیان ...  tgk_Arabe\n",
       "30973   Public  عَلَى الاِسلاَمِ السَّلامُ اِذْ قَدْ بُلِيَتِ ...  tgk_Arabe\n",
       "178389  Public  جدہکرناٹکا نان ریسڈینڈنٹ انڈین فورم جدہ کے صدر...  tgk_Arabe\n",
       "184356  Public  ہمارے علم کے مطابق ان میں سے کسی کتاب کا اردو ...  tgk_Arabe\n",
       "180827  Public                     یہ بلکل غلط تصور ہے یاد رہے کے  tgk_Arabe\n",
       "93807   Public  زمین پر وعدہ تنازعے سے متعلق معاہدے کا حصہ ہے ...  tgk_Arabe\n",
       "98255   Public  اقوام متحدہ کے سیکرٹری جنرل کی خصوصی نمائندہ پ...  tgk_Arabe\n",
       "31115   Public  ایک بڑے ہال میں لے گئے جہاں سیکڑوں لڑکے لڑکیاں...  tgk_Arabe\n",
       "96347   Public  اسلام میں جادو کے توڑ کے لیے بہت سارے حل موجود...  tgk_Arabe\n",
       "28586   Public  ۔ کارروائی دانستہ ہو ۔ ۔ انسانی حقوق کی خلاف و...  tgk_Arabe\n",
       "53192   Public             کا نام دیا گیا ہے کورونا وائرس کو کووڈ  tgk_Arabe\n",
       "135120  Public  کیٹاگری میں تازہ ترین agged ایف آئی اے، بینظیر...  tgk_Arabe\n",
       "135422  Public  چیف جسٹس نے پوچھا کہ پیمرا قانون میں ترمیم کے ...  tgk_Arabe\n",
       "30731   Public  بےنظیرکےبعد زرداری اوربلاول آگئے،بلاول کوتواُر...  tgk_Arabe\n",
       "25972   Public          lang منتخب موضوعات کو منتقل کر دیا گیا ہے  tgk_Arabe\n",
       "18544   Public  کلثوم نواز کی میت کو پی آئی اے کی پرواز پی کے ...  tgk_Arabe\n",
       "149758  Public  مذکورہ پیلی ساڑی والی عورت بگ باس میں جانا چاہ...  tgk_Arabe\n",
       "151358  Public  arz سرائیکی خط جناب حبیب امام مظلوم چر جگ حبیب...  tgk_Arabe\n",
       "163891  Public  الزكاة واجبة على الحرّ العاقل البالغ المسلم إذ...  tgk_Arabe\n",
       "186587  Public  واشنگٹن امریکی کانگریس میں پاکستان کاکس کی شری...  tgk_Arabe\n",
       "48109   Public                            ظاہر اور باطن بھی تم ہو  tgk_Arabe\n",
       "128642  Public  نئے پیدائش زیادہ سرمایہ کاری حاصل کی اور بائیو...  tgk_Arabe\n",
       "85823   Public  ایران امریکا تنازع کی صورت میں کسی کی حمایت نہ...  tgk_Arabe\n",
       "105396  Public  خاشقجی کی لاش قونصل جنرل کی رہائش گاہ کی بھٹی ...  tgk_Arabe\n",
       "70625   Public  وفاق کے زیر انتظام قبائلی علاقوں کے تعلیم یافت...  tgk_Arabe\n",
       "21107   Public  انصاف کا قتل نواز یافتہ تحقیقاتی کمیشن نے ماڈل...  tgk_Arabe\n",
       "167102  Public      الجبر والتشبيه أمويان، والعدل والتوحيد علويان  tgk_Arabe\n",
       "48915   Public               سامنے ہم جو رکھیں گر ترا کردار حسینؓ  tgk_Arabe\n",
       "147174  Public  فروغ انسانی وسائل کی وزارت نے چیلنجز کو مواقع ...  tgk_Arabe\n",
       "31700   Public  سیاحون سمیت مری شہر اور گرد و نواح کی مقامی آب...  tgk_Arabe\n",
       "41454   Public  مرموزکار، مزید ایسے ایڈوب فلیش سرور ، owza میڈ...  tgk_Arabe\n",
       "83784   Public  الریاض شاہ رخ خان نے سعودی عرب کے بارے میں کیا...  tgk_Arabe\n",
       "136691  Public  نے کہہ دیا کہ یہ معاہدہ سیکولر نظریات کیخلاف ہ...  tgk_Arabe\n",
       "60912   Public                        چه مسعود نام و چه احمد مقام  tgk_Arabe\n",
       "184860  Public                     فطرت کے مقاصد کی کرتاے نگہبانی  tgk_Arabe\n",
       "108988  Public      ۔ میں آپ کے لیے تین بہترین شعبے تجویز کروں گا  tgk_Arabe\n",
       "19726   Public  انہوں نے کہا کہ کھاد کی قیمتوں میں کمی کے لیے ...  tgk_Arabe\n",
       "97997   Public  نیو اسلام آباد ائیرپورٹ کو آفیشل نام دے دیا گی...  tgk_Arabe\n",
       "38750   Public         إن الدين يسر، ولن يشاد أحد الدين إلا غلبه…  tgk_Arabe\n",
       "43629   Public  ہم چین میں arduino مطابقت کے سپلائرز کے لئے اہ...  tgk_Arabe\n",
       "67639   Public  وقد أول الخلف الاستواء بالقهر والاستيلاء على ا...  tgk_Arabe\n",
       "51743   Public  یہ غلطیاں تہذیبی تغیر میں کثرت سے رُونما ہوئیں...  tgk_Arabe\n",
       "64751   Public  دو طرفہ ٹاک کے ساتھ او ایم جی وائی فائی بلوٹوت...  tgk_Arabe\n",
       "149119  Public  قَالَ بُرَيْدَةُ سَمِعْتُ رَسُولَ اللَّهِ صلى ...  tgk_Arabe\n",
       "66864   Public  اپنے گاہک کی بنیاد بنائیں اور رابطے میں رہیں ۔...  tgk_Arabe\n",
       "166797  Public  حجت الاسلام و المسلمین حسین انصاریان نے کہا حق...  tgk_Arabe\n",
       "163383  Public  دستاویز کی جانب سے منظور ہو گئی ہے۔ مزید کسی ک...  tgk_Arabe\n",
       "86002   Public   ان تمام ہیکر گروپس کے علاوہ آج کل ایک نئی اصطلاح  tgk_Arabe\n",
       "25170   Public  سڑکوں پر ہر طرف کالا دھواں،اور آسمان پہ چھائی ...  tgk_Arabe\n",
       "98531   Public  راس العین سے فورسز نکال لیں ، ترکی نے فائر بند...  tgk_Arabe\n",
       "39874   Public  چھوڑے بُکس بورنگ اتنے بُکس دیکھو گی سر چکڑا جا...  tgk_Arabe\n",
       "118299  Public  تو نادان مفت میں رو رہی ہے کہ جس کک باکسر کو ا...  tgk_Arabe\n",
       "81597   Public  واشنگٹن، اکتوبر ءپی آرنیوزوائر– سی جی اے پی نے...  tgk_Arabe\n",
       "94636   Public  پوسٹ کارڈز میں نریندر مودی سے کہا گیا ہے کہ ہن...  tgk_Arabe\n",
       "24881   Public  پاکستان تحرک انصاف عوامی امنگوں کی مکمل ترجمان...  tgk_Arabe\n",
       "95363   Public   جناب یحییٰ بختیار ٹھیک نہیں ہے، تیز نہیں ہوسکتا۔  tgk_Arabe\n",
       "38283   Public  وَالْأَفْضَلُ فِي الزَّكَاةِ وَالْفِطْرِ وَالن...  tgk_Arabe\n",
       "9542    Public  یو لائیو گیمز ایک کھیل اور اسپورٹس پلیٹ فارم ہ...  tgk_Arabe\n",
       "118378  Public                  کپ ملے جلے گری دار میوے دھلے ہوئے  tgk_Arabe\n",
       "20394   Public                 من ضحك أن يعيد الوضوء ويعيد الصلاة  tgk_Arabe\n",
       "103284  Public          من كان منكم مصليا بعد الجمعة فليصلّ اربعا  tgk_Arabe\n",
       "67289   Public  آزادی اور اسلام کے دو عنوانات تھے جنکے ساتھ ہم...  tgk_Arabe\n",
       "66747   Public  ان كل واحد من القوى النفسانية مهما انضم اليها ...  tgk_Arabe\n",
       "80013   Public        رائے احمد کھرل وی پنجاب دے ایس علاقے دا سی۔  tgk_Arabe\n",
       "169965  Public  ایک بات خوشآئیند ہے کہ حال میں اردو بلاگرز کے ...  tgk_Arabe\n",
       "46676   Public  ohn ccain وال سٹریٹ جرنل نے بدھ کو رپورٹ کیا ک...  tgk_Arabe\n",
       "190496  Public  اور یہ طریقہ آج ہمارے اکثر دیہات میں رائج ہیں ...  tgk_Arabe\n",
       "87391   Public  بیشک رانا بھائی کا ورک کافی اچھا جا رہا تھا می...  tgk_Arabe\n",
       "67077   Public                        یہ خود درستگی کے مارے افراد  tgk_Arabe\n",
       "54220   Public                          ٹریڈ کردہ لاٹ انعامی لاٹس  tgk_Arabe\n",
       "4015    Public  ایرانی صدر نے کہا کہ مشترکہ ایٹمی معاہدے کا مق...  tgk_Arabe\n",
       "157547  Public  ﴿أَمْ كُنْتُمْ شُهَدَاءَ إِذْ حَضَرَ يَعْقُوبَ...  tgk_Arabe\n",
       "122388  Public  جہاں بڑے بڑے تمام کھلاڑ ی ناکام ہو گئے وہاں فہ...  tgk_Arabe\n",
       "66810   Public  · مصنف نے چونکہ درایت حدیث سے متعلق مواد اپنی ...  tgk_Arabe\n",
       "154741  Public  صدر مملکت جناب آصف علی زرداری نے کراچی میں پیپ...  tgk_Arabe\n",
       "68868   Public  عَنِ السَّائِبِ بْنِ يَزِيدَ رَضِي اللهُ عَنْه...  tgk_Arabe\n",
       "7158    Public  epsi oke aseous rinks پیپسی اور کوکا کولا اور ...  tgk_Arabe\n",
       "64295   Public  parkoviště آپ کی outube ویڈیوز یا ملٹی میڈیا م...  tgk_Arabe\n",
       "150083  Public  اثر پاکستان آزاد جموں و کشمیر عوامی تحریک برائ...  tgk_Arabe\n",
       "38924   Public  صوابی تربت میں شہید ھونے والے ایف سی اہلکار نا...  tgk_Arabe\n",
       "26998   Public  عَنْ عَائِشَةَ رضي الله عنها أَنَّ فَاطِمَةَ ب...  tgk_Arabe\n",
       "116014  Public  ایران جب سے خلافت کے دائرہ کار سے آزاد ہوا تو...  tgk_Arabe\n",
       "2855    Public                               ome میرے سا تھہ آئیے  tgk_Arabe\n",
       "115061  Public  ان کے بقول وہ تین ہفتوں تک وہاں ایک نجی کلینک ...  tgk_Arabe\n",
       "145958  Public  فَاطِمَةُ بِضْعَةٌ مِنِّى فَمَنْ أَ غْضَبَهَا ...  tgk_Arabe\n",
       "26782   Public  وزارت محنت کے مطابق وہ غیر ملکی افراد جنہو ں ن...  tgk_Arabe\n",
       "169747  Public  بھائی سب سو گئے میں بور ہو رہی ہوں۔۔۔ آپ میرے ...  tgk_Arabe\n",
       "172386  Public  پٹن پنچایت صدارتی انتخابات کے لئے تنظیم نے مید...  tgk_Arabe\n",
       "29134   Public                        سنی لیون کو ماں ہونے پر فخر  tgk_Arabe\n",
       "63609   Public  لَا تَظُنَّنَّ بِکَلِمَهٍ خَرَجَتْ مِنْ أَحَدٍ...  tgk_Arabe"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set_first_version[val_set_first_version['Label'] == \"tgk_Arabe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième approche avec SentencePiece comme tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération d'un fichier brut .txt pour entraîner SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190599/190599 [00:02<00:00, 82645.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus enregistré : corpus_multilingue.txt, avec 190599 phrases.\n"
     ]
    }
   ],
   "source": [
    "# Extraire uniquement la colonne \"Text\"\n",
    "corpus_path = \"corpus_multilingue.txt\"  # Chemin de sortie pour le corpus\n",
    "data_train_preprocessed_for_corpus = data_train.copy()\n",
    "data_train_preprocessed_for_corpus = pre_processing(data_train_preprocessed_for_corpus, remove_espace=False, not_test=True, need_to_clean=True)\n",
    "data_train_preprocessed_for_corpus[\"Text\"].dropna().to_csv(corpus_path, index=False, header=False, sep=\"\\n\")\n",
    "\n",
    "print(f\"Corpus enregistré : {corpus_path}, avec {len(data_train)} phrases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement de SentencePiece et chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/corpus_multilingue.txt\n",
      "  input_format: \n",
      "  model_prefix: sp_model\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 60000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ./data/corpus_multilingue.txt\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (8498 > 4192).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 190430 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 169 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=21558433\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=8187\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 190429 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=10003839\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 1008187 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 190429\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 1076103\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 1076103 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=560095 obj=19.66 num_tokens=2546709 num_tokens/piece=4.54692\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=485356 obj=18.2809 num_tokens=2555460 num_tokens/piece=5.26512\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=363728 obj=18.3171 num_tokens=2636958 num_tokens/piece=7.24981\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=362884 obj=18.2414 num_tokens=2638242 num_tokens/piece=7.27021\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=272070 obj=18.5081 num_tokens=2770052 num_tokens/piece=10.1814\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=271995 obj=18.4138 num_tokens=2771072 num_tokens/piece=10.188\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=203981 obj=18.8175 num_tokens=2923782 num_tokens/piece=14.3336\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=203972 obj=18.6982 num_tokens=2924437 num_tokens/piece=14.3374\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=152975 obj=19.1954 num_tokens=3085317 num_tokens/piece=20.1688\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=152975 obj=19.0685 num_tokens=3085671 num_tokens/piece=20.1711\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=114731 obj=19.629 num_tokens=3249687 num_tokens/piece=28.3244\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=114731 obj=19.5028 num_tokens=3250078 num_tokens/piece=28.3278\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=86048 obj=20.1232 num_tokens=3420631 num_tokens/piece=39.7526\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=86048 obj=19.9952 num_tokens=3421278 num_tokens/piece=39.7601\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=66000 obj=20.6077 num_tokens=3581700 num_tokens/piece=54.2682\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=66000 obj=20.488 num_tokens=3582566 num_tokens/piece=54.2813\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: sp_model.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: sp_model.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input='./data/corpus_multilingue.txt',  \n",
    "    model_prefix='sp_model',\n",
    "    vocab_size=60000,  \n",
    "    character_coverage=1.0,  \n",
    "    model_type='unigram'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='sp_model.model')\n",
    "\n",
    "def sentencepiece_tokenize(text):\n",
    "    \"\"\"Tokenise un texte en sous-mots avec SentencePiece\"\"\"\n",
    "    return ' '.join(sp.encode(text, out_type=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le tokenizer sur du texte pré-traité en revanche on l'infère sur du texte brut car il est capable de le gérer directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_second_version = train_set.copy()\n",
    "val_set_second_version = val_set.copy()\n",
    "# train_set_second_version = pre_processing(train_set_second_version, remove_espace=False, not_test=True, need_to_clean=False)\n",
    "# val_set_second_version = pre_processing(val_set_second_version, remove_espace=False, not_test=True, need_to_clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152079/152079 [00:12<00:00, 12180.62it/s]\n",
      "100%|██████████| 38020/38020 [00:03<00:00, 12041.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set_second_version = add_alphabet_to_label(train_set_second_version)\n",
    "val_set_second_version = add_alphabet_to_label(val_set_second_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152079/152079 [00:07<00:00, 21034.84it/s]\n",
      "100%|██████████| 38020/38020 [00:01<00:00, 20856.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Appliquer SentencePiece \n",
    "train_set_second_version['Text'] = train_set_second_version['Text'].progress_apply(sentencepiece_tokenize)\n",
    "val_set_second_version['Text'] = val_set_second_version['Text'].progress_apply(sentencepiece_tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en place de la même pipeline que précédemment, on a juste tokenizé en amont les phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000, ngram_range=(1, 4))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.001, fit_prior=False)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char', max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                ('mnb', MultinomialNB(alpha=0.001, fit_prior=False))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer_sp = TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4), max_features=200000)\n",
    "naive_bayes_sp = MultinomialNB(alpha= 0.001, fit_prior = False) \n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer_sp),\n",
    "    ('mnb', naive_bayes_sp)\n",
    "])\n",
    "\n",
    "x_train_sp = train_set_second_version['Text'].tolist()\n",
    "y_train_sp = train_set_second_version['Label'].tolist()\n",
    "x_val_sp = val_set_second_version['Text'].tolist()\n",
    "y_val_sp = val_set_second_version['Label'].tolist()\n",
    "y_total_sp = y_train_sp + y_val_sp\n",
    "\n",
    "# converting categorical variables to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_sp = LabelEncoder()\n",
    "le_sp.fit(y_total_sp)\n",
    "\n",
    "y_train_sp = le_sp.transform(y_train_sp)\n",
    "y_val_sp = le_sp.transform(y_val_sp)\n",
    "label_mapping = dict(zip(le_sp.classes_, range(len(le_sp.classes_))))\n",
    "\n",
    "\n",
    "pipeline.fit(x_train_sp, y_train_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8505523408732246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "predictions_sp = pipeline.predict(x_val_sp)\n",
    "accuracy_sp = accuracy_score(y_val_sp, predictions_sp)\n",
    "print(\"Accuracy:\", accuracy_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des labels originaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_sp = le_sp.inverse_transform(predictions_sp)\n",
    "labels_to_predict = le_sp.inverse_transform(y_val_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def restore_original_label(label):\n",
    "    return label.split(\"_\")[0]  # Prend seulement la première partie avant '_'\n",
    "\n",
    "def restore_labels(liste):\n",
    "    new_liste = []\n",
    "    for element in tqdm(liste): \n",
    "        new_liste.append(restore_original_label(element))\n",
    "    return np.array(new_liste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38020/38020 [00:00<00:00, 1045749.83it/s]\n",
      "100%|██████████| 38020/38020 [00:00<00:00, 1511482.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8524723829563388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_prediction = restore_labels(predicted_labels_sp)\n",
    "val_to_predict = restore_labels(labels_to_predict)\n",
    "final_accuracy = accuracy_score(val_to_predict, final_prediction)\n",
    "print(\"Accuracy:\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_classes_sp = np.unique(np.concatenate((y_val_sp, predictions_sp)))\n",
    "\n",
    "# Extraire uniquement les noms correspondants\n",
    "filtered_target_names_sp = [le_sp.classes_[i] for i in present_classes_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (trié par F1-score décroissant):\n",
      "\n",
      "abk_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 116.0\n",
      "ach_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 22.0\n",
      "ada_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 1.0\n",
      "ahk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 89.0\n",
      "alt_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "aoj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "arn_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "asm_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 99.0\n",
      "bpy_Bengali: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "bzj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 104.0\n",
      "cab_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 83.0\n",
      "cak_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 103.0\n",
      "chk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "cjk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "csy_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 120.0\n",
      "ctu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "cuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "div_THAANA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "djk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 87.0\n",
      "guc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "hbo_Hébreu: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 4.0\n",
      "hnj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 5.0\n",
      "hui_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 85.0\n",
      "hus_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "ikk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 92.0\n",
      "iku_CANADIAN: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "ixl_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "kac_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 107.0\n",
      "kal_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "kan_KANNADA: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 92.0\n",
      "kjb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "kjh_Cyrillique: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 100.0\n",
      "kmb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 91.0\n",
      "knv_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "kor_Hangul (Coréen): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "ksw_MYANMAR: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 3.0\n",
      "lhu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 39.0\n",
      "luo_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 107.0\n",
      "mah_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 4.0\n",
      "mal_MALAYALAM: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "mam_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 109.0\n",
      "mau_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 104.0\n",
      "mco_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 108.0\n",
      "mgh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "mos_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 92.0\n",
      "mps_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 89.0\n",
      "mzh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 99.0\n",
      "naq_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 111.0\n",
      "nav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 93.0\n",
      "nch_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "ncj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "ngu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "nnb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 108.0\n",
      "nyu_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 90.0\n",
      "ote_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 91.0\n",
      "pan_GURMUKHI: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 119.0\n",
      "poh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "pon_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "qub_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 6.0\n",
      "qvi_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 113.0\n",
      "rop_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 86.0\n",
      "seh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "srm_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 98.0\n",
      "suz_Devanagari (Hindi, Sanskrit): F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 116.0\n",
      "tbz_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "tca_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 91.0\n",
      "tdt_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 77.0\n",
      "tlh_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "toj_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 107.0\n",
      "tok_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 111.0\n",
      "top_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 95.0\n",
      "tuc_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 115.0\n",
      "tuk_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 117.0\n",
      "tzo_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 97.0\n",
      "uig_Arabe: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "umb_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 101.0\n",
      "xav_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 108.0\n",
      "yao_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 96.0\n",
      "yap_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 94.0\n",
      "yom_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 106.0\n",
      "zai_Latin: F1-score = 1.0000, Precision = 1.0000, Recall = 1.0000, Support = 111.0\n",
      "wal_Latin: F1-score = 0.9956, Precision = 0.9912, Recall = 1.0000, Support = 112.0\n",
      "guj_GUJARATI: F1-score = 0.9955, Precision = 1.0000, Recall = 0.9910, Support = 111.0\n",
      "kir_Cyrillique: F1-score = 0.9954, Precision = 0.9909, Recall = 1.0000, Support = 109.0\n",
      "ksd_Latin: F1-score = 0.9954, Precision = 0.9909, Recall = 1.0000, Support = 109.0\n",
      "kbp_Latin: F1-score = 0.9954, Precision = 0.9908, Recall = 1.0000, Support = 108.0\n",
      "kpg_Latin: F1-score = 0.9953, Precision = 1.0000, Recall = 0.9907, Support = 107.0\n",
      "kos_Latin: F1-score = 0.9953, Precision = 1.0000, Recall = 0.9906, Support = 106.0\n",
      "sgs_Latin: F1-score = 0.9952, Precision = 1.0000, Recall = 0.9904, Support = 104.0\n",
      "lvs_Latin: F1-score = 0.9951, Precision = 0.9903, Recall = 1.0000, Support = 102.0\n",
      "tam_Tamoul: F1-score = 0.9951, Precision = 0.9903, Recall = 1.0000, Support = 102.0\n",
      "quw_Latin: F1-score = 0.9950, Precision = 1.0000, Recall = 0.9901, Support = 101.0\n",
      "lua_Latin: F1-score = 0.9949, Precision = 0.9898, Recall = 1.0000, Support = 97.0\n",
      "bqc_Latin: F1-score = 0.9948, Precision = 0.9896, Recall = 1.0000, Support = 95.0\n",
      "rug_Latin: F1-score = 0.9948, Precision = 0.9896, Recall = 1.0000, Support = 95.0\n",
      "ewe_Latin: F1-score = 0.9947, Precision = 1.0000, Recall = 0.9895, Support = 95.0\n",
      "gom_Devanagari (Hindi, Sanskrit): F1-score = 0.9947, Precision = 0.9895, Recall = 1.0000, Support = 94.0\n",
      "kek_Latin: F1-score = 0.9947, Precision = 1.0000, Recall = 0.9894, Support = 94.0\n",
      "sat_OL: F1-score = 0.9947, Precision = 0.9894, Recall = 1.0000, Support = 93.0\n",
      "gym_Latin: F1-score = 0.9945, Precision = 1.0000, Recall = 0.9891, Support = 92.0\n",
      "sin_SINHALA: F1-score = 0.9944, Precision = 0.9888, Recall = 1.0000, Support = 88.0\n",
      "bem_Latin: F1-score = 0.9942, Precision = 1.0000, Recall = 0.9884, Support = 86.0\n",
      "pls_Latin: F1-score = 0.9937, Precision = 1.0000, Recall = 0.9875, Support = 80.0\n",
      "sag_Latin: F1-score = 0.9907, Precision = 0.9907, Recall = 0.9907, Support = 108.0\n",
      "kbd_Cyrillique: F1-score = 0.9905, Precision = 1.0000, Recall = 0.9811, Support = 106.0\n",
      "sah_Cyrillique: F1-score = 0.9905, Precision = 1.0000, Recall = 0.9811, Support = 106.0\n",
      "ndo_Latin: F1-score = 0.9903, Precision = 0.9903, Recall = 0.9903, Support = 103.0\n",
      "orm_Latin: F1-score = 0.9902, Precision = 0.9806, Recall = 1.0000, Support = 101.0\n",
      "che_Cyrillique: F1-score = 0.9899, Precision = 1.0000, Recall = 0.9800, Support = 100.0\n",
      "mon_Cyrillique: F1-score = 0.9898, Precision = 0.9798, Recall = 1.0000, Support = 97.0\n",
      "snd_Arabe: F1-score = 0.9898, Precision = 0.9898, Recall = 0.9898, Support = 98.0\n",
      "vol_Latin: F1-score = 0.9896, Precision = 1.0000, Recall = 0.9794, Support = 97.0\n",
      "tha_Thaï: F1-score = 0.9895, Precision = 0.9792, Recall = 1.0000, Support = 94.0\n",
      "mya_MYANMAR: F1-score = 0.9894, Precision = 0.9789, Recall = 1.0000, Support = 93.0\n",
      "fon_Latin: F1-score = 0.9892, Precision = 1.0000, Recall = 0.9787, Support = 94.0\n",
      "hun_Latin: F1-score = 0.9891, Precision = 0.9785, Recall = 1.0000, Support = 91.0\n",
      "yid_Hébreu: F1-score = 0.9891, Precision = 0.9891, Recall = 0.9891, Support = 92.0\n",
      "kam_Latin: F1-score = 0.9884, Precision = 1.0000, Recall = 0.9770, Support = 87.0\n",
      "srn_Latin: F1-score = 0.9882, Precision = 1.0000, Recall = 0.9767, Support = 86.0\n",
      "heb_Hébreu: F1-score = 0.9877, Precision = 0.9877, Recall = 0.9877, Support = 81.0\n",
      "krc_Cyrillique: F1-score = 0.9871, Precision = 1.0000, Recall = 0.9746, Support = 118.0\n",
      "meu_Latin: F1-score = 0.9867, Precision = 0.9911, Recall = 0.9823, Support = 113.0\n",
      "vie_Latin: F1-score = 0.9867, Precision = 0.9867, Recall = 0.9867, Support = 75.0\n",
      "tso_Latin: F1-score = 0.9864, Precision = 0.9820, Recall = 0.9909, Support = 110.0\n",
      "xmf_Géorgien: F1-score = 0.9855, Precision = 0.9903, Recall = 0.9808, Support = 104.0\n",
      "jbo_Latin: F1-score = 0.9849, Precision = 1.0000, Recall = 0.9703, Support = 101.0\n",
      "dtp_Latin: F1-score = 0.9845, Precision = 0.9794, Recall = 0.9896, Support = 96.0\n",
      "kik_Latin: F1-score = 0.9843, Precision = 1.0000, Recall = 0.9691, Support = 97.0\n",
      "gom_Latin: F1-score = 0.9841, Precision = 0.9894, Recall = 0.9789, Support = 95.0\n",
      "lus_Latin: F1-score = 0.9841, Precision = 0.9894, Recall = 0.9789, Support = 95.0\n",
      "eus_Latin: F1-score = 0.9836, Precision = 1.0000, Recall = 0.9677, Support = 93.0\n",
      "pap_Latin: F1-score = 0.9832, Precision = 0.9915, Recall = 0.9750, Support = 120.0\n",
      "lit_Latin: F1-score = 0.9820, Precision = 0.9732, Recall = 0.9909, Support = 110.0\n",
      "gug_Latin: F1-score = 0.9817, Precision = 0.9727, Recall = 0.9907, Support = 108.0\n",
      "kaz_Cyrillique: F1-score = 0.9798, Precision = 1.0000, Recall = 0.9604, Support = 101.0\n",
      "hmo_Latin: F1-score = 0.9767, Precision = 0.9655, Recall = 0.9882, Support = 85.0\n",
      "quh_Latin: F1-score = 0.9767, Precision = 0.9545, Recall = 1.0000, Support = 84.0\n",
      "roh_Latin: F1-score = 0.9763, Precision = 0.9904, Recall = 0.9626, Support = 107.0\n",
      "fij_Latin: F1-score = 0.9758, Precision = 0.9619, Recall = 0.9902, Support = 102.0\n",
      "khm_KHMER: F1-score = 0.9747, Precision = 0.9506, Recall = 1.0000, Support = 77.0\n",
      "fin_Latin: F1-score = 0.9741, Precision = 0.9691, Recall = 0.9792, Support = 96.0\n",
      "isl_Latin: F1-score = 0.9741, Precision = 0.9592, Recall = 0.9895, Support = 95.0\n",
      "szl_Latin: F1-score = 0.9735, Precision = 0.9787, Recall = 0.9684, Support = 95.0\n",
      "oss_Cyrillique: F1-score = 0.9724, Precision = 1.0000, Recall = 0.9462, Support = 93.0\n",
      "sme_Latin: F1-score = 0.9703, Precision = 1.0000, Recall = 0.9423, Support = 104.0\n",
      "epo_Latin: F1-score = 0.9701, Precision = 1.0000, Recall = 0.9419, Support = 86.0\n",
      "new_Devanagari (Hindi, Sanskrit): F1-score = 0.9686, Precision = 1.0000, Recall = 0.9391, Support = 115.0\n",
      "grc_Grec: F1-score = 0.9681, Precision = 1.0000, Recall = 0.9381, Support = 97.0\n",
      "azb_Arabe: F1-score = 0.9671, Precision = 0.9537, Recall = 0.9810, Support = 105.0\n",
      "ell_Grec: F1-score = 0.9671, Precision = 0.9364, Recall = 1.0000, Support = 103.0\n",
      "fao_Latin: F1-score = 0.9671, Precision = 0.9904, Recall = 0.9450, Support = 109.0\n",
      "tpi_Latin: F1-score = 0.9670, Precision = 0.9888, Recall = 0.9462, Support = 93.0\n",
      "crh_Latin: F1-score = 0.9662, Precision = 0.9804, Recall = 0.9524, Support = 105.0\n",
      "fur_Latin: F1-score = 0.9662, Precision = 0.9901, Recall = 0.9434, Support = 106.0\n",
      "gcf_Latin: F1-score = 0.9655, Precision = 1.0000, Recall = 0.9333, Support = 30.0\n",
      "kat_Géorgien: F1-score = 0.9652, Precision = 0.9510, Recall = 0.9798, Support = 99.0\n",
      "glv_Latin: F1-score = 0.9645, Precision = 0.9596, Recall = 0.9694, Support = 98.0\n",
      "tir_Éthiopien: F1-score = 0.9645, Precision = 0.9406, Recall = 0.9896, Support = 96.0\n",
      "kom_Cyrillique: F1-score = 0.9637, Precision = 1.0000, Recall = 0.9300, Support = 100.0\n",
      "mar_Devanagari (Hindi, Sanskrit): F1-score = 0.9634, Precision = 0.9583, Recall = 0.9684, Support = 95.0\n",
      "vep_Latin: F1-score = 0.9634, Precision = 0.9787, Recall = 0.9485, Support = 97.0\n",
      "pms_Latin: F1-score = 0.9613, Precision = 1.0000, Recall = 0.9255, Support = 94.0\n",
      "lug_Latin: F1-score = 0.9612, Precision = 0.9706, Recall = 0.9519, Support = 104.0\n",
      "amh_Éthiopien: F1-score = 0.9605, Precision = 0.9884, Recall = 0.9341, Support = 91.0\n",
      "acr_Latin: F1-score = 0.9592, Precision = 0.9792, Recall = 0.9400, Support = 100.0\n",
      "aln_Latin: F1-score = 0.9589, Precision = 0.9211, Recall = 1.0000, Support = 105.0\n",
      "quc_Latin: F1-score = 0.9589, Precision = 0.9375, Recall = 0.9813, Support = 107.0\n",
      "cym_Latin: F1-score = 0.9579, Precision = 0.9681, Recall = 0.9479, Support = 96.0\n",
      "ace_Latin: F1-score = 0.9573, Precision = 0.9806, Recall = 0.9352, Support = 108.0\n",
      "csb_Latin: F1-score = 0.9565, Precision = 0.9747, Recall = 0.9390, Support = 82.0\n",
      "udm_Cyrillique: F1-score = 0.9557, Precision = 0.9604, Recall = 0.9510, Support = 102.0\n",
      "frr_Latin: F1-score = 0.9548, Precision = 0.9794, Recall = 0.9314, Support = 102.0\n",
      "hye_Arménien: F1-score = 0.9545, Precision = 0.9130, Recall = 1.0000, Support = 84.0\n",
      "mhr_Cyrillique: F1-score = 0.9543, Precision = 0.9592, Recall = 0.9495, Support = 99.0\n",
      "grn_Latin: F1-score = 0.9524, Precision = 0.9804, Recall = 0.9259, Support = 108.0\n",
      "ssw_Latin: F1-score = 0.9524, Precision = 0.9804, Recall = 0.9259, Support = 108.0\n",
      "kea_Latin: F1-score = 0.9519, Precision = 0.9570, Recall = 0.9468, Support = 94.0\n",
      "ces_Latin: F1-score = 0.9510, Precision = 0.9510, Recall = 0.9510, Support = 102.0\n",
      "kaa_Latin: F1-score = 0.9493, Precision = 0.9904, Recall = 0.9115, Support = 113.0\n",
      "swe_Latin: F1-score = 0.9478, Precision = 0.9478, Recall = 0.9478, Support = 115.0\n",
      "bul_Cyrillique: F1-score = 0.9474, Precision = 0.9474, Recall = 0.9474, Support = 95.0\n",
      "kon_Latin: F1-score = 0.9468, Precision = 0.9674, Recall = 0.9271, Support = 96.0\n",
      "tum_Latin: F1-score = 0.9457, Precision = 0.9667, Recall = 0.9255, Support = 94.0\n",
      "eml_Latin: F1-score = 0.9450, Precision = 0.9626, Recall = 0.9279, Support = 111.0\n",
      "afr_Latin: F1-score = 0.9444, Precision = 0.9533, Recall = 0.9358, Support = 109.0\n",
      "npi_Devanagari (Hindi, Sanskrit): F1-score = 0.9444, Precision = 0.9808, Recall = 0.9107, Support = 112.0\n",
      "lin_Latin: F1-score = 0.9418, Precision = 0.9889, Recall = 0.8990, Support = 99.0\n",
      "hsb_Latin: F1-score = 0.9412, Precision = 0.9697, Recall = 0.9143, Support = 105.0\n",
      "gle_Latin: F1-score = 0.9400, Precision = 0.9038, Recall = 0.9792, Support = 96.0\n",
      "tyv_Cyrillique: F1-score = 0.9391, Precision = 0.9818, Recall = 0.9000, Support = 120.0\n",
      "chv_Cyrillique: F1-score = 0.9385, Precision = 1.0000, Recall = 0.8842, Support = 95.0\n",
      "mkd_Cyrillique: F1-score = 0.9381, Precision = 0.9579, Recall = 0.9192, Support = 99.0\n",
      "tur_Latin: F1-score = 0.9381, Precision = 0.9286, Recall = 0.9479, Support = 96.0\n",
      "mwl_Latin: F1-score = 0.9366, Precision = 0.9412, Recall = 0.9320, Support = 103.0\n",
      "slv_Latin: F1-score = 0.9364, Precision = 0.9759, Recall = 0.9000, Support = 90.0\n",
      "pus_Arabe: F1-score = 0.9353, Precision = 0.9691, Recall = 0.9038, Support = 104.0\n",
      "jam_Latin: F1-score = 0.9346, Precision = 0.9804, Recall = 0.8929, Support = 112.0\n",
      "crh_Cyrillique: F1-score = 0.9333, Precision = 1.0000, Recall = 0.8750, Support = 96.0\n",
      "gla_Latin: F1-score = 0.9333, Precision = 0.9891, Recall = 0.8835, Support = 103.0\n",
      "diq_Latin: F1-score = 0.9326, Precision = 0.9881, Recall = 0.8830, Support = 94.0\n",
      "ksh_Latin: F1-score = 0.9321, Precision = 0.9364, Recall = 0.9279, Support = 111.0\n",
      "arz_Arabe: F1-score = 0.9310, Precision = 0.9730, Recall = 0.8926, Support = 121.0\n",
      "slk_Latin: F1-score = 0.9307, Precision = 0.9307, Recall = 0.9307, Support = 101.0\n",
      "pol_Latin: F1-score = 0.9305, Precision = 0.8700, Recall = 1.0000, Support = 87.0\n",
      "mzn_Arabe: F1-score = 0.9290, Precision = 0.9551, Recall = 0.9043, Support = 94.0\n",
      "ilo_Latin: F1-score = 0.9286, Precision = 0.9630, Recall = 0.8966, Support = 116.0\n",
      "lao_LAO: F1-score = 0.9286, Precision = 0.8750, Recall = 0.9891, Support = 92.0\n",
      "ukr_Cyrillique: F1-score = 0.9271, Precision = 0.9271, Recall = 0.9271, Support = 96.0\n",
      "bis_Latin: F1-score = 0.9251, Precision = 0.9545, Recall = 0.8974, Support = 117.0\n",
      "mai_Devanagari (Hindi, Sanskrit): F1-score = 0.9224, Precision = 0.9386, Recall = 0.9068, Support = 118.0\n",
      "lfn_Latin: F1-score = 0.9222, Precision = 0.9540, Recall = 0.8925, Support = 93.0\n",
      "ven_Latin: F1-score = 0.9222, Precision = 1.0000, Recall = 0.8557, Support = 97.0\n",
      "san_Devanagari (Hindi, Sanskrit): F1-score = 0.9202, Precision = 0.8522, Recall = 1.0000, Support = 98.0\n",
      "dyu_Latin: F1-score = 0.9200, Precision = 0.8762, Recall = 0.9684, Support = 95.0\n",
      "pis_Latin: F1-score = 0.9189, Precision = 0.8500, Recall = 1.0000, Support = 34.0\n",
      "ful_Latin: F1-score = 0.9158, Precision = 0.9775, Recall = 0.8614, Support = 101.0\n",
      "yor_Latin: F1-score = 0.9128, Precision = 0.9780, Recall = 0.8558, Support = 104.0\n",
      "bre_Latin: F1-score = 0.9126, Precision = 0.9400, Recall = 0.8868, Support = 106.0\n",
      "ceb_Latin: F1-score = 0.9123, Precision = 0.9512, Recall = 0.8764, Support = 89.0\n",
      "bih_Devanagari (Hindi, Sanskrit): F1-score = 0.9102, Precision = 0.8941, Recall = 0.9268, Support = 82.0\n",
      "quy_Latin: F1-score = 0.9101, Precision = 0.8431, Recall = 0.9885, Support = 87.0\n",
      "ibo_Latin: F1-score = 0.9070, Precision = 1.0000, Recall = 0.8298, Support = 94.0\n",
      "rap_Latin: F1-score = 0.9067, Precision = 1.0000, Recall = 0.8293, Support = 41.0\n",
      "cat_Latin: F1-score = 0.9064, Precision = 0.9020, Recall = 0.9109, Support = 101.0\n",
      "ido_Latin: F1-score = 0.9062, Precision = 0.8969, Recall = 0.9158, Support = 95.0\n",
      "pnb_Arabe: F1-score = 0.9058, Precision = 0.8860, Recall = 0.9266, Support = 109.0\n",
      "tah_Latin: F1-score = 0.9055, Precision = 0.9785, Recall = 0.8426, Support = 108.0\n",
      "hne_Devanagari (Hindi, Sanskrit): F1-score = 0.9053, Precision = 0.9149, Recall = 0.8958, Support = 96.0\n",
      "por_Latin: F1-score = 0.9043, Precision = 0.9341, Recall = 0.8763, Support = 97.0\n",
      "rmy_Latin: F1-score = 0.9026, Precision = 0.9362, Recall = 0.8713, Support = 101.0\n",
      "kaa_Cyrillique: F1-score = 0.8995, Precision = 0.9884, Recall = 0.8252, Support = 103.0\n",
      "min_Latin: F1-score = 0.8966, Precision = 0.9070, Recall = 0.8864, Support = 88.0\n",
      "lat_Latin: F1-score = 0.8934, Precision = 0.8889, Recall = 0.8980, Support = 98.0\n",
      "fry_Latin: F1-score = 0.8930, Precision = 0.9505, Recall = 0.8421, Support = 114.0\n",
      "lij_Latin: F1-score = 0.8889, Precision = 0.8800, Recall = 0.8980, Support = 98.0\n",
      "bam_Latin: F1-score = 0.8877, Precision = 0.9432, Recall = 0.8384, Support = 99.0\n",
      "pag_Latin: F1-score = 0.8866, Precision = 0.9773, Recall = 0.8113, Support = 106.0\n",
      "ile_Latin: F1-score = 0.8857, Precision = 0.9300, Recall = 0.8455, Support = 110.0\n",
      "jpn_Katakana (Japonais): F1-score = 0.8846, Precision = 0.8214, Recall = 0.9583, Support = 24.0\n",
      "ron_Latin: F1-score = 0.8844, Precision = 0.8462, Recall = 0.9263, Support = 95.0\n",
      "ext_Latin: F1-score = 0.8785, Precision = 0.8952, Recall = 0.8624, Support = 109.0\n",
      "myv_Cyrillique: F1-score = 0.8772, Precision = 0.8333, Recall = 0.9259, Support = 108.0\n",
      "tls_Latin: F1-score = 0.8772, Precision = 0.9868, Recall = 0.7895, Support = 95.0\n",
      "ton_Latin: F1-score = 0.8764, Precision = 0.9070, Recall = 0.8478, Support = 92.0\n",
      "dzo_TIBETAN: F1-score = 0.8756, Precision = 0.8889, Recall = 0.8627, Support = 102.0\n",
      "mon_Latin: F1-score = 0.8750, Precision = 0.9625, Recall = 0.8021, Support = 96.0\n",
      "vls_Latin: F1-score = 0.8738, Precision = 0.8571, Recall = 0.8911, Support = 101.0\n",
      "bod_TIBETAN: F1-score = 0.8731, Precision = 0.8269, Recall = 0.9247, Support = 93.0\n",
      "tat_Cyrillique: F1-score = 0.8718, Precision = 0.7846, Recall = 0.9808, Support = 104.0\n",
      "ayr_Latin: F1-score = 0.8711, Precision = 0.7967, Recall = 0.9608, Support = 102.0\n",
      "nep_Devanagari (Hindi, Sanskrit): F1-score = 0.8710, Precision = 0.8265, Recall = 0.9205, Support = 88.0\n",
      "deu_Latin: F1-score = 0.8704, Precision = 0.8319, Recall = 0.9126, Support = 103.0\n",
      "lzh_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8692, Precision = 0.8230, Recall = 0.9208, Support = 101.0\n",
      "lim_Latin: F1-score = 0.8673, Precision = 0.8586, Recall = 0.8763, Support = 97.0\n",
      "dan_Latin: F1-score = 0.8663, Precision = 0.9205, Recall = 0.8182, Support = 99.0\n",
      "som_Latin: F1-score = 0.8649, Precision = 0.9756, Recall = 0.7767, Support = 103.0\n",
      "arg_Latin: F1-score = 0.8634, Precision = 0.8167, Recall = 0.9159, Support = 107.0\n",
      "hmn_Latin: F1-score = 0.8627, Precision = 0.9888, Recall = 0.7652, Support = 115.0\n",
      "pfl_Latin: F1-score = 0.8588, Precision = 0.8085, Recall = 0.9157, Support = 83.0\n",
      "lue_Latin: F1-score = 0.8571, Precision = 1.0000, Recall = 0.7500, Support = 4.0\n",
      "nld_Latin: F1-score = 0.8532, Precision = 0.8304, Recall = 0.8774, Support = 106.0\n",
      "yue_Kanji (Chinois, Japonais, Coréen): F1-score = 0.8525, Precision = 0.8254, Recall = 0.8814, Support = 118.0\n",
      "nap_Latin: F1-score = 0.8520, Precision = 0.8716, Recall = 0.8333, Support = 114.0\n",
      "weighted avg: F1-score = 0.8518, Precision = 0.8643, Recall = 0.8506, Support = 38020.0\n",
      "mlt_Latin: F1-score = 0.8515, Precision = 0.8350, Recall = 0.8687, Support = 99.0\n",
      "pcd_Latin: F1-score = 0.8505, Precision = 0.8198, Recall = 0.8835, Support = 103.0\n",
      "lmo_Latin: F1-score = 0.8488, Precision = 0.8588, Recall = 0.8391, Support = 87.0\n",
      "zlm_Latin: F1-score = 0.8480, Precision = 0.8154, Recall = 0.8833, Support = 120.0\n",
      "rue_Cyrillique: F1-score = 0.8404, Precision = 0.7383, Recall = 0.9753, Support = 81.0\n",
      "hau_Latin: F1-score = 0.8374, Precision = 0.8095, Recall = 0.8673, Support = 98.0\n",
      "wol_Latin: F1-score = 0.8364, Precision = 0.9452, Recall = 0.7500, Support = 92.0\n",
      "nds_Latin: F1-score = 0.8357, Precision = 0.8318, Recall = 0.8396, Support = 106.0\n",
      "fra_Latin: F1-score = 0.8325, Precision = 0.7810, Recall = 0.8913, Support = 92.0\n",
      "uzb_Latin: F1-score = 0.8319, Precision = 0.7734, Recall = 0.9000, Support = 110.0\n",
      "gsw_Latin: F1-score = 0.8295, Precision = 0.8202, Recall = 0.8391, Support = 87.0\n",
      "nno_Latin: F1-score = 0.8283, Precision = 0.7387, Recall = 0.9425, Support = 87.0\n",
      "pcm_Latin: F1-score = 0.8264, Precision = 0.7692, Recall = 0.8929, Support = 112.0\n",
      "gor_Latin: F1-score = 0.8254, Precision = 0.8667, Recall = 0.7879, Support = 99.0\n",
      "bsb_Latin: F1-score = 0.8252, Precision = 0.8416, Recall = 0.8095, Support = 105.0\n",
      "zea_Latin: F1-score = 0.8235, Precision = 0.8642, Recall = 0.7865, Support = 89.0\n",
      "bak_Cyrillique: F1-score = 0.8218, Precision = 0.9651, Recall = 0.7155, Support = 116.0\n",
      "swc_Latin: F1-score = 0.8195, Precision = 0.8936, Recall = 0.7568, Support = 111.0\n",
      "hil_Latin: F1-score = 0.8148, Precision = 1.0000, Recall = 0.6875, Support = 16.0\n",
      "nso_Latin: F1-score = 0.8144, Precision = 0.7980, Recall = 0.8316, Support = 95.0\n",
      "hif_Latin: F1-score = 0.8122, Precision = 0.7619, Recall = 0.8696, Support = 92.0\n",
      "macro avg: F1-score = 0.8074, Precision = 0.8251, Recall = 0.8046, Support = 38020.0\n",
      "smo_Latin: F1-score = 0.8023, Precision = 0.9324, Recall = 0.7041, Support = 98.0\n",
      "uig_Latin: F1-score = 0.8023, Precision = 0.9103, Recall = 0.7172, Support = 99.0\n",
      "kur_Latin: F1-score = 0.7965, Precision = 0.7188, Recall = 0.8932, Support = 103.0\n",
      "plt_Latin: F1-score = 0.7964, Precision = 0.9670, Recall = 0.6769, Support = 130.0\n",
      "jpn_Hiragana (Japonais): F1-score = 0.7857, Precision = 0.6875, Recall = 0.9167, Support = 36.0\n",
      "kat_Latin: F1-score = 0.7826, Precision = 0.8351, Recall = 0.7364, Support = 110.0\n",
      "wuu_Kanji (Chinois, Japonais, Coréen): F1-score = 0.7815, Precision = 0.7623, Recall = 0.8017, Support = 116.0\n",
      "scn_Latin: F1-score = 0.7803, Precision = 0.7909, Recall = 0.7699, Support = 113.0\n",
      "haw_Latin: F1-score = 0.7750, Precision = 0.8986, Recall = 0.6813, Support = 91.0\n",
      "bar_Latin: F1-score = 0.7725, Precision = 0.6870, Recall = 0.8824, Support = 102.0\n",
      "oci_Latin: F1-score = 0.7674, Precision = 0.8250, Recall = 0.7174, Support = 92.0\n",
      "ber_Latin: F1-score = 0.7614, Precision = 0.8242, Recall = 0.7075, Support = 106.0\n",
      "glg_Latin: F1-score = 0.7609, Precision = 0.7609, Recall = 0.7609, Support = 92.0\n",
      "hat_Latin: F1-score = 0.7604, Precision = 0.8202, Recall = 0.7087, Support = 103.0\n",
      "kmr_Latin: F1-score = 0.7590, Precision = 0.8873, Recall = 0.6632, Support = 95.0\n",
      "aka_Latin: F1-score = 0.7553, Precision = 0.8068, Recall = 0.7100, Support = 100.0\n",
      "ekk_Latin: F1-score = 0.7500, Precision = 0.7642, Recall = 0.7364, Support = 110.0\n",
      "cbk_Latin: F1-score = 0.7439, Precision = 0.8472, Recall = 0.6630, Support = 92.0\n",
      "hbs_Cyrillique: F1-score = 0.7438, Precision = 0.6429, Recall = 0.8824, Support = 102.0\n",
      "kab_Latin: F1-score = 0.7423, Precision = 0.6792, Recall = 0.8182, Support = 88.0\n",
      "prs_Arabe: F1-score = 0.7395, Precision = 0.6154, Recall = 0.9263, Support = 95.0\n",
      "srd_Latin: F1-score = 0.7340, Precision = 0.8846, Recall = 0.6273, Support = 110.0\n",
      "tsn_Latin: F1-score = 0.7292, Precision = 0.7527, Recall = 0.7071, Support = 99.0\n",
      "mri_Latin: F1-score = 0.7283, Precision = 0.8171, Recall = 0.6569, Support = 102.0\n",
      "cmn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.7273, Precision = 0.7273, Recall = 0.7273, Support = 88.0\n",
      "twi_Latin: F1-score = 0.7264, Precision = 0.7157, Recall = 0.7374, Support = 99.0\n",
      "ina_Latin: F1-score = 0.7256, Precision = 0.6610, Recall = 0.8041, Support = 97.0\n",
      "bjn_Latin: F1-score = 0.7240, Precision = 0.7477, Recall = 0.7018, Support = 114.0\n",
      "jpn_Kanji (Chinois, Japonais, Coréen): F1-score = 0.7213, Precision = 0.9167, Recall = 0.5946, Support = 37.0\n",
      "arb_Arabe: F1-score = 0.7170, Precision = 0.6463, Recall = 0.8051, Support = 118.0\n",
      "ori_ORIYA: F1-score = 0.7136, Precision = 0.7172, Recall = 0.7100, Support = 100.0\n",
      "est_Latin: F1-score = 0.7094, Precision = 0.6990, Recall = 0.7200, Support = 100.0\n",
      "hrx_Latin: F1-score = 0.7083, Precision = 1.0000, Recall = 0.5484, Support = 31.0\n",
      "jav_Latin: F1-score = 0.7071, Precision = 0.7778, Recall = 0.6481, Support = 108.0\n",
      "que_Latin: F1-score = 0.7027, Precision = 0.9455, Recall = 0.5591, Support = 93.0\n",
      "ory_ORIYA: F1-score = 0.6889, Precision = 0.6813, Recall = 0.6966, Support = 89.0\n",
      "bew_Cyrillique: F1-score = 0.6885, Precision = 0.7590, Recall = 0.6300, Support = 100.0\n",
      "ckb_Arabe: F1-score = 0.6850, Precision = 0.5724, Recall = 0.8529, Support = 102.0\n",
      "ast_Latin: F1-score = 0.6831, Precision = 0.5804, Recall = 0.8300, Support = 100.0\n",
      "nbl_Latin: F1-score = 0.6812, Precision = 0.5954, Recall = 0.7959, Support = 98.0\n",
      "bel_Cyrillique: F1-score = 0.6772, Precision = 0.6337, Recall = 0.7273, Support = 88.0\n",
      "hin_Devanagari (Hindi, Sanskrit): F1-score = 0.6734, Precision = 0.6700, Recall = 0.6768, Support = 99.0\n",
      "mlg_Latin: F1-score = 0.6723, Precision = 0.6202, Recall = 0.7339, Support = 109.0\n",
      "aym_Latin: F1-score = 0.6712, Precision = 0.9245, Recall = 0.5269, Support = 93.0\n",
      "nya_Latin: F1-score = 0.6704, Precision = 0.7500, Recall = 0.6061, Support = 99.0\n",
      "iba_Latin: F1-score = 0.6667, Precision = 1.0000, Recall = 0.5000, Support = 2.0\n",
      "run_Latin: F1-score = 0.6609, Precision = 0.5758, Recall = 0.7755, Support = 98.0\n",
      "bak_Latin: F1-score = 0.6557, Precision = 0.6522, Recall = 0.6593, Support = 91.0\n",
      "tgl_Latin: F1-score = 0.6533, Precision = 0.6842, Recall = 0.6250, Support = 104.0\n",
      "ita_Latin: F1-score = 0.6502, Precision = 0.6000, Recall = 0.7097, Support = 93.0\n",
      "glk_Arabe: F1-score = 0.6471, Precision = 0.6286, Recall = 0.6667, Support = 99.0\n",
      "spa_Latin: F1-score = 0.6442, Precision = 0.6262, Recall = 0.6634, Support = 101.0\n",
      "swa_Latin: F1-score = 0.6429, Precision = 0.6545, Recall = 0.6316, Support = 114.0\n",
      "xho_Latin: F1-score = 0.6424, Precision = 0.8413, Recall = 0.5196, Support = 102.0\n",
      "aze_Arabe: F1-score = 0.6411, Precision = 0.6442, Recall = 0.6381, Support = 105.0\n",
      "sqi_Latin: F1-score = 0.6385, Precision = 0.5862, Recall = 0.7010, Support = 97.0\n",
      "swh_Latin: F1-score = 0.6335, Precision = 0.5882, Recall = 0.6863, Support = 102.0\n",
      "zho_Kanji (Chinois, Japonais, Coréen): F1-score = 0.6304, Precision = 0.7342, Recall = 0.5524, Support = 105.0\n",
      "war_Latin: F1-score = 0.6243, Precision = 0.6556, Recall = 0.5960, Support = 99.0\n",
      "san_Latin: F1-score = 0.6207, Precision = 0.6429, Recall = 0.6000, Support = 15.0\n",
      "srp_Latin: F1-score = 0.6114, Precision = 0.6556, Recall = 0.5728, Support = 103.0\n",
      "urd_Arabe: F1-score = 0.6070, Precision = 0.4815, Recall = 0.8211, Support = 95.0\n",
      "hbs_Latin: F1-score = 0.6035, Precision = 0.4804, Recall = 0.8113, Support = 106.0\n",
      "ban_Latin: F1-score = 0.5829, Precision = 0.6824, Recall = 0.5088, Support = 114.0\n",
      "vec_Latin: F1-score = 0.5803, Precision = 0.5490, Recall = 0.6154, Support = 91.0\n",
      "sot_Latin: F1-score = 0.5759, Precision = 0.6395, Recall = 0.5238, Support = 105.0\n",
      "hau_Arabe: F1-score = 0.5756, Precision = 0.6782, Recall = 0.5000, Support = 118.0\n",
      "aze_Latin: F1-score = 0.5755, Precision = 0.5755, Recall = 0.5755, Support = 106.0\n",
      "nob_Latin: F1-score = 0.5672, Precision = 0.5700, Recall = 0.5644, Support = 101.0\n",
      "azj_Latin: F1-score = 0.5654, Precision = 0.5745, Recall = 0.5567, Support = 97.0\n",
      "wln_Latin: F1-score = 0.5650, Precision = 0.5682, Recall = 0.5618, Support = 89.0\n",
      "tgk_Cyrillique: F1-score = 0.5625, Precision = 0.6818, Recall = 0.4787, Support = 94.0\n",
      "tat_Latin: F1-score = 0.5542, Precision = 0.7667, Recall = 0.4340, Support = 106.0\n",
      "srp_Cyrillique: F1-score = 0.5541, Precision = 0.7069, Recall = 0.4556, Support = 90.0\n",
      "guj_Devanagari (Hindi, Sanskrit): F1-score = 0.5392, Precision = 0.5288, Recall = 0.5500, Support = 100.0\n",
      "mad_Latin: F1-score = 0.5333, Precision = 0.5385, Recall = 0.5283, Support = 106.0\n",
      "sun_Latin: F1-score = 0.5333, Precision = 0.4812, Recall = 0.5981, Support = 107.0\n",
      "bik_Latin: F1-score = 0.5312, Precision = 0.5000, Recall = 0.5667, Support = 90.0\n",
      "nor_Latin: F1-score = 0.5297, Precision = 0.5698, Recall = 0.4949, Support = 99.0\n",
      "tuk_Cyrillique: F1-score = 0.5271, Precision = 0.4096, Recall = 0.7391, Support = 46.0\n",
      "kur_Arabe: F1-score = 0.5269, Precision = 0.7586, Recall = 0.4037, Support = 109.0\n",
      "cos_Latin: F1-score = 0.5259, Precision = 0.4748, Recall = 0.5893, Support = 112.0\n",
      "ary_Arabe: F1-score = 0.5143, Precision = 0.5143, Recall = 0.5143, Support = 105.0\n",
      "fil_Latin: F1-score = 0.5000, Precision = 0.4636, Recall = 0.5426, Support = 94.0\n",
      "mya_Latin: F1-score = 0.5000, Precision = 1.0000, Recall = 0.3333, Support = 3.0\n",
      "ltz_Latin: F1-score = 0.4967, Precision = 0.3619, Recall = 0.7917, Support = 96.0\n",
      "ara_Arabe: F1-score = 0.4917, Precision = 0.3854, Recall = 0.6789, Support = 109.0\n",
      "ajp_Arabe: F1-score = 0.4898, Precision = 0.4103, Recall = 0.6076, Support = 79.0\n",
      "pes_Arabe: F1-score = 0.4859, Precision = 0.5890, Recall = 0.4135, Support = 104.0\n",
      "tgk_Latin: F1-score = 0.4815, Precision = 0.5571, Recall = 0.4239, Support = 92.0\n",
      "kin_Latin: F1-score = 0.4773, Precision = 0.4667, Recall = 0.4884, Support = 86.0\n",
      "uzn_Cyrillique: F1-score = 0.4747, Precision = 0.5222, Recall = 0.4352, Support = 108.0\n",
      "fas_Arabe: F1-score = 0.4731, Precision = 0.4889, Recall = 0.4583, Support = 96.0\n",
      "uzb_Cyrillique: F1-score = 0.4688, Precision = 0.3822, Recall = 0.6061, Support = 99.0\n",
      "pam_Latin: F1-score = 0.4658, Precision = 0.4250, Recall = 0.5152, Support = 99.0\n",
      "sna_Latin: F1-score = 0.4595, Precision = 0.7391, Recall = 0.3333, Support = 102.0\n",
      "apc_Arabe: F1-score = 0.4574, Precision = 0.4474, Recall = 0.4679, Support = 109.0\n",
      "acm_Arabe: F1-score = 0.4490, Precision = 0.6111, Recall = 0.3548, Support = 93.0\n",
      "ind_Latin: F1-score = 0.4457, Precision = 0.4432, Recall = 0.4483, Support = 87.0\n",
      "hin_Latin: F1-score = 0.4455, Precision = 0.4412, Recall = 0.4500, Support = 100.0\n",
      "als_Latin: F1-score = 0.4348, Precision = 0.5556, Recall = 0.3571, Support = 98.0\n",
      "nde_Latin: F1-score = 0.4321, Precision = 0.4375, Recall = 0.4268, Support = 82.0\n",
      "zsm_Latin: F1-score = 0.4246, Precision = 0.3918, Recall = 0.4634, Support = 82.0\n",
      "eng_Latin: F1-score = 0.4190, Precision = 0.2964, Recall = 0.7143, Support = 105.0\n",
      "bcl_Latin: F1-score = 0.4032, Precision = 0.3566, Recall = 0.4636, Support = 110.0\n",
      "enm_Latin: F1-score = 0.4000, Precision = 1.0000, Recall = 0.2500, Support = 4.0\n",
      "msa_Latin: F1-score = 0.3946, Precision = 0.3793, Recall = 0.4112, Support = 107.0\n",
      "afb_Arabe: F1-score = 0.3757, Precision = 0.4048, Recall = 0.3505, Support = 97.0\n",
      "zul_Latin: F1-score = 0.3681, Precision = 0.4286, Recall = 0.3226, Support = 93.0\n",
      "sco_Latin: F1-score = 0.3545, Precision = 0.2356, Recall = 0.7156, Support = 109.0\n",
      "khm_Latin: F1-score = 0.3333, Precision = 1.0000, Recall = 0.2000, Support = 5.0\n",
      "som_Arabe: F1-score = 0.3226, Precision = 0.9091, Recall = 0.1961, Support = 102.0\n",
      "hrv_Latin: F1-score = 0.2917, Precision = 0.3559, Recall = 0.2471, Support = 85.0\n",
      "bos_Latin: F1-score = 0.2889, Precision = 0.3514, Recall = 0.2453, Support = 106.0\n",
      "tgk_Arabe: F1-score = 0.2838, Precision = 0.4565, Recall = 0.2059, Support = 102.0\n",
      "lao_Latin: F1-score = 0.2353, Precision = 0.6667, Recall = 0.1429, Support = 14.0\n",
      "guj_Latin: F1-score = 0.1429, Precision = 0.1667, Recall = 0.1250, Support = 8.0\n",
      "bod_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "dzo_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 7.0\n",
      "hne_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 3.0\n",
      "hyw_Arménien: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 7.0\n",
      "jpn_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "lao_Cyrillique: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "mai_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "miq_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 0.0\n",
      "nep_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "ngl_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 3.0\n",
      "niu_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "ori_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "pus_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "quz_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sat_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "sin_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "tam_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n",
      "teo_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "tha_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 2.0\n",
      "wbm_Latin: F1-score = 0.0000, Precision = 0.0000, Recall = 0.0000, Support = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hippolytelecomte/Documents/Etudes/CentraleSupelec/3A/ANLP/TD/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Générer le rapport de classification sous forme de dictionnaire\n",
    "report_sp = classification_report(y_val_sp, predictions_sp, target_names=filtered_target_names_sp, output_dict=True)\n",
    "\n",
    "# Filtrer les classes (en excluant 'accuracy', 'macro avg', 'weighted avg')\n",
    "filtered_report = {label: metrics for label, metrics in report_sp.items() if isinstance(metrics, dict)}\n",
    "\n",
    "# Trier les langues par F1-score de manière décroissante\n",
    "sorted_report = sorted(filtered_report.items(), key=lambda x: x[1]['f1-score'], reverse=True)\n",
    "\n",
    "# Afficher le rapport trié\n",
    "print(\"Classification Report (trié par F1-score décroissant):\\n\")\n",
    "for label, metrics in sorted_report:\n",
    "    print(f\"{label}: F1-score = {metrics['f1-score']:.4f}, Precision = {metrics['precision']:.4f}, Recall = {metrics['recall']:.4f}, Support = {metrics['support']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ B . ▁ 2 4 SI ▁ - ▁ I stra ži vanje ▁od sje k...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187584</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ I ▁svak og ▁da na ▁nakon ▁to ga ▁je ▁laga no...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172443</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ S lu ša j ! ▁ G de ▁je ▁čo ve k ▁koji ▁je ▁p...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ E ki pa ▁ J a pan ske ▁se ▁sas toj ala ▁od ▁...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49647</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ Ž ene ▁će ▁pu ca ti ▁ako ▁su ▁iz gu bile ▁si...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146261</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ N o ▁proizvod it ▁će ▁ih ▁i ▁sam ▁jedno m ▁k...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170926</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ \" C rk va ▁ Š klop ot nica ▁ ( c rk va ▁sv ....</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152952</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ T ako đe ▁nekoliko ▁ta ča ka ▁je ▁ski nu to ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156427</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ S vi ▁koji ▁su ▁radi li ▁sa ▁tvoj im ▁oc em ...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25324</th>\n",
       "      <td>Public</td>\n",
       "      <td>▁ D i rek tor ▁ F onda ▁ PIORS ▁ Z o ran ▁ M a...</td>\n",
       "      <td>bos_Latin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Usage                                               Text      Label\n",
       "34789   Public  ▁ B . ▁ 2 4 SI ▁ - ▁ I stra ži vanje ▁od sje k...  bos_Latin\n",
       "187584  Public  ▁ I ▁svak og ▁da na ▁nakon ▁to ga ▁je ▁laga no...  bos_Latin\n",
       "172443  Public  ▁ S lu ša j ! ▁ G de ▁je ▁čo ve k ▁koji ▁je ▁p...  bos_Latin\n",
       "1390    Public  ▁ E ki pa ▁ J a pan ske ▁se ▁sas toj ala ▁od ▁...  bos_Latin\n",
       "49647   Public  ▁ Ž ene ▁će ▁pu ca ti ▁ako ▁su ▁iz gu bile ▁si...  bos_Latin\n",
       "...        ...                                                ...        ...\n",
       "146261  Public  ▁ N o ▁proizvod it ▁će ▁ih ▁i ▁sam ▁jedno m ▁k...  bos_Latin\n",
       "170926  Public  ▁ \" C rk va ▁ Š klop ot nica ▁ ( c rk va ▁sv ....  bos_Latin\n",
       "152952  Public  ▁ T ako đe ▁nekoliko ▁ta ča ka ▁je ▁ski nu to ...  bos_Latin\n",
       "156427  Public  ▁ S vi ▁koji ▁su ▁radi li ▁sa ▁tvoj im ▁oc em ...  bos_Latin\n",
       "25324   Public  ▁ D i rek tor ▁ F onda ▁ PIORS ▁ Z o ran ▁ M a...  bos_Latin\n",
       "\n",
       "[106 rows x 3 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set_second_version[val_set_second_version['Label'] == 'bos_Latin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation du meilleur modèle pour le test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du meilleur modèle sur tout le train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190099/190099 [00:15<00:00, 12378.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-13 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-13 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-13 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-13 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-13 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB(alpha=0.001, fit_prior=False))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_features=200000, ngram_range=(1, 4))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.001, fit_prior=False)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char', max_features=200000,\n",
       "                                 ngram_range=(1, 4))),\n",
       "                ('mnb', MultinomialNB(alpha=0.001, fit_prior=False))])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_train_without_nan_for_label.copy()\n",
    "train = pre_processing(train, remove_espace=False, not_test=False)\n",
    "train = add_alphabet_to_label(train)\n",
    "# train['Text'] = train['Text'].progress_apply(sentencepiece_tokenize)\n",
    "x = train['Text'].tolist()\n",
    "y = train['Label'].tolist()\n",
    "\n",
    "vectorizer= TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4), max_features=200000)\n",
    "naive_bayes = MultinomialNB(alpha= 0.001, fit_prior = False) \n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('mnb', naive_bayes)\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_test = LabelEncoder()\n",
    "y = le_test.fit_transform(y)\n",
    "label_mapping_test = dict(zip(le_test.classes_, range(len(le_test.classes_))))\n",
    "\n",
    "best_pipeline.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction des labels pour le test et génération du csv à déposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test= pd.read_csv(file_path_test)\n",
    "test_set = pre_processing(data_test, remove_espace=False, not_test=False)\n",
    "# test_set['Text'] = test_set['Text'].progress_apply(sentencepiece_tokenize)\n",
    "\n",
    "x_test = test_set['Text'].tolist()\n",
    "predictions_test = best_pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190567/190567 [00:00<00:00, 1302890.45it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_test = le_test.inverse_transform(predictions_test)\n",
    "predicted_labels_test = restore_labels(predicted_labels_test)\n",
    "test_set['Label'] = predicted_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_ID = [i for i in range(1, len(test_set)+1)]\n",
    "test_set['ID'] = column_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[['Label', 'ID']].to_csv('test_set_v7_sans_tokenizer_predicted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
